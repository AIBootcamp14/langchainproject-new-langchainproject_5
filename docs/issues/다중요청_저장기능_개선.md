# 다중 요청 저장 기능 개선

## 📋 문서 정보
- **작성일**: 2025-11-05
- **작성자**: 개발팀
- **이슈 유형**: 버그 수정 + 기능 개선
- **우선순위**: ⭐⭐⭐ (긴급 - 사용자 기능 미작동)
- **상태**: ✅ 완료

---

## 🎯 이슈 개요

### 문제 상황
사용자가 "AI가 뭔지 찾아서 저장해줘"와 같은 **다중 요청(검색 + 저장)**을 할 때 두 가지 문제가 발생:

1. **다중 요청 인식 실패**: "찾아서 저장해줘" 패턴이 다중 요청으로 인식되지 않음
   - "AI가 뭔지 찾아서 저장해줘" → search_paper만 실행, save_file 실행 안됨
   - "전체 대화 내용 저장해줘" → 정상 작동

2. **저장 내용 문제**: 사용자 질문까지 저장됨
   - 사용자 의도: **LLM이 생성한 답변만** 마크다운으로 저장
   - 실제 동작: 사용자 질문 + AI 답변 모두 저장 (불필요한 정보 포함)

### 로그 분석 결과

**실험 폴더**: `experiments/20251105/20251105_223815_session_032`

#### 문제 1: "AI가 뭔지 찾아서 저장해줘" (chatbot.log:53)
```
2025-11-05 22:39:22 | 라우터 노드 실행: AI가 뭔지 찾아서 저장해줘
2025-11-05 22:39:25 | JSON 파싱 실패: Extra data
2025-11-05 22:39:25 | 키워드 기반 폴백 매칭 결과: search_paper
2025-11-05 22:39:25 | 최종 선택 도구: search_paper
2025-11-05 22:39:33 | 도구 실행 성공: search_paper
```
→ save_file 도구 전혀 실행되지 않음

#### 정상 동작: "전체 대화 내용 저장해줘" (chatbot.log:966)
```
2025-11-05 22:55:55 | 라우터 노드 실행: 전체 대화 내용 저장해줘
2025-11-05 22:55:55 | 다중 요청 감지: ['전체', '저장'] → ['save_file']
2025-11-05 22:55:55 | 저장 모드: 전체 대화 저장
2025-11-05 22:55:55 | 파일 저장 완료
```

#### 문제 2: 저장된 파일 내용
`20251105_225555_response_1.md` (29458 bytes):
```markdown
# 대화 내용

## [1] 🙋 사용자
llm이 뭐야?

## [2] 🤖 AI
LLM(Large Language Model)은...

## [3] 🙋 사용자
AI가 뭔지 찾아서 저장해줘

## [4] 🤖 AI
...
```
→ 사용자 질문(## [1], [3])까지 저장됨

---

## 📝 근본 원인 분석

### 원인 1: 다중 요청 패턴 매칭 실패

**configs/multi_request_patterns.yaml (line 79-91)**:
```yaml
- keywords:
  - 뭔지
  - 저장
  exclude_keywords:
  - 전체
  tools:
  - glossary
  - save_file
  description: 용어 정의 후 저장
  priority: 130
```

**문제점**:
1. "AI가 **뭔지** **찾아서** **저장**해줘" 질문
   - "뭔지" 단일 패턴 (line 20-28)에 `exclude_keywords: [찾아]` 존재
   - 단일 패턴이 먼저 매칭 시도 → exclude_keywords 때문에 실패
   - 다중 패턴 (line 79-91)은 priority 130으로 낮아서 매칭 안됨

2. "뭔지 + 저장" 패턴이 "찾아", "검색" 키워드를 고려하지 않음
   - "찾아서 저장", "검색해서 저장"도 같은 의도인데 매칭 실패

### 원인 2: save_file.py 저장 로직

**src/tools/save_file.py (line 44-77)**:

**문제 코드**:
```python
if is_full_save and messages:
    # 전체 대화 저장: 모든 사용자 질문 + AI 답변 포함
    for i, msg in enumerate(messages, 1):
        if role == "user":
            header = f"## [{i}] 🙋 사용자"
        elif role == "assistant":
            header = f"## [{i}] 🤖 AI"
        content_lines.append(f"{header}\n\n{content}\n")
```

**문제점**:
- 파이프라인 실행 시에도 tool_result만 사용하지 않고 logic이 복잡함
- 단일 답변 저장 시에도 명확히 "LLM 답변만" 추출하지 않음

---

## 🔧 해결 방안

### 1. 다중 요청 패턴 우선순위 및 exclude_keywords 개선

**수정 전** (configs/multi_request_patterns.yaml:79-91):
```yaml
- keywords:
  - 뭔지
  - 저장
  exclude_keywords:
  - 전체
  tools:
  - glossary
  - save_file
  description: 용어 정의 후 저장
  priority: 130
  examples:
  - AI가 뭔지 찾아서 저장해줘
  - GAN이 뭔지 알려주고 저장해줘
```

**수정 후**:
```yaml
- keywords:
  - 뭔지
  - 저장
  exclude_keywords:
  - 전체
  - 논문  # 추가: 논문 관련 질문과 구분
  tools:
  - glossary
  - save_file
  description: 용어 정의 후 저장
  priority: 140  # 상향: 130 → 140
  examples:
  - AI가 뭔지 찾아서 저장해줘
  - GAN이 뭔지 알려주고 저장해줘
  - Transformer가 뭔지 검색해서 저장해줘  # 추가
```

**변경 사항**:
1. **priority 상향** (130 → 140): 단일 패턴보다 우선 매칭
2. **exclude_keywords 추가** (`논문`): 논문 검색 + 저장은 별도 패턴
3. **예시 추가**: "검색해서 저장" 패턴 명시

**"뭐야 + 저장" 패턴도 동일하게 수정** (line 65-77).

---

### 2. save_file.py 저장 로직 개선

**수정 전** (src/tools/save_file.py:65-77):
```python
else:
    # 단일 답변 저장
    tool_pipeline = state.get("tool_pipeline", [])
    pipeline_index = state.get("pipeline_index", 0)

    if tool_pipeline and pipeline_index > 1:
        content_to_save = state.get("tool_result") or state.get("final_answer")
    else:
        content_to_save = state.get("tool_result") or state.get("final_answer")
```

**수정 후**:
```python
else:
    # 단일 답변 저장: LLM 답변만 저장 (사용자 질문 제외)
    tool_pipeline = state.get("tool_pipeline", [])
    pipeline_index = state.get("pipeline_index", 0)

    if tool_pipeline and pipeline_index > 1:
        # 파이프라인 실행 중: tool_result (이전 도구 결과) 사용
        content_to_save = state.get("tool_result", "")
    else:
        # 단일 도구 실행: messages에서 마지막 AI 답변만 추출
        content_to_save = ""

        if messages:
            for msg in reversed(messages):
                if msg.get("role") == "assistant":
                    content_to_save = msg.get("content", "")
                    break

        # 찾지 못했으면 Fallback
        if not content_to_save:
            content_to_save = state.get("tool_result") or state.get("final_answer") or "저장할 내용이 없습니다."
```

**변경 사항**:
1. **파이프라인 실행 중**: `tool_result` 직접 사용 (이전 도구 결과)
2. **단일 실행**: `messages`에서 마지막 `assistant` 메시지만 추출
3. **전체 대화 저장**: "전체" 키워드 있을 때만 사용자 질문 포함

---

## ✅ 개선 효과

### 1. 다중 요청 정상 인식

**이전**:
```
"AI가 뭔지 찾아서 저장해줘"
→ search_paper만 실행
→ save_file 실행 안됨
```

**개선 후**:
```
"AI가 뭔지 찾아서 저장해줘"
→ 다중 요청 감지: ['뭔지', '저장'] → ['glossary', 'save_file']
→ glossary 실행 → LLM 답변 생성 → save_file 실행
→ LLM 답변만 저장됨
```

### 2. 저장 내용 개선

**이전**:
```markdown
# 대화 내용

## [1] 🙋 사용자
llm이 뭐야?

## [2] 🤖 AI
LLM(Large Language Model)은...

## [3] 🙋 사용자
AI가 뭔지 찾아서 저장해줘

## [4] 🤖 AI
AI(Artificial Intelligence)는...
```

**개선 후** (단일 답변 저장 시):
```markdown
AI(Artificial Intelligence)는 인간의 학습, 추론, 문제 해결 능력을 모방한 컴퓨터 시스템입니다.

### 초등학생용 (8-13세)
...

### 초급자용 (14-22세)
...
```

→ **사용자 질문 없이 LLM 답변만 저장됨**

**전체 대화 저장** (명시적으로 "전체" 요청 시):
```markdown
# 대화 내용

## [1] 🙋 사용자
llm이 뭐야?

## [2] 🤖 AI
LLM(Large Language Model)은...
```
→ 사용자가 원할 때만 전체 대화 포함

---

## 📁 수정된 파일 목록

| 파일 경로 | 수정 내용 | 변경 라인 |
|-----------|----------|-----------|
| `configs/multi_request_patterns.yaml` | "뭐야/뭔지 + 저장" 패턴 priority 상향 (130→140), exclude_keywords 추가 | 65-93 |
| `src/tools/save_file.py` | 단일 답변 저장 시 LLM 답변만 추출, 파이프라인 로직 개선 | 65-87 |

---

## 🧪 테스트 시나리오

### 시나리오 1: 다중 요청 (검색 + 저장)
**질문**: "Transformer가 뭔지 찾아서 저장해줘"

**예상 동작**:
1. 다중 요청 감지: ['뭔지', '저장'] → ['glossary', 'save_file']
2. glossary 실행 → Transformer 정의 생성
3. save_file 실행 → LLM 답변만 저장 (질문 제외)

### 시나리오 2: 단일 답변 저장
**질문**: "llm이 뭐야?" (답변 생성 후) → "저장해줘"

**예상 동작**:
1. messages에서 마지막 assistant 메시지 추출
2. LLM 답변만 저장

### 시나리오 3: 전체 대화 저장
**질문**: "전체 대화 내용 저장해줘"

**예상 동작**:
1. `is_full_save = True`
2. 모든 사용자 질문 + AI 답변 포함

---

## 🔗 관련 문서

- **[09_도구_시스템.md](../modularization/09_도구_시스템.md)** - save_file 도구 설명
- **[06-1_다중_요청_처리.md](../modularization/06-1_다중_요청_처리.md)** - 다중 요청 패턴 매칭

---

## 📝 요약

1. **다중 요청 패턴 개선**: "뭐야/뭔지 + 저장" 패턴 priority 상향 및 exclude_keywords 추가
2. **저장 로직 개선**:
   - 단일 답변 저장 시 LLM 답변만 추출
   - 파이프라인 실행 시 tool_result 직접 사용
   - "전체" 키워드 있을 때만 사용자 질문 포함

이로써 사용자가 "찾아서 저장해줘" 요청 시:
- 다중 요청으로 정상 인식
- LLM 답변만 깔끔하게 저장
