## 제목 : 추가 선택 기능 구현 (Text-to-SQL, 성능 평가, Reranking 등)

---

## 📋 작업 개요
**작업 주제:** 핵심 기능 완료 후 선택 구현 (가산점 기능)
**담당자:** @먼저_완료한_팀원
**마감일:** 11/05 24:00

## 📅 기간
- 시작일: 2025-11-04
- 종료일: 2025-11-05

---

## 📌 이슈 목적

핵심 기능(AI Agent, RAG, 용어집, 웹 검색, 파일 저장, UI)을 먼저 완료한 팀원이 추가로 선택하여 구현할 수 있는 가산점 기능들입니다. 프로젝트 품질 향상 및 발표 시 차별화 요소로 활용할 수 있습니다.

**선택 기준:**
- 프로젝트에 가산점을 줄 수 있는 기능
- 구현 난이도와 시간 고려
- 팀원의 관심사 및 강점

---

## ✅ 작업 항목 체크리스트

### 선택 기능 1: Text-to-SQL 도구 (⭐⭐⭐ 가산점, 2-3일)
- [ ] SQLDatabaseChain 설정 (`src/tools/text2sql.py`)
  - [ ] SQLDatabase.from_uri()로 PostgreSQL 연결
  - [ ] ChatOpenAI (gpt-4, temperature=0) 사용
  - [ ] SQLDatabaseChain 생성 (verbose=True)
- [ ] query_paper_statistics 도구 구현
  - [ ] @tool 데코레이터 정의
  - [ ] 자연어 질문 → SQL 쿼리 변환
  - [ ] 쿼리 실행 및 결과 포맷팅
- [ ] 커스텀 SQL 생성 (고급)
  - [ ] SQL_GENERATION_PROMPT 정의 (DB 스키마 포함)
  - [ ] custom_sql_query() 함수 구현
  - [ ] 결과를 Markdown 테이블 형식으로 포맷팅
  - [ ] 오류 처리 (잘못된 SQL 생성 시)
- [ ] Agent 노드 추가 (선택 사항)

**사용 예시:**
- "2024년에 발표된 논문 개수는?"
- "가장 많이 인용된 논문 Top 5는?"
- "저자별 논문 수 알려줘"

---

### 선택 기능 2: 성능 평가 시스템 (⭐⭐ 가산점, 2-3일)
- [ ] LLM-as-a-Judge 평가 구현 (`src/evaluation/evaluator.py`)
  - [ ] EVALUATION_PROMPT 정의 (평가 기준: 정확도, 관련성, 난이도 적합성, 출처 명시)
  - [ ] AnswerEvaluator 클래스 정의
  - [ ] evaluate() 메서드 구현 (LLM으로 평가)
  - [ ] JSON 파싱 및 결과 반환
- [ ] 평가 결과 저장
  - [ ] save_evaluation_results() 함수 구현
  - [ ] PostgreSQL evaluation_results 테이블 생성
  - [ ] 평가 결과 INSERT
- [ ] Streamlit UI에 평가 결과 표시 (선택 사항)
  - [ ] 평가 점수 차트 (plotly)
  - [ ] 평가 코멘트 표시

**평가 항목:**
1. 정확도 (0-10점): 논문 내용과 일치하는지
2. 관련성 (0-10점): 질문과 답변이 관련있는지
3. 난이도 적합성 (0-10점): Easy/Hard 모드에 맞는지
4. 출처 명시 (0-10점): 논문 제목, 저자 명시 여부

---

### 선택 기능 3: Reranking (검색 최적화) (⭐⭐, 1-2일)
- [ ] Cohere Rerank 구현 (`src/rag/reranking.py`)
  - [ ] create_rerank_retriever() 함수 정의
  - [ ] CohereRerank 압축기 생성 (model: rerank-english-v2.0)
  - [ ] ContextualCompressionRetriever 생성
- [ ] 또는 LLMChainExtractor 구현
  - [ ] create_llm_extractor_retriever() 함수 정의
  - [ ] LLMChainExtractor로 문서 압축
- [ ] RAG 검색 도구에 Reranking 적용
- [ ] 성능 비교 (Before/After)

**효과:**
- 상위 20개 검색 결과에서 더 관련성 높은 5개 선택
- 검색 정확도 향상

---

### 선택 기능 4: 논문 비교 도구 (⭐, 1일)
- [ ] compare_papers 도구 구현 (`src/tools/paper_comparison.py`)
  - [ ] @tool 데코레이터 정의 (paper1_title, paper2_title)
  - [ ] RAG Retriever로 두 논문 검색
  - [ ] 비교 프롬프트 구성 (주요 기여, 모델 구조, 장점, 단점, 성능)
  - [ ] LLM 호출하여 비교 결과 생성 (Markdown 표 형식)

**사용 예시:**
- "BERT와 GPT 비교해줘"
- "Transformer와 RNN의 차이는?"

---

### 선택 기능 5: 대화 이력 시각화 (⭐, 1일)
- [ ] 분석 페이지 구현 (`ui/analytics.py`)
  - [ ] show_analytics() 함수 정의
  - [ ] PostgreSQL query_logs 테이블 조회
  - [ ] 도구 사용 통계 차트 (plotly 막대 그래프)
  - [ ] 난이도별 질문 분포 차트 (plotly 파이 차트)
- [ ] Streamlit 메뉴에 분석 페이지 추가

**시각화 내용:**
- 도구 사용 빈도
- 난이도별 질문 분포
- 시간대별 질문 패턴

---

### 선택 기능 6: 멀티모달 지원 (이미지 논문) (⭐⭐⭐, 2-3일)
- [ ] GPT-4 Vision 연동
  - [ ] ChatOpenAI 초기화 (model: gpt-4-vision-preview)
  - [ ] analyze_paper_image() 함수 정의
  - [ ] 이미지 Base64 인코딩
  - [ ] HumanMessage 생성 (text + image_url)
  - [ ] GPT-4 Vision 호출
- [ ] 논문 그래프, 표, 수식 이미지 분석

---

## 📦 설치/실행 명령어 예시

```bash
# Text-to-SQL
pip install langchain-community sqlalchemy psycopg2-binary
python src/tools/text2sql.py

# 성능 평가
pip install langchain-openai
python src/evaluation/evaluator.py

# Reranking
pip install cohere
python src/rag/reranking.py

# 대화 이력 시각화
pip install plotly pandas
streamlit run ui/analytics.py

# 멀티모달
pip install langchain-openai pillow
python -c "from src.tools.vision import analyze_paper_image; print('Vision 연동 성공')"
```

---

### ⚡️ 참고

**우선순위 추천:**

**High Priority (가산점 크고 구현 가능)**
1. **Text-to-SQL** (⭐⭐⭐) - 2-3일
2. **성능 평가 시스템** (⭐⭐) - 2-3일

**Medium Priority (구현 간단)**
3. **Reranking** (⭐⭐) - 1-2일
4. **논문 비교 도구** (⭐) - 1일
5. **대화 이력 시각화** (⭐) - 1일

**Low Priority (시간 많이 소요)**
6. **멀티모달 지원** (⭐⭐⭐) - 2-3일

**선택 가이드:**
- 시간이 2일 남았다면 → Text-to-SQL 또는 성능 평가 시스템
- 시간이 1일 남았다면 → Reranking 또는 논문 비교 도구
- 시간이 여유 있다면 → 멀티모달 지원

---

### 유용한 링크

**필수 참고 PRD 문서:**
- [docs/PRD/01_프로젝트_개요.md](../PRD/01_프로젝트_개요.md) - 프로젝트 전체 개요
- [docs/PRD/02_프로젝트_구조.md](../PRD/02_프로젝트_구조.md) - 폴더 구조
- [docs/PRD/05_로깅_시스템.md](../PRD/05_로깅_시스템.md) ⭐ - Logger 사용법
- [docs/PRD/06_실험_추적_관리.md](../PRD/06_실험_추적_관리.md) ⭐ - 실험 폴더 구조
- [docs/PRD/10_기술_요구사항.md](../PRD/10_기술_요구사항.md) - 기술 스택
- [docs/PRD/11_데이터베이스_설계.md](../PRD/11_데이터베이스_설계.md) - DB 스키마 (Text-to-SQL용)

**참고 PRD 문서:**
- [docs/PRD/03_브랜치_전략.md](../PRD/03_브랜치_전략.md) - Feature 브랜치
- [docs/PRD/04_일정_관리.md](../PRD/04_일정_관리.md) - 개발 일정

**외부 링크:**
- [Langchain SQL Database](https://python.langchain.com/docs/integrations/tools/sql_database)
- [LangChain Evaluation](https://python.langchain.com/docs/guides/evaluation/)
- [ContextualCompressionRetriever](https://python.langchain.com/docs/modules/data_connection/retrievers/contextual_compression/)

**역할 문서:**
- [docs/roles/담당역할_05_추가선택기능.md](../roles/담당역할_05_추가선택기능.md)

## 🔖 추천 라벨

`enhancement` `text2sql` `evaluation` `optimization` `experiment` `medium`

---

**참고 사항:**
- 선택 기능은 **필수가 아닙니다**
- 핵심 기능을 먼저 완성한 후 시간이 남을 때만 구현
- 팀원들과 상의하여 역할 분배
- 구현 시 **Feature 브랜치 생성** 필수

---
