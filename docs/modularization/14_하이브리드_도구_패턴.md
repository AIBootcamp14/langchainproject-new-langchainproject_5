# 14. 하이브리드 도구 패턴

## 📋 문서 정보
- **작성일**: 2025-11-04
- **작성자**: 최현화[팀장]
- **시스템명**: 하이브리드 도구 패턴 (Multi-Component Integration)
- **구현 파일**: `src/tools/`, `src/agent/nodes.py`
- **우선순위**: ⭐⭐⭐ (최고 - 핵심 설계 패턴)
- **참고 문서**: [09_도구_시스템.md](./09_도구_시스템.md), [05_데이터베이스_시스템.md](./05_데이터베이스_시스템.md)

---

## 📌 시스템 개요

### 하이브리드 도구 패턴이란?

**하이브리드 도구 패턴**은 **여러 기술 컴포넌트를 조합하여 하나의 도구를 구성**하는 설계 방식입니다. 본 프로젝트에서는 LangGraph Agent가 라우터에서 하나의 도구를 선택하지만, **선택된 도구 내부에서 여러 시스템을 순차적으로 조합하여 복잡한 작업을 수행**합니다.

### 단일 도구 vs 하이브리드 도구

**전통적인 단일 도구 방식**:
```
사용자 질문 → Router → [도구 A] → 답변 반환
                         └─ 단일 기능만 수행
```

**본 프로젝트의 하이브리드 방식**:
```
사용자 질문 → Router → [도구 A]
                         ├─ 컴포넌트 1 (LLM)
                         ├─ 컴포넌트 2 (DB)
                         ├─ 컴포넌트 3 (VectorDB)
                         └─ 컴포넌트 4 (LLM) → 답변 반환
```

### 하이브리드 패턴의 장점

1. **복잡도 은닉**: 사용자는 단일 도구처럼 사용하지만 내부는 다중 시스템 조합
2. **재사용성**: 각 컴포넌트를 독립적으로 테스트 및 교체 가능
3. **확장성**: 새로운 컴포넌트를 추가하여 기능 확장 용이
4. **데이터 일관성**: 여러 데이터 소스를 조합하여 정확도 향상

---

## 🔄 하이브리드 패턴 분류

### 패턴 1: 웹 검색 + 자동 저장 (web_search)

**컴포넌트 조합**:
```
Tavily API (웹 검색) → ArxivPaperHandler (논문 저장) → LLM (결과 정리)
```

**데이터 흐름**:
```
사용자 질문: "2025년 최신 LLM 논문?"
    ↓
1. Tavily API 호출
    ├─ 검색 결과 5개 획득
    └─ arXiv URL 감지
    ↓
2. ArxivPaperHandler 자동 실행 (발견 시)
    ├─ papers 테이블에 메타데이터 저장
    ├─ PDF 다운로드 및 텍스트 추출
    └─ langchain_pg_embedding에 벡터 임베딩 저장
    ↓
3. LLM 답변 생성
    └─ 검색 결과 + arXiv 저장 완료 메시지
```

**파일 위치**: `src/tools/web_search.py:83-111`, `src/tools/arxiv_handler.py`

---

### 패턴 2: 벡터 + 관계형 DB (search_paper)

**컴포넌트 조합**:
```
PGVector (벡터 검색) → PostgreSQL (메타데이터 조회) → LLM (답변 생성)
```

**데이터 흐름**:
```
사용자 질문: "What is Transformer?"
    ↓
1. PGVector 벡터 유사도 검색
    ├─ 질문 임베딩: [0.1, 0.2, ..., 0.8]
    ├─ langchain_pg_embedding 테이블 검색
    └─ Top-5 논문 청크 + paper_id 반환
    ↓
2. PostgreSQL 메타데이터 조회
    ├─ papers 테이블에서 paper_id로 조회
    └─ 제목, 저자, 발행일, URL 획득
    ↓
3. 결과 병합
    ├─ 벡터 검색 결과 + 메타데이터 조인
    └─ Markdown 포맷으로 변환
    ↓
4. LLM 답변 생성
    └─ 검색 결과를 바탕으로 답변 작성
```

**파일 위치**: `src/tools/search_paper.py:237-321`

**핵심 코드**:
```python
# 1. VectorDB 검색
retriever = RAGRetriever(search_type="similarity", k=5)
docs = retriever.similarity_search(query, k=5)

# 2. RDBMS 메타데이터 조회
paper_ids = [d.metadata.get("paper_id") for d in docs]
meta_map = _fetch_paper_meta(paper_ids)

# 3. 결과 병합
for doc in docs:
    pid = doc.metadata.get("paper_id")
    meta = meta_map.get(pid, {})
    # 벡터 검색 결과 + 메타데이터 조합
```

---

### 패턴 3: 다중 단계 LLM + DB (summarize)

**컴포넌트 조합**:
```
LLM (제목 추출) → PostgreSQL (논문 검색) → PGVector (청크 조회) → LLM (요약 생성)
```

**데이터 흐름**:
```
사용자 질문: "Attention Is All You Need 요약해줘"
    ↓
1. LLM 제목 추출
    ├─ 질문에서 논문 제목 파싱
    └─ 결과: "Attention Is All You Need"
    ↓
2. PostgreSQL 논문 검색
    ├─ papers 테이블에서 제목으로 검색
    └─ paper_id, title, authors, abstract 획득
    ↓
3. PGVector 청크 조회
    ├─ langchain_pg_embedding에서 논문 제목으로 검색
    ├─ 해당 논문의 모든 청크 조회 (k=50)
    └─ 청크들을 순서대로 결합
    ↓
4. LLM 요약 생성
    ├─ 논문 메타데이터 + 청크 내용 전달
    └─ 난이도별 요약 프롬프트 적용
```

**파일 위치**: `src/tools/summarize.py:24-238`

**핵심 코드**:
```python
# 1. LLM 제목 추출
paper_title = llm_client.llm.invoke(extract_prompt).content.strip()

# 2. PostgreSQL 논문 검색
cursor.execute("SELECT paper_id, title FROM papers WHERE title ILIKE %s", (f"%{paper_title}%",))
paper_id, title = cursor.fetchone()

# 3. PGVector 청크 조회
vectorstore = PGVector(collection_name="paper_chunks", ...)
docs = vectorstore.similarity_search(query=title, k=50)

# 4. LLM 요약 생성
combined_text = "\n\n".join([doc.page_content for doc in docs])
summary = llm_client.llm.invoke(summary_prompt).content
```

---

### 패턴 4: LLM + SQL 실행 (text2sql)

**컴포넌트 조합**:
```
LLM (SQL 생성) → PostgreSQL (쿼리 실행) → Markdown 변환
```

**데이터 흐름**:
```
사용자 질문: "2024년 논문 개수는?"
    ↓
1. LLM SQL 생성
    ├─ 자연어를 SQL로 변환
    └─ 결과: SELECT COUNT(*) FROM papers WHERE EXTRACT(YEAR FROM publish_date) = 2024
    ↓
2. SQL 안전성 검증
    ├─ DDL/DML 차단 (INSERT/UPDATE/DELETE 금지)
    ├─ 화이트리스트 테이블/컬럼만 허용
    └─ EXPLAIN으로 실행 계획 확인
    ↓
3. PostgreSQL 쿼리 실행
    └─ papers 테이블 조회
    ↓
4. Markdown 표 변환
    └─ 결과를 보기 좋은 표 형식으로 반환
```

**파일 위치**: `src/tools/text2sql.py`

**안전성 검증 로직**:
```python
# 금지 패턴 차단
FORBIDDEN_PATTERNS = [
    r'\b(INSERT|UPDATE|DELETE|DROP|ALTER|TRUNCATE)\b',  # DML/DDL
    r'\b(GRANT|REVOKE)\b',  # 권한 명령
    r';.*SELECT'  # 다중 쿼리
]

# 화이트리스트 검증
ALLOWED_TABLES = {"papers"}
ALLOWED_COLUMNS = {"paper_id", "title", "authors", ...}
```

---

## 📊 하이브리드 패턴 비교표

| 도구 | 컴포넌트 개수 | 주요 컴포넌트 | DB 접근 횟수 | LLM 호출 횟수 | 복잡도 |
|------|--------------|--------------|-------------|--------------|--------|
| **web_search** | 3개 | Tavily + ArxivHandler + LLM | 2회 (arXiv 발견 시) | 1회 | 중간 |
| **search_paper** | 3개 | VectorDB + RDBMS + LLM | 2회 | 1회 | 중간 |
| **summarize** | 4개 | LLM + RDBMS + VectorDB + LLM | 2회 | 2회 | 높음 |
| **text2sql** | 2개 | LLM + RDBMS | 1회 | 1회 | 낮음 |
| **general** | 1개 | LLM | 0회 | 1회 | 낮음 |
| **glossary** | 2개 | RDBMS + LLM | 1회 | 1회 | 낮음 |
| **save_file** | 1개 | File I/O | 0회 | 0회 | 낮음 |

---

## 🔗 컴포넌트 간 데이터 전달

### web_search 패턴

```python
# src/tools/web_search.py:83-111
for result in search_results:
    url = result.get('url', '')

    # arXiv URL 감지
    if 'arxiv.org' in url:
        # ArxivPaperHandler 호출
        arxiv_handler = ArxivPaperHandler(logger=tool_logger)
        success = arxiv_handler.process_arxiv_paper(url)

        # papers 테이블 + langchain_pg_embedding 자동 저장
```

**데이터 전달 흐름**:
1. Tavily API → JSON 검색 결과 (URL 포함)
2. URL 감지 → ArxivPaperHandler 객체 생성
3. ArxivPaperHandler → papers 테이블 INSERT
4. ArxivPaperHandler → PDF 다운로드 → 텍스트 추출
5. ArxivPaperHandler → 벡터 임베딩 생성 → langchain_pg_embedding INSERT

### search_paper 패턴

```python
# src/tools/search_paper.py:168-204
# 1. VectorDB 검색
docs = retriever.similarity_search(query, k=5)

# 2. paper_id 추출
paper_ids = [d.metadata.get("paper_id") for d in docs]

# 3. RDBMS 메타데이터 일괄 조회
meta_map = _fetch_paper_meta(paper_ids)

# 4. 결과 병합
for doc in docs:
    pid = doc.metadata.get("paper_id")
    meta = meta_map.get(pid, {})
    # 벡터 검색 content + RDBMS 메타데이터
```

**데이터 전달 흐름**:
1. 사용자 질문 → 임베딩 벡터 (1536차원)
2. 임베딩 벡터 → langchain_pg_embedding 유사도 검색
3. 검색 결과 (Document 리스트) → paper_id 추출
4. paper_id → papers 테이블 조회 (IN 쿼리)
5. VectorDB 결과 + RDBMS 메타데이터 → 병합 → Markdown

---

## ⚡ 성능 최적화 전략

### 1. 일괄 조회 (Batch Query)

**문제점**: N개 논문에 대해 N번 DB 조회
```python
# ❌ 비효율적
for paper_id in paper_ids:
    cursor.execute("SELECT * FROM papers WHERE paper_id = %s", (paper_id,))
    # N번 DB 접근
```

**해결책**: 일괄 조회로 1번에 처리
```python
# ✅ 효율적
cursor.execute("SELECT * FROM papers WHERE paper_id = ANY(%s)", (paper_ids,))
# 1번 DB 접근
```

**적용 위치**: `src/tools/search_paper.py:42-72` (_fetch_paper_meta 함수)

### 2. Connection Pool 재사용

**전략**: 매번 새 연결을 생성하지 않고 Pool에서 재사용
```python
# src/database/db.py
connection_pool = psycopg2.pool.SimpleConnectionPool(
    minconn=1,
    maxconn=10  # 최대 10개 연결 재사용
)
```

**성능 개선**: 연결 생성 오버헤드 제거 (100ms → 1ms)

### 3. IVFFlat 인덱스 활용

**VectorDB 검색 최적화**:
```sql
-- langchain_pg_embedding 테이블에 IVFFlat 인덱스
CREATE INDEX langchain_pg_embedding_embedding_idx
ON langchain_pg_embedding
USING ivfflat (embedding vector_cosine_ops)
WITH (lists = 100);
```

**성능 개선**: O(n) → O(log n) 벡터 검색

### 4. LLM 호출 최소화

**summarize 도구 최적화**:
- **청크 제한**: 50개 청크 조회 → 20개만 요약에 사용
- **이유**: LLM Context Window 제한 (4K 토큰)
```python
# src/tools/summarize.py:159
combined_text = "\n\n".join([doc.page_content for doc in docs[:20]])
```

---

## 🎯 하이브리드 패턴 선택 가이드

### 언제 하이브리드 패턴을 사용하는가?

**사용 케이스**:
1. ✅ **여러 데이터 소스가 필요한 경우** (VectorDB + RDBMS)
2. ✅ **다단계 처리가 필요한 경우** (LLM → DB → LLM)
3. ✅ **자동화가 필요한 경우** (웹 검색 → 자동 저장)
4. ✅ **데이터 일관성이 중요한 경우** (메타데이터 + 벡터 데이터)

**사용하지 않는 경우**:
1. ❌ **단순 조회만 필요한 경우** (glossary - RDBMS만 사용)
2. ❌ **LLM만으로 충분한 경우** (general - LLM만 사용)
3. ❌ **파일 작업만 필요한 경우** (save_file - File I/O만 사용)

---

## 🔗 관련 문서

- **[09_도구_시스템.md](./09_도구_시스템.md)** - 7개 도구 전체 개요
- **[05_데이터베이스_시스템.md](./05_데이터베이스_시스템.md)** - RDBMS/VectorDB 구조
- **[10_RAG_시스템.md](./10_RAG_시스템.md)** - RAG 검색 상세
- **[06_AI_Agent_시스템.md](./06_AI_Agent_시스템.md)** - Agent 라우팅 로직

---

## 📝 요약

### 핵심 하이브리드 패턴 (4개)

1. **web_search**: Tavily + ArxivHandler + LLM (웹 검색 + 자동 저장)
2. **search_paper**: VectorDB + RDBMS + LLM (벡터 검색 + 메타데이터)
3. **summarize**: LLM + RDBMS + VectorDB + LLM (4단계 조합)
4. **text2sql**: LLM + RDBMS (자연어 → SQL)

### 설계 원칙

- **복잡도 은닉**: 사용자는 단일 도구로 인식
- **재사용성**: 각 컴포넌트 독립적으로 테스트 가능
- **확장성**: 새 컴포넌트 추가 용이
- **성능**: 일괄 조회, Connection Pool, 인덱스 활용

### 성능 최적화

- ✅ 일괄 조회 (N번 → 1번)
- ✅ Connection Pool (연결 재사용)
- ✅ IVFFlat 인덱스 (벡터 검색 가속)
- ✅ LLM 호출 최소화 (청크 제한)
