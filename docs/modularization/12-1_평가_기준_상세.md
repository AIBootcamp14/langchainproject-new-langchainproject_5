# 12-1. 평가 기준 상세

## 문서 정보
- **작성일**: 2025-11-04
- **작성자**: 최현화[팀장]
- **최종 수정일**: 2025-11-04

---

## 개요

본 문서는 LLM-as-a-Judge 방식의 평가 시스템에서 사용하는 4가지 평가 기준에 대한 상세 설명을 제공합니다. 각 기준은 0-10점 척도로 평가되며, 구체적인 점수 부여 기준과 예시를 포함합니다.

### 평가 항목 요약

| 항목 | 점수 범위 | 평가 대상 |
|------|----------|-----------|
| 정확도 (Accuracy) | 0-10 | 참고 문서 내용과의 일치도 |
| 관련성 (Relevance) | 0-10 | 질문과 답변의 연관성 |
| 난이도 적합성 (Difficulty) | 0-10 | 모드별 설명 수준 적합성 |
| 출처 명시 (Citation) | 0-10 | 참고 문헌 인용 명확성 |
| **총점** | **0-40** | **4개 항목의 합계** |

---

## 1. 정확도 (Accuracy)

### 정의

참고 문서의 내용이 답변에 얼마나 정확하게 반영되었는지 평가합니다. 핵심 정보의 포함 여부, 사실 관계의 정확성, 오류의 유무를 종합적으로 고려합니다.

### 점수 기준

| 점수 | 기준 | 핵심 내용 반영 비율 | 오류 허용 수준 |
|------|------|-------------------|---------------|
| **10점** | 완벽 | 100% | 오류 없음 |
| **7-9점** | 우수 | 80% 이상 | 사소한 표현 차이만 허용 |
| **4-6점** | 보통 | 50-79% | 경미한 오류 1-2개 허용 |
| **1-3점** | 미흡 | 50% 미만 | 중요 오류 여러 개 |
| **0점** | 부적합 | 거의 없음 | 완전히 틀린 정보 |

### 상세 채점 기준

#### 10점: 완벽한 정확도
- 참고 문서의 핵심 내용을 모두 정확히 반영
- 사실 관계 오류 전혀 없음
- 전문 용어 정확히 사용
- 수치, 날짜, 이름 등 세부 정보 정확

**예시**:
- **질문**: "Transformer의 핵심 구조는?"
- **참고 문서**: "Transformer는 Self-Attention과 Feed-Forward Neural Network로 구성됩니다."
- **10점 답변**: "Transformer는 Self-Attention 메커니즘과 Feed-Forward Neural Network 두 가지 핵심 구조로 구성됩니다."

#### 7-9점: 우수한 정확도
- 핵심 내용 80% 이상 정확히 반영
- 사소한 표현 차이만 있음 (의미는 동일)
- 중요한 정보 누락 없음
- 사실 관계는 정확

**예시**:
- **9점 답변**: "Transformer는 Self-Attention과 피드포워드 신경망으로 이루어져 있습니다."
  - (Feed-Forward를 "피드포워드"로 표현했으나 의미 동일)
- **7점 답변**: "Transformer는 Attention 메커니즘과 신경망 레이어로 구성됩니다."
  - (Self-Attention을 Attention으로, FFN을 신경망 레이어로 일반화했으나 크게 틀리지 않음)

#### 4-6점: 보통 수준의 정확도
- 핵심 내용 50-79% 반영
- 일부 중요 내용 누락
- 경미한 사실 오류 1-2개
- 부분적으로 정확

**예시**:
- **6점 답변**: "Transformer는 Attention 메커니즘으로 구성됩니다."
  - (Feed-Forward 부분 완전 누락, 핵심 중 50% 반영)
- **4점 답변**: "Transformer는 CNN과 Attention을 결합한 구조입니다."
  - (CNN 언급은 오류, Attention은 맞음)

#### 1-3점: 미흡한 정확도
- 핵심 내용 50% 미만만 정확
- 중요 내용 대부분 누락
- 사실 오류 여러 개
- 참고 문서와 큰 차이

**예시**:
- **3점 답변**: "Transformer는 딥러닝 모델의 한 종류입니다."
  - (너무 일반적, 구체적 구조 설명 없음)
- **1점 답변**: "Transformer는 RNN 기반의 순환 신경망입니다."
  - (RNN 기반이라는 것은 완전히 틀림)

#### 0점: 부적합
- 참고 문서와 완전히 무관
- 전혀 다른 주제
- 완전히 틀린 정보

**예시**:
- **0점 답변**: "Transformer는 자동차 변신 로봇입니다."
  - (완전히 다른 의미)

---

## 2. 관련성 (Relevance)

### 정의

사용자 질문과 AI 답변이 얼마나 직접적으로 연관되어 있는지 평가합니다. 질문의 의도를 정확히 파악하고, 필요한 정보를 완전하게 제공했는지 확인합니다.

### 점수 기준

| 점수 | 기준 | 질문 대응도 | 불필요한 정보 |
|------|------|-----------|--------------|
| **10점** | 완벽 | 직접적이고 완전한 답변 | 없음 |
| **7-9점** | 우수 | 직접 답변, 일부 정보 누락 | 약간 있음 (허용) |
| **4-6점** | 보통 | 간접적 답변 | 다소 많음 |
| **1-3점** | 미흡 | 부분적으로만 관련 | 대부분 불필요 |
| **0점** | 부적합 | 완전히 무관 | 전부 불필요 |

### 상세 채점 기준

#### 10점: 완벽한 관련성
- 질문에 직접적으로 답변
- 질문이 요구하는 모든 정보 포함
- 불필요한 정보 없음
- 질문 의도를 정확히 파악

**예시**:
- **질문**: "BERT의 학습 방법은?"
- **10점 답변**: "BERT는 Masked Language Modeling (MLM)과 Next Sentence Prediction (NSP) 두 가지 방식으로 사전학습합니다."
  - (학습 방법을 구체적이고 완전하게 답변)

#### 7-9점: 우수한 관련성
- 질문에 직접 답변했으나 일부 정보 누락
- 약간의 불필요한 내용 포함 가능
- 질문 의도는 충족

**예시**:
- **9점 답변**: "BERT는 Masked Language Modeling으로 사전학습합니다."
  - (MLM만 언급, NSP 누락)
- **7점 답변**: "BERT는 대규모 텍스트 데이터로 Masked Language Modeling 방식으로 학습하며, Google에서 개발했습니다."
  - (개발사 정보는 질문과 약간 무관하지만 허용 가능)

#### 4-6점: 보통 수준의 관련성
- 질문과 관련은 있으나 핵심에서 벗어남
- 간접적인 답변
- 불필요한 정보가 다소 많음

**예시**:
- **6점 답변**: "BERT는 Transformer 기반 모델로, 대규모 데이터셋에서 학습됩니다."
  - (학습 방법보다 모델 구조와 데이터에 초점)
- **4점 답변**: "BERT는 2018년 발표된 자연어 처리 모델입니다."
  - (발표 시기와 용도는 맞지만 학습 방법 설명 없음)

#### 1-3점: 미흡한 관련성
- 질문과 부분적으로만 관련
- 핵심을 다루지 않음
- 대부분 불필요한 정보

**예시**:
- **3점 답변**: "BERT는 자연어 처리 분야에서 많이 사용됩니다."
  - (사용 분야만 언급, 학습 방법 전혀 없음)

#### 0점: 완전 무관
- 질문과 전혀 무관한 답변

**예시**:
- **0점 답변**: "GPT는 생성형 모델입니다."
  - (BERT가 아닌 GPT에 대한 답변)

---

## 3. 난이도 적합성 (Difficulty)

### 정의

사용자가 선택한 난이도 모드(Easy/Hard)에 맞게 답변이 작성되었는지 평가합니다. 용어 선택, 설명 수준, 예시 사용 등을 종합적으로 고려합니다.

### Easy 모드 기준

| 점수 | 수준 | 용어 선택 | 설명 방식 |
|------|------|----------|----------|
| **10점** | 중학생 | 일상 용어, 비유/예시 풍부 | 단계별 쉬운 설명 |
| **7-9점** | 고등학생 | 대부분 쉬운 용어, 일부 전문 용어는 설명 | 이해하기 쉬운 설명 |
| **4-6점** | 대학생 | 쉬운 용어와 전문 용어 혼재 | 보통 난이도 설명 |
| **1-3점** | 대학원생 | 전문 용어 다수, 추상적 | 어렵고 전문적 |
| **0점** | 전문가 | Hard 모드 수준 | 논문 수준 |

### Hard 모드 기준

| 점수 | 수준 | 용어 선택 | 설명 방식 |
|------|------|----------|----------|
| **10점** | 전문가 | 전문 용어 정확히 사용 | 수식/알고리즘, 논문 수준 |
| **7-9점** | 대학원생 | 대부분 전문적, 일부 쉬운 설명 | 기술적 설명 |
| **4-6점** | 대학생 | 전문 용어와 쉬운 설명 혼재 | 중간 수준 |
| **1-3점** | 고등학생 | 쉬운 용어 다수, 비유 위주 | 피상적 설명 |
| **0점** | 중학생 | Easy 모드 수준 | 매우 쉬운 설명 |

### Easy 모드 예시

#### 10점: 완벽한 Easy 수준
- **질문**: "Attention 메커니즘이란?" (Easy 모드)
- **10점 답변**: "Attention은 마치 선생님이 학생들 중에서 손을 든 학생에게 집중하는 것처럼, AI가 문장에서 중요한 단어에 더 집중하는 방법입니다. 예를 들어 '나는 사과를 먹었다'라는 문장에서 '사과'와 '먹었다'가 중요하다고 판단하면, 그 부분에 더 많은 주의를 기울입니다."
  - (일상적 비유, 구체적 예시, 쉬운 용어)

#### 7-9점: 우수한 Easy 수준
- **9점 답변**: "Attention은 AI가 입력 데이터에서 중요한 부분을 찾아내는 기술입니다. 마치 책을 읽을 때 중요한 문장에 형광펜을 칠하는 것처럼, 중요한 정보에 더 많은 가중치를 부여합니다."
  - (비유 사용, 약간의 기술 용어 포함하지만 설명 추가)

#### 4-6점: 보통 수준 (Easy 모드로는 부족)
- **6점 답변**: "Attention 메커니즘은 입력 시퀀스의 각 요소에 가중치를 할당하여 중요도를 계산하는 방법입니다."
  - (전문 용어 많음, 비유 없음, 대학생 수준)

#### 1-3점: 너무 어려움
- **2점 답변**: "Attention(Q, K, V) = softmax(QK^T / √d_k)V로 계산되며, Query, Key, Value의 내적으로 가중치를 산출합니다."
  - (수식 사용, 전문가 수준, Easy 모드 부적합)

### Hard 모드 예시

#### 10점: 완벽한 Hard 수준
- **질문**: "Transformer의 Self-Attention 계산 방법은?" (Hard 모드)
- **10점 답변**: "Self-Attention은 Attention(Q, K, V) = softmax(QK^T / √d_k)V로 계산됩니다. 여기서 Q, K, V는 각각 Query, Key, Value 행렬이며, d_k는 Key의 차원입니다. 스케일링 팩터 √d_k는 내적 값이 커지는 것을 방지하여 gradient 안정성을 높입니다."
  - (수식 정확, 전문 용어 사용, 기술적 설명)

#### 7-9점: 우수한 Hard 수준
- **9점 답변**: "Self-Attention은 Query, Key, Value 행렬의 연산으로 계산되며, softmax와 스케일링이 적용됩니다. 이를 통해 각 토큰 간의 관계를 학습합니다."
  - (전문적이지만 수식 생략, 개념적 설명)

#### 1-3점: 너무 쉬움
- **2점 답변**: "Self-Attention은 문장에서 각 단어가 다른 단어들과 얼마나 관련 있는지 계산하는 방법입니다."
  - (비유적 설명, Hard 모드로는 부적합)

---

## 4. 출처 명시 (Citation)

### 정의

답변에 참고 문헌이나 출처를 얼마나 명확하고 구체적으로 인용했는지 평가합니다. 논문 제목, 저자, 발행 연도를 모두 포함하는 것이 이상적입니다.

### 점수 기준

| 점수 | 인용 정보 | 예시 |
|------|----------|------|
| **10점** | 제목 + 저자 + 연도 | "Attention Is All You Need (Vaswani et al., 2017)" |
| **7-9점** | 제목 + 저자 또는 제목 + 연도 | "Vaswani et al.의 Attention Is All You Need" |
| **4-6점** | 제목만 또는 저자만 | "Attention Is All You Need 논문" |
| **1-3점** | 모호한 출처 언급 | "한 논문에 따르면" |
| **0점** | 출처 명시 없음 | (출처 언급 전혀 없음) |

### 상세 채점 기준

#### 10점: 완벽한 출처 명시
- 논문 제목, 저자, 발행 연도 모두 포함
- 표준 인용 형식

**예시**:
- "Transformer는 Attention Is All You Need (Vaswani et al., 2017) 논문에서 제안되었습니다."
- "BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding (Devlin et al., 2018)에서 소개되었습니다."

#### 7-9점: 우수한 출처 명시
- 제목 + 저자 (연도 누락)
- 제목 + 연도 (저자 누락)

**예시**:
- **9점**: "Vaswani et al.의 Attention Is All You Need 논문에서 제안되었습니다."
  - (제목 + 저자, 연도 누락)
- **7점**: "Attention Is All You Need (2017) 논문에서 제안되었습니다."
  - (제목 + 연도, 저자 누락)

#### 4-6점: 보통 수준의 출처 명시
- 제목만 명시
- 저자만 명시

**예시**:
- **6점**: "Attention Is All You Need 논문에서 제안되었습니다."
  - (제목만, 저자/연도 없음)
- **4점**: "Vaswani 등이 제안했습니다."
  - (저자만, 제목/연도 없음)

#### 1-3점: 미흡한 출처 명시
- 출처를 언급했으나 구체적이지 않음
- "한 논문", "연구에 따르면" 등 모호한 표현

**예시**:
- **3점**: "한 연구에서 제안된 방법입니다."
- **1점**: "논문에서 나왔습니다."

#### 0점: 출처 명시 없음
- 출처에 대한 언급이 전혀 없음

**예시**:
- "Transformer는 Self-Attention 메커니즘을 사용합니다."
  - (내용은 맞지만 출처 없음)

---

## 평가 프로세스

### 1. 평가 전 준비

```python
from src.evaluation.evaluator import AnswerEvaluator

# Evaluator 초기화
evaluator = AnswerEvaluator()
```

### 2. 단일 평가 수행

```python
result = evaluator.evaluate(
    question="사용자 질문",
    answer="AI 답변",
    reference_docs="참고 문서 내용",
    difficulty="easy"  # 또는 "hard"
)

# 결과 출력
print(f"정확도: {result['accuracy_score']}/10")
print(f"관련성: {result['relevance_score']}/10")
print(f"난이도: {result['difficulty_score']}/10")
print(f"출처: {result['citation_score']}/10")
print(f"총점: {result['total_score']}/40")
print(f"코멘트: {result['comment']}")
```

### 3. 배치 평가 수행

```python
test_cases = [
    {
        "question": "질문1",
        "answer": "답변1",
        "reference_docs": "참고문서1",
        "difficulty": "easy"
    },
    {
        "question": "질문2",
        "answer": "답변2",
        "reference_docs": "참고문서2",
        "difficulty": "hard"
    }
]

results = evaluator.evaluate_batch(test_cases)
```

---

## 평가 시 주의사항

### 1. 일관성 유지
- 동일한 품질의 답변은 유사한 점수를 받아야 함
- 채점 기준을 엄격히 준수
- 개인적 선호도 배제

### 2. 종합적 판단
- 4가지 기준을 독립적으로 평가
- 한 항목의 점수가 다른 항목에 영향을 주지 않도록 주의
- 각 기준의 가중치는 동일 (각 10점)

### 3. 명확한 근거
- 각 점수에 대한 명확한 근거 제시
- comment 필드에 구체적인 이유 기재
- 개선 방향 제시 (선택 사항)

---

## 참고 자료

- [12_성능_평가_시스템.md](./12_성능_평가_시스템.md) - 시스템 전체 아키텍처
- [12-2_평가_일관성_검증.md](./12-2_평가_일관성_검증.md) - 일관성 검증 방법
- [docs/issues/05-3_평가시스템_개선_구체적_기준_추가.md](../issues/05-3_평가시스템_개선_구체적_기준_추가.md) - 평가 기준 개선 배경

---

## 작성자

- **최현화[팀장]** (평가 기준 설계 및 문서화)
