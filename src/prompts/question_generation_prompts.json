{
  "question_generation_prompt": {
    "template": "다음 논문을 기반으로 테스트용 질문을 생성해주세요.\n\n[논문 정보]\n제목: {title}\n저자: {authors}\n초록: {abstract}\n\n[생성 규칙]\n- 각 난이도(Easy/Hard)별로 5개씩 총 10개 질문 생성\n- 각 도구(search_paper, web_search, glossary, summarize, general)를 다양하게 사용하는 질문 포함\n- Easy 질문: 초심자용 (\"~가 뭐야?\", \"간단히 설명해줘\")\n- Hard 질문: 전문가용 (\"시간 복잡도는?\", \"알고리즘 비교\")\n\nJSON 형식으로 반환:\n{\n  \"questions\": [\n    {\n      \"question\": \"질문 내용\",\n      \"difficulty\": \"easy\",\n      \"expected_tool\": \"search_paper\",\n      \"expected_answer_keywords\": [\"키워드1\", \"키워드2\", \"키워드3\"]\n    }\n  ]\n}",
    "input_variables": ["title", "authors", "abstract"]
  },

  "question_templates": {
    "easy": [
      "{term}가 뭐야?",
      "{paper_title} 간단히 설명해줘",
      "{concept} 쉽게 알려줘",
      "{paper_title} 요약해줘",
      "{method}는 어떻게 작동해?"
    ],
    "hard": [
      "{algorithm}의 시간 복잡도는?",
      "{paper_title}의 핵심 기여는?",
      "{method1}과 {method2}의 차이는?",
      "{paper_title}의 한계점은?",
      "{architecture}의 구조를 자세히 설명해줘"
    ]
  },

  "tool_based_templates": {
    "search_paper": [
      "{keyword} 논문 찾아줘",
      "{topic}에 대한 연구 검색해줘",
      "{author}의 논문 찾아줘"
    ],
    "web_search": [
      "최신 {topic} 뉴스",
      "2024년 {field} 연구 동향",
      "최근 {method} 발전"
    ],
    "glossary": [
      "{term}이 뭐야?",
      "{concept}의 정의는?",
      "{abbreviation} 설명해줘"
    ],
    "summarize": [
      "{paper_title} 요약해줘",
      "{paper_title} 핵심 내용",
      "{paper_title} 간단히 정리해줘"
    ],
    "general": [
      "{A}와 {B}의 차이는?",
      "{method}가 {baseline}보다 나은 이유는?",
      "{concept} 설명해줘"
    ],
    "save_file": [
      "대화 내용 저장해줘",
      "파일로 다운로드",
      "결과 저장"
    ]
  },

  "generation_examples": [
    {
      "paper": {
        "title": "Attention Is All You Need",
        "authors": "Vaswani et al.",
        "abstract": "We propose a new simple network architecture, the Transformer..."
      },
      "generated_questions": [
        {
          "question": "Transformer가 뭐야?",
          "difficulty": "easy",
          "expected_tool": "glossary",
          "expected_answer_keywords": ["Attention", "병렬 처리", "인코더-디코더"]
        },
        {
          "question": "Attention Is All You Need 논문 찾아줘",
          "difficulty": "easy",
          "expected_tool": "search_paper",
          "expected_answer_keywords": ["Vaswani", "2017", "Transformer"]
        },
        {
          "question": "Self-Attention의 시간 복잡도는?",
          "difficulty": "hard",
          "expected_tool": "general",
          "expected_answer_keywords": ["O(n²)", "시퀀스 길이", "복잡도"]
        },
        {
          "question": "Transformer 논문 요약해줘",
          "difficulty": "easy",
          "expected_tool": "summarize",
          "expected_answer_keywords": ["Attention", "인코더", "디코더", "병렬"]
        },
        {
          "question": "Transformer와 RNN의 차이는?",
          "difficulty": "hard",
          "expected_tool": "general",
          "expected_answer_keywords": ["병렬화", "순차 처리", "long-range dependency"]
        }
      ]
    }
  ]
}
