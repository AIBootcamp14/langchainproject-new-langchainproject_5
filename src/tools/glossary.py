# ==========================================
# ğŸ“˜ Phase 3: ìš©ì–´ì§‘ ì‹œìŠ¤í…œ êµ¬í˜„
# ğŸ“ Step 5: ìš©ì–´ì§‘ ë„êµ¬(@tool) + í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰
# ------------------------------------------
# - @tool: search_glossary (hybrid/sql/vector)
# - PostgreSQL(ILIKE/í•„í„°) + PGVector(ìœ ì‚¬ë„) ë³‘í•©
# - ë‚œì´ë„ ëª¨ë“œ(easy/hard/auto)ë¡œ ì„¤ëª… ì„ íƒ
# ==========================================

import os
from typing import Any, Dict, List, Optional, Tuple

import psycopg2
from psycopg2.extras import RealDictCursor
from langchain_core.tools import tool
from langchain_core.documents import Document
from langchain_openai import OpenAIEmbeddings
from langchain_postgres.vectorstores import PGVector

# ---------- í™˜ê²½/ì»¤ë„¥ì…˜ ----------
def _env(primary: str, alt: str, default: Optional[str] = None) -> Optional[str]:
    return os.getenv(primary) or os.getenv(alt) or default

def _pg_conn_str() -> str:
    user = _env("POSTGRES_USER", "PGUSER", "postgres")
    password = _env("POSTGRES_PASSWORD", "PGPASSWORD", "postgres")
    host = _env("POSTGRES_HOST", "PGHOST", "localhost")
    port = _env("POSTGRES_PORT", "PGPORT", "5432")
    db = _env("POSTGRES_DB", "PGDATABASE", "papers")
    return f"postgresql://{user}:{password}@{host}:{port}/{db}"

def _get_glossary_vectorstore() -> PGVector:
    """ìš©ì–´ì§‘ ì „ìš© VectorStore ì´ˆê¸°í™”."""
    conn_str = _pg_conn_str()
    collection = os.getenv("PGV_COLLECTION_GLOSSARY", "glossary_embeddings")
    embeddings = OpenAIEmbeddings(model=os.getenv("EMBEDDING_MODEL", "text-embedding-3-small"))
    return PGVector(
        collection_name=collection,
        embeddings=embeddings,
        connection=conn_str,
        use_jsonb=True,
    )

# ---------- SQL 1ì°¨ ì¡°íšŒ ----------

def _fetch_glossary_sql(
    query: Optional[str],
    category: Optional[str],
    difficulty: Optional[str],
    limit: int,
) -> List[Dict[str, Any]]:
    conn = psycopg2.connect(_pg_conn_str())
    try:
        where = []
        params: List[Any] = []
        if query:
            where.append("(term ILIKE %s OR definition ILIKE %s OR easy_explanation ILIKE %s OR hard_explanation ILIKE %s)")
            like = f"%{query}%"
            params.extend([like, like, like, like])
        if category:
            where.append("category = %s")
            params.append(category)
        if difficulty:
            where.append("difficulty_level = %s")
            params.append(difficulty)

        sql = """
            SELECT term_id, term, definition, easy_explanation, hard_explanation,
                   category, difficulty_level, related_terms, examples, created_at, updated_at
            FROM glossary
        """
        if where:
            sql += " WHERE " + " AND ".join(where)
        sql += " ORDER BY term_id ASC LIMIT %s"
        params.append(limit)

        with conn.cursor(cursor_factory=RealDictCursor) as cur:
            cur.execute(sql, tuple(params))
            rows = cur.fetchall()
            return [dict(r) for r in rows]
    finally:
        conn.close()

# ---------- Vector 2ì°¨ ì¡°íšŒ ----------

def _vector_search_glossary(query: str, k: int) -> List[Tuple[Document, float]]:
    vs = _get_glossary_vectorstore()
    pairs = vs.similarity_search_with_score(query, k=k)
    # pairs: List[Tuple[Document, score(float)]]
    return pairs

# ---------- ê²°ê³¼ í¬ë§·/ì„¤ëª… ì„ íƒ ----------

def _pick_explanation(row: Dict[str, Any], difficulty_mode: str) -> str:
    """ë‚œì´ë„ ëª¨ë“œì— ë§ëŠ” ì„¤ëª… ì„ íƒ."""
    if difficulty_mode == "easy":
        return row.get("easy_explanation") or row.get("definition") or ""
    if difficulty_mode == "hard":
        return row.get("hard_explanation") or row.get("definition") or ""
    # auto: difficulty_level ë³´ê³  ìš°ì„ ìˆœìœ„ ì„ íƒ
    level = (row.get("difficulty_level") or "").lower()
    if level in ("beginner", "intermediate") and row.get("easy_explanation"):
        return row["easy_explanation"]
    if level == "advanced" and row.get("hard_explanation"):
        return row["hard_explanation"]
    return row.get("easy_explanation") or row.get("hard_explanation") or row.get("definition") or ""

def _format_glossary_md(items: List[Dict[str, Any]]) -> str:
    if not items:
        return "ê´€ë ¨ ìš©ì–´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
    out: List[str] = ["## ìš©ì–´ì§‘ ê²€ìƒ‰ ê²°ê³¼\n"]
    for i, r in enumerate(items, 1):
        out.append(f"### {i}. {r.get('term','(term)')}")
        out.append(f"- **ì¹´í…Œê³ ë¦¬**: {r.get('category','')}")
        out.append(f"- **ë‚œì´ë„**: {r.get('difficulty_level','')}")
        if r.get("score") is not None:
            out.append(f"- **ìœ ì‚¬ë„ ì ìˆ˜(ë‚®ì„ìˆ˜ë¡ ìœ ì‚¬)**: {r['score']:.4f}")
        if r.get("related_terms"):
            out.append(f"- **ì—°ê´€ ìš©ì–´**: {', '.join(r['related_terms']) if isinstance(r['related_terms'], list) else r['related_terms']}")
        if r.get("examples"):
            out.append(f"- **ì˜ˆì‹œ**: {r['examples']}")
        if r.get("definition"):
            out.append(f"- **ì •ì˜**: {r['definition']}")
        if r.get("explanation"):
            out.append(f"\n{r['explanation']}\n")
        out.append("\n---\n")
    return "\n".join(out)

# ---------- @tool: ìš©ì–´ì§‘ ê²€ìƒ‰ ----------
@tool
def search_glossary(
    query: Optional[str] = None,
    category: Optional[str] = None,
    difficulty: str = "auto",  # 'easy' | 'hard' | 'auto'
    mode: str = "hybrid",      # 'hybrid' | 'sql' | 'vector'
    top_k: int = 5,
    with_scores: bool = True,
) -> str:
    """
    ìš©ì–´ì§‘ ê²€ìƒ‰ ë„êµ¬ (í•˜ì´ë¸Œë¦¬ë“œ/SQL/Vector ì§€ì›).
    - SQL: ILIKE + í•„í„°
    - Vector: glossary_embeddings ì»¬ë ‰ì…˜
    - hybrid: ë‘ ê²°ê³¼ ë³‘í•© í›„ dedup
    """
    items: List[Dict[str, Any]] = []

    if mode in ("hybrid", "vector") and query:
        try:
            vector_pairs = _vector_search_glossary(query, k=top_k)
            for doc, score in vector_pairs:
                md = doc.metadata or {}
                row = {
                    "term": md.get("term") or md.get("title") or "",
                    "category": md.get("category"),
                    "difficulty_level": md.get("difficulty_level"),
                    "related_terms": md.get("related_terms"),
                    "examples": md.get("examples"),
                    "definition": md.get("definition"),
                    "explanation": _pick_explanation(md, difficulty),
                    "score": float(score) if with_scores else None,
                }
                items.append(row)
        except Exception:
            # ë²¡í„° ì¸ë±ìŠ¤ê°€ ë¹„ì–´ ìˆê±°ë‚˜ ì»¬ë ‰ì…˜ ë¯¸ìƒì„± ì‹œ ì¡°ìš©íˆ íŒ¨ìŠ¤ (hybridë©´ SQLë¡œ ë³´ì™„)
            pass

    if mode in ("hybrid", "sql"):
        sql_rows = _fetch_glossary_sql(
            query=query,
            category=category,
            difficulty=(difficulty if difficulty in ("beginner", "intermediate", "advanced") else None),
            limit=top_k,
        )
        for r in sql_rows:
            items.append({
                "term": r.get("term"),
                "category": r.get("category"),
                "difficulty_level": r.get("difficulty_level"),
                "related_terms": r.get("related_terms"),
                "examples": r.get("examples"),
                "definition": r.get("definition"),
                "explanation": _pick_explanation(r, difficulty),
                "score": None,
            })

    # ê°„ë‹¨ dedup (term, definition)
    seen = set()
    uniq: List[Dict[str, Any]] = []
    for it in items:
        key = (it.get("term"), it.get("definition"))
        if key not in seen:
            seen.add(key)
            uniq.append(it)

    # top_k ë³´ì¥
    return _format_glossary_md(uniq[:top_k])



