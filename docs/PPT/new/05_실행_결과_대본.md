# 05. 실행 결과 (페이지 48-62 대본)

## 페이지 48: 실행 결과 인트로

**PPT 내용:**

논문 리뷰 챗봇
AI/ML 논문을 누구나 쉽게 이해하고 활용할 수 있는 지능형 챗봇 개발

논문을 읽고 이해하기란 쉽지 않을 뿐더러, 사용자마다 이해도의 차이가 존재할 수 있습니다.
저희는 그러한 정보 격차를 완화하고, 진입장벽을 낮추고자 해당 프로젝트를 기획하게 되었습니다.

**발표 대본:**
```
이제 실제 시스템을 실행한 결과를 보여드리겠습니다.

Streamlit 웹 UI를 통해 사용자가 논문 관련 질문을 하면
AI Agent가 7가지 도구 중 적절한 도구를 자동으로 선택하여
난이도에 맞는 답변을 제공하는 전체 프로세스를 시연하겠습니다.

단일 요청과 다중 요청 처리, 그리고 LLM-as-a-Judge 방식의
성능 평가 결과까지 함께 확인하실 수 있습니다.
```

---

## 페이지 49: 메인 채팅 페이지

**PPT 내용:**

main.py 실행시 Streamlit 채팅창 페이지 이미지 캡처

**발표 대본:**
```
이것이 저희 시스템의 메인 채팅 페이지입니다.

좌측 사이드바에서 Easy 또는 Hard 난이도를 선택할 수 있으며,
중앙의 채팅 인터페이스에서 자연스럽게 질문을 입력할 수 있습니다.

상단에는 현재 선택된 난이도와 세션 정보가 표시되고,
하단에는 대화 기록이 저장됩니다.

모든 대화 내용은 ExperimentManager가 자동으로 추적하여
experiments 폴더에 세션별로 저장됩니다.
```

---

## 페이지 50: 용어집 페이지

**PPT 내용:**

용어집 페이지 화면 캡처

**발표 대본:**
```
우측 탭에서 용어집 페이지로 이동할 수 있습니다.

이 페이지에서는 대화 중 자동으로 추출된 AI/ML 전문 용어들을
난이도별 설명과 함께 확인할 수 있습니다.

사용자가 질문할 때마다 답변에 포함된 전문 용어를
자동으로 감지하여 PostgreSQL glossary 테이블에 저장하고,
이 페이지에서 쉽게 검색하고 학습할 수 있도록 했습니다.
```

---

## 페이지 51: 단일 요청 - RAG 용어집 검색

**PPT 내용:**

RAG 용어집 검색 단일 요청 후 도구 선택 과정 및 LLM 답변 결과 이미지 캡처

**발표 대본:**
```
첫 번째 단일 요청 시연입니다. "BERT가 뭐야?"라는 용어 정의 질문입니다.

Router가 질문을 분석하여 glossary 도구를 선택했고,
glossary 테이블과 glossary_embeddings 컬렉션을
하이브리드 검색하여 BERT의 정의를 찾았습니다.

Easy 모드로 설정했기 때문에
"책을 읽을 때 앞뒤 문맥을 모두 본다"는 식의
쉬운 비유와 일상 언어를 사용하여 설명합니다.

하단의 평가 결과에서 정확도, 관련성, 난이도 적합성,
출처 명시 점수를 실시간으로 확인할 수 있습니다.
```

---

## 페이지 52: 단일 요청 - RAG 논문 검색

**PPT 내용:**

RAG 논문 검색 단일 요청 후 도구 선택 과정 및 LLM 답변 결과 이미지 캡처

**발표 대본:**
```
"Transformer 논문 찾아줘"라는 논문 검색 질문입니다.

Router가 search_paper 도구를 선택하고,
PGVector 벡터 검색으로 유사한 논문 청크를 추출했습니다.

검색된 논문의 제목, 저자, 출판일, 초록 정보를
난이도에 맞게 재구성하여 답변을 생성했고,
출처를 명확히 명시했습니다.

Hard 모드로 전환하면 동일한 질문에 대해
기술 용어와 연구 방법론이 포함된
전문적인 답변을 받을 수 있습니다.
```

---

## 페이지 53: 단일 요청 - Web 논문 검색

**PPT 내용:**

웹 논문 검색 단일 요청 후 도구 선택 과정 및 LLM 답변 결과 이미지 캡처

**발표 대본:**
```
"최신 Diffusion Model 논문 찾아줘"라는 최신 정보 질문입니다.

Router가 "최신"이라는 키워드를 감지하여 web_search 도구를 선택했고,
Tavily API를 통해 arXiv와 웹에서 실시간으로 최신 논문을 검색했습니다.

검색된 논문 정보를 자동으로 PostgreSQL에 저장하고,
청킹 후 PGVector에 임베딩하여 향후 검색에 활용할 수 있도록 했습니다.

이를 통해 LLM의 지식 컷오프 문제를 해결하고
항상 최신 논문 정보를 제공할 수 있습니다.
```

---

## 페이지 54: 단일 요청 - 논문 요약

**PPT 내용:**

논문 요약 단일 요청 후 도구 선택 과정 및 LLM 답변 결과 이미지 캡처

**발표 대본:**
```
"Attention is All You Need 논문 요약해줘"라는 요약 요청입니다.

Router가 summarize 도구를 선택하고,
질문에서 논문 제목을 추출한 후
PostgreSQL에서 해당 논문의 메타데이터를 조회했습니다.

PGVector에서 논문 청크를 모두 검색하여
LLM에게 전달하고 난이도에 맞는 요약을 생성했습니다.

Easy 모드는 핵심 아이디어 3가지를 간단히 요약하고,
Hard 모드는 연구 배경, 제안 방법, 실험 결과, 한계점까지
상세하게 분석합니다.
```

---

## 페이지 55: 단일 요청 - Web 논문 검색 (중복)

**PPT 내용:**

웹 논문 검색 단일 요청 후 도구 선택 과정 및 LLM 답변 결과 이미지 캡처

**발표 대본:**
```
또 다른 웹 논문 검색 시연입니다.

"2024년 최신 LLM 연구 동향"처럼
뉴스나 트렌드를 묻는 질문에서도
web_search 도구가 선택되어 실시간 정보를 제공합니다.

Tavily API는 arXiv뿐만 아니라
학술 블로그, 연구 기관 웹사이트 등
다양한 소스에서 정보를 수집하여
포괄적인 답변을 생성합니다.
```

---

## 페이지 56: 단일 요청 - Text2SQL

**PPT 내용:**

text2sql 단일 요청 후 도구 선택 과정 및 LLM 답변 결과 이미지 캡처

**발표 대본:**
```
"2024년에 발표된 논문 개수는?"이라는 통계 질문입니다.

Router가 text2sql 도구를 선택하고,
자연어 질문을 SQL 쿼리로 변환했습니다.

SELECT COUNT(*) FROM papers WHERE publish_date >= '2024-01-01'
형태의 쿼리가 생성되고, 보안 필터를 거쳐 안전하게 실행됩니다.

DROP, DELETE 같은 위험한 명령은 화이트리스트로 차단되며,
실행 결과를 표 형태로 변환하여 직관적으로 표시합니다.
```

---

## 페이지 57: 단일 요청 - 파일 저장

**PPT 내용:**

파일 저장(하나의 응답 저장/전체 저장) 단일 요청 후 도구 선택 과정 및 LLM 답변 결과 이미지 캡처

**발표 대본:**
```
"대화 내용 저장해줘"라는 파일 저장 요청입니다.

Router가 save_file 도구를 선택하고,
사용자에게 저장 옵션을 제공합니다.

하나의 응답만 저장하거나, 전체 대화 기록을 저장할 수 있으며,
텍스트 파일로 저장되어 나중에 참고할 수 있습니다.

파일 경로를 지정하지 않으면 기본 경로인
experiments/날짜/session_XXX/outputs 폴더에 자동 저장됩니다.
```

---

## 페이지 58: 단일 요청 - 일반 답변

**PPT 내용:**

일반 답변 단일 요청 후 도구 선택 과정 및 LLM 답변 결과 이미지 캡처

**발표 대본:**
```
"안녕하세요"라는 인사말이나 일반 질문입니다.

Router가 특정 도구가 필요 없다고 판단하여
general 도구를 선택했고,
LLM의 자체 지식으로 답변을 생성했습니다.

general 도구는 다른 모든 도구의 최종 Fallback 역할도 수행하여,
어떤 도구도 질문을 처리하지 못했을 때
반드시 답변을 제공할 수 있도록 보장합니다.
```

---

## 페이지 59-61: 다중 요청

**PPT 내용:**

다중 요청 후 도구 선택 과정 및 LLM 답변 결과 이미지 캡처

**발표 대본:**
```
이제 다중 요청 처리를 시연하겠습니다.

"Transformer 논문 찾아서 요약해줘"라는 질문은
두 가지 작업을 요구합니다.

Router가 question_type을 "paper_summary"로 분류하고,
tool_pipeline을 ["search_paper", "summarize"]로 설정했습니다.

먼저 search_paper가 실행되어 논문을 찾고,
그 결과를 state["context"]에 저장합니다.

다음으로 summarize가 실행되어
context의 논문 내용을 요약하여 최종 답변을 생성합니다.

만약 search_paper가 논문을 찾지 못하면
Fallback Chain이 작동하여 web_search로 자동 전환되고,
웹에서 논문을 찾아 요약합니다.

이러한 파이프라인 방식으로
복잡한 다중 요청도 하나의 질문으로 간편하게 처리할 수 있습니다.
```

---

## 페이지 62: 평가 지표

**PPT 내용:**

postgresql 'evaluation_results' 테이블 평가 점수들로 그래프 표시
- 출처명시, 관련성, 난이도 적합성, 정확도, 도구 호출
- 일반 답변, 논문 검색, 용어집, 웹 검색, 논문 요약별 평가 점수

**발표 대본:**
```
마지막으로 LLM-as-a-Judge 방식의 성능 평가 결과입니다.

PostgreSQL의 evaluation_results 테이블에서
모든 답변의 평가 점수를 조회하여 시각화했습니다.

왼쪽 그래프는 6가지 평가 기준별 평균 점수를 보여줍니다.
정확도, 관련성, 난이도 적합성, 출처 명시, 도구 호출 정확성, 응답 시간
모두 8점 이상으로 우수한 성능을 보였습니다.

오른쪽 그래프는 도구별 평균 평가 점수입니다.
논문 검색과 용어집 도구가 가장 높은 점수를 받았으며,
일반 답변 도구도 안정적인 성능을 보여줍니다.

실시간 평가 시스템을 통해 답변 품질을 지속적으로 모니터링하고,
평가 결과를 바탕으로 프롬프트와 도구를 개선할 수 있었습니다.

이러한 정량적 평가를 통해 시스템의 신뢰성을 검증하고,
사용자에게 고품질의 답변을 제공할 수 있음을 확인했습니다.
```

---

## 요약

**실행 결과 파트 완료**

- 페이지 48-62 내용 작성 완료
- 각 페이지마다 PPT 내용과 발표 대본 포함
- 주요 UI 화면 및 실행 시연 설명

**주요 내용:**
1. 실행 결과 인트로 (페이지 48)
2. 메인 채팅 페이지 (페이지 49)
3. 용어집 페이지 (페이지 50)
4. 단일 요청 시연 (페이지 51-58)
   - RAG 용어집 검색
   - RAG 논문 검색
   - Web 논문 검색
   - 논문 요약
   - Text2SQL
   - 파일 저장
   - 일반 답변
5. 다중 요청 처리 (페이지 59-61)
   - 파이프라인 방식
   - Fallback Chain 작동
6. 평가 지표 (페이지 62)
   - LLM-as-a-Judge 평가 결과
   - 도구별 성능 비교

**특징:**
- 모든 도구의 실행 결과를 실제 UI 화면으로 시연
- Easy/Hard 난이도 차이 설명
- 실시간 성능 평가 결과 표시
- 다중 요청 파이프라인 처리 과정 상세 설명
- PostgreSQL 평가 데이터 기반 정량적 성능 분석

**참고:**
- 실제 발표 시에는 Streamlit UI를 라이브로 시연하거나
- 캡처한 화면 이미지를 PPT에 삽입하여 설명
