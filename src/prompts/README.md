# í”„ë¡¬í”„íŠ¸ íŒŒì¼ ë§¤í•‘ ê°€ì´ë“œ

## ğŸ“ í”„ë¡¬í”„íŠ¸ íŒŒì¼ êµ¬ì¡°

```
src/prompts/
â”œâ”€â”€ routing_prompts.json          # ë¼ìš°íŒ… í”„ë¡¬í”„íŠ¸ + Few-shot ì˜ˆì‹œ
â”œâ”€â”€ tool_prompts.json              # 6ê°œ ë„êµ¬ë³„ í”„ë¡¬í”„íŠ¸
â”œâ”€â”€ evaluation_prompts.json        # í‰ê°€ í”„ë¡¬í”„íŠ¸
â”œâ”€â”€ question_generation_prompts.json  # ì§ˆë¬¸ ìƒì„± í”„ë¡¬í”„íŠ¸
â”œâ”€â”€ golden_dataset.json            # Golden Dataset (í…ŒìŠ¤íŠ¸ìš© ì§ˆë¬¸)
â””â”€â”€ README.md                      # ì´ íŒŒì¼
```

---

## ğŸ—ºï¸ í”„ë¡¬í”„íŠ¸ ì‚¬ìš© íŒŒì¼ ë§¤í•‘

### 1. ë¼ìš°íŒ… í”„ë¡¬í”„íŠ¸ (`routing_prompts.json`)

**ì‚¬ìš© ìœ„ì¹˜**: `src/agent/nodes.py:router_node` (lines 44-81)

**í˜„ì¬ ìƒíƒœ**: í•˜ë“œì½”ë”© (JSON íŒŒì¼ë¡œ ì´ë™ í•„ìš”)

**ì‚¬ìš© ë°©ë²•**:
```python
import json

# JSON í”„ë¡¬í”„íŠ¸ ë¡œë“œ
with open("src/prompts/routing_prompts.json", "r", encoding="utf-8") as f:
    routing_data = json.load(f)

routing_prompt = routing_data["routing_prompt"]
few_shot_examples = routing_data["few_shot_examples"]
```

**í¬í•¨ ë‚´ìš©**:
- 6ê°œ ë„êµ¬ ì„¤ëª… ë° ì‚¬ìš© ì‹œë‚˜ë¦¬ì˜¤
- ë„êµ¬ë³„ í‚¤ì›Œë“œ ë¦¬ìŠ¤íŠ¸
- ì¤‘ìš” ê·œì¹™ (ë¹„êµ ì§ˆë¬¸ â†’ general ë“±)
- Few-shot ì˜ˆì‹œ 10ê°œ

---

### 2. ë„êµ¬ë³„ í”„ë¡¬í”„íŠ¸ (`tool_prompts.json`)

#### 2.1 ì¼ë°˜ ë‹µë³€ í”„ë¡¬í”„íŠ¸

**ì‚¬ìš© ìœ„ì¹˜**: `src/tools/general_answer.py` (lines 37-50)

**í˜„ì¬ ìƒíƒœ**: í•˜ë“œì½”ë”© (JSON íŒŒì¼ë¡œ ì´ë™ í•„ìš”)

**ì‚¬ìš© ë°©ë²•**:
```python
import json

with open("src/prompts/tool_prompts.json", "r", encoding="utf-8") as f:
    tool_prompts = json.load(f)

# ë‚œì´ë„ë³„ í”„ë¡¬í”„íŠ¸
difficulty = "easy"  # or "hard"
system_prompt = tool_prompts["general_answer_prompts"][difficulty]["system_prompt"]
```

**í¬í•¨ ë‚´ìš©**:
- Easy ëª¨ë“œ ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸
- Hard ëª¨ë“œ ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸
- ê° ë‚œì´ë„ë³„ ì˜ˆì‹œ

---

#### 2.2 ì›¹ ê²€ìƒ‰ í”„ë¡¬í”„íŠ¸

**ì‚¬ìš© ìœ„ì¹˜**: `src/tools/web_search.py` (lines 119-147)

**í˜„ì¬ ìƒíƒœ**: í•˜ë“œì½”ë”© (JSON íŒŒì¼ë¡œ ì´ë™ í•„ìš”)

**ì‚¬ìš© ë°©ë²•**:
```python
import json

with open("src/prompts/tool_prompts.json", "r", encoding="utf-8") as f:
    tool_prompts = json.load(f)

# ë‚œì´ë„ë³„ í”„ë¡¬í”„íŠ¸
difficulty = "easy"  # or "hard"
system_prompt = tool_prompts["web_search_prompts"][difficulty]["system_prompt"]
user_prompt_template = tool_prompts["web_search_prompts"][difficulty]["user_prompt_template"]

# ì‚¬ìš© ì˜ˆì‹œ
user_prompt = user_prompt_template.format(
    formatted_results=formatted_results,
    question=question
)
```

**í¬í•¨ ë‚´ìš©**:
- Easy/Hard ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸
- ì‚¬ìš©ì í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ (ê²€ìƒ‰ ê²°ê³¼ í¬í•¨)

---

#### 2.3 ë…¼ë¬¸ ìš”ì•½ í”„ë¡¬í”„íŠ¸

**ì‚¬ìš© ìœ„ì¹˜**: `src/tools/summarize.py`
- ì œëª© ì¶”ì¶œ: lines 58-63
- ìš”ì•½ í”„ë¡¬í”„íŠ¸: lines 157-168

**í˜„ì¬ ìƒíƒœ**: í•˜ë“œì½”ë”© (JSON íŒŒì¼ë¡œ ì´ë™ í•„ìš”)

**ì‚¬ìš© ë°©ë²•**:
```python
import json

with open("src/prompts/tool_prompts.json", "r", encoding="utf-8") as f:
    tool_prompts = json.load(f)

# ì œëª© ì¶”ì¶œ í”„ë¡¬í”„íŠ¸
title_extraction_template = tool_prompts["summarize_prompts"]["title_extraction"]["template"]
extract_prompt = title_extraction_template.format(question=question)

# ìš”ì•½ í”„ë¡¬í”„íŠ¸
difficulty = "easy"  # or "hard"
system_prompt = tool_prompts["summarize_prompts"][difficulty]["system_prompt"]
summary_template = tool_prompts["summarize_prompts"][difficulty]["summary_template"]

summary_prompt = summary_template.format(
    system_prompt=system_prompt,
    title=title,
    authors=authors,
    publish_date=publish_date,
    abstract=abstract,
    combined_text=combined_text
)
```

**í¬í•¨ ë‚´ìš©**:
- ë…¼ë¬¸ ì œëª© ì¶”ì¶œ í”„ë¡¬í”„íŠ¸
- Easy/Hard ìš”ì•½ í”„ë¡¬í”„íŠ¸
- ìš”ì•½ í…œí”Œë¦¿

---

#### 2.4 ìš©ì–´ì§‘ í”„ë¡¬í”„íŠ¸

**ì‚¬ìš© ìœ„ì¹˜**: `src/tools/glossary.py`

**í˜„ì¬ ìƒíƒœ**: êµ¬í˜„ í•„ìš”

**ì‚¬ìš© ë°©ë²•**:
```python
import json

with open("src/prompts/tool_prompts.json", "r", encoding="utf-8") as f:
    tool_prompts = json.load(f)

# ë‚œì´ë„ë³„ í”„ë¡¬í”„íŠ¸
difficulty = "easy"  # or "hard"
system_prompt = tool_prompts["glossary_prompts"][difficulty]["system_prompt"]
```

**í¬í•¨ ë‚´ìš©**:
- Easy/Hard ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸

---

#### 2.5 ë…¼ë¬¸ ê²€ìƒ‰ í”„ë¡¬í”„íŠ¸

**ì‚¬ìš© ìœ„ì¹˜**: `src/tools/search_paper.py`

**í˜„ì¬ ìƒíƒœ**: êµ¬í˜„ í•„ìš”

**ì‚¬ìš© ë°©ë²•**:
```python
import json

with open("src/prompts/tool_prompts.json", "r", encoding="utf-8") as f:
    tool_prompts = json.load(f)

# ë‚œì´ë„ë³„ í”„ë¡¬í”„íŠ¸
difficulty = "easy"  # or "hard"
system_prompt = tool_prompts["search_paper_prompts"][difficulty]["system_prompt"]
```

**í¬í•¨ ë‚´ìš©**:
- Easy/Hard ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸

---

#### 2.6 íŒŒì¼ ì €ì¥ í”„ë¡¬í”„íŠ¸

**ì‚¬ìš© ìœ„ì¹˜**: `src/tools/file_save.py` ë˜ëŠ” `src/tools/save_file.py`

**í˜„ì¬ ìƒíƒœ**: êµ¬í˜„ í•„ìš”

**ì‚¬ìš© ë°©ë²•**:
```python
import json

with open("src/prompts/tool_prompts.json", "r", encoding="utf-8") as f:
    tool_prompts = json.load(f)

# ë©”ì‹œì§€
confirmation_msg = tool_prompts["save_file_prompts"]["confirmation_message"]
success_msg = tool_prompts["save_file_prompts"]["success_message"].format(filepath=filepath)
error_msg = tool_prompts["save_file_prompts"]["error_message"].format(error=str(e))
```

**í¬í•¨ ë‚´ìš©**:
- í™•ì¸ ë©”ì‹œì§€
- ì„±ê³µ ë©”ì‹œì§€
- ì˜¤ë¥˜ ë©”ì‹œì§€

---

### 3. í‰ê°€ í”„ë¡¬í”„íŠ¸ (`evaluation_prompts.json`)

**ì‚¬ìš© ìœ„ì¹˜**: `src/evaluation/evaluator.py`

**í˜„ì¬ ìƒíƒœ**: êµ¬í˜„ í•„ìš”

**ì‚¬ìš© ë°©ë²•**:
```python
import json
from langchain.prompts import PromptTemplate

with open("src/prompts/evaluation_prompts.json", "r", encoding="utf-8") as f:
    eval_data = json.load(f)

# í‰ê°€ í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿
prompt_template = PromptTemplate(
    template=eval_data["evaluation_prompt"]["template"],
    input_variables=eval_data["evaluation_prompt"]["input_variables"]
)

# í”„ë¡¬í”„íŠ¸ í¬ë§·íŒ…
prompt = prompt_template.format(
    question=question,
    answer=answer,
    reference_docs=reference_docs,
    difficulty=difficulty
)
```

**í¬í•¨ ë‚´ìš©**:
- í‰ê°€ í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿
- í‰ê°€ ê¸°ì¤€ (ì •í™•ë„, ê´€ë ¨ì„±, ë‚œì´ë„ ì í•©ì„±, ì¶œì²˜ ëª…ì‹œ)
- í‰ê°€ ì˜ˆì‹œ

---

### 4. ì§ˆë¬¸ ìƒì„± í”„ë¡¬í”„íŠ¸ (`question_generation_prompts.json`)

**ì‚¬ìš© ìœ„ì¹˜**: í…ŒìŠ¤íŠ¸ ìŠ¤í¬ë¦½íŠ¸ ë˜ëŠ” ì§ˆë¬¸ ìë™ ìƒì„± ë„êµ¬

**í˜„ì¬ ìƒíƒœ**: êµ¬í˜„ í•„ìš”

**ì‚¬ìš© ë°©ë²•**:
```python
import json
from langchain.prompts import PromptTemplate

with open("src/prompts/question_generation_prompts.json", "r", encoding="utf-8") as f:
    qgen_data = json.load(f)

# ì§ˆë¬¸ ìƒì„± í”„ë¡¬í”„íŠ¸
prompt_template = PromptTemplate(
    template=qgen_data["question_generation_prompt"]["template"],
    input_variables=qgen_data["question_generation_prompt"]["input_variables"]
)

# ì§ˆë¬¸ ìƒì„±
prompt = prompt_template.format(
    title=title,
    authors=authors,
    abstract=abstract
)

response = llm.invoke(prompt)
questions = json.loads(response.content)
```

**í¬í•¨ ë‚´ìš©**:
- ì§ˆë¬¸ ìƒì„± í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿
- ì§ˆë¬¸ í…œí”Œë¦¿ (Easy/Hard)
- ë„êµ¬ë³„ ì§ˆë¬¸ í…œí”Œë¦¿
- ìƒì„± ì˜ˆì‹œ

---

### 5. Golden Dataset (`golden_dataset.json`)

**ì‚¬ìš© ìœ„ì¹˜**: í…ŒìŠ¤íŠ¸ ìŠ¤í¬ë¦½íŠ¸, í‰ê°€ ìŠ¤í¬ë¦½íŠ¸

**í˜„ì¬ ìƒíƒœ**: 15ê°œ ì§ˆë¬¸ í¬í•¨

**ì‚¬ìš© ë°©ë²•**:
```python
import json

with open("src/prompts/golden_dataset.json", "r", encoding="utf-8") as f:
    dataset = json.load(f)

# ì „ì²´ ì§ˆë¬¸ ëª©ë¡
questions = dataset["golden_dataset"]

# í…ŒìŠ¤íŠ¸ ì‹¤í–‰
for item in questions:
    question = item["question"]
    expected_tool = item["expected_tool"]
    expected_keywords = item["expected_answer_keywords"]

    # Agent ì‹¤í–‰
    result = agent.invoke({"question": question, "difficulty": item["difficulty"]})

    # ë¼ìš°íŒ… ì •í™•ë„ ê²€ì¦
    actual_tool = result["tool_choice"]
    assert actual_tool == expected_tool, f"Expected {expected_tool}, got {actual_tool}"
```

**í¬í•¨ ë‚´ìš©**:
- 15ê°œ í…ŒìŠ¤íŠ¸ ì§ˆë¬¸
- ê° ì§ˆë¬¸ì˜ ë‚œì´ë„, ì˜ˆìƒ ë„êµ¬, ì˜ˆìƒ í‚¤ì›Œë“œ
- ì§ˆë¬¸ ë¶„í¬ ë©”íƒ€ë°ì´í„°

---

## ğŸ“Š í”„ë¡¬í”„íŠ¸ íŒŒì¼ í†µê³„

| íŒŒì¼ëª… | í”„ë¡¬í”„íŠ¸ ìˆ˜ | ì‚¬ìš© íŒŒì¼ ìˆ˜ |
|-------|-----------|-----------|
| routing_prompts.json | 1 + 10 ì˜ˆì‹œ | 1 (nodes.py) |
| tool_prompts.json | 12 (6ê°œ ë„êµ¬ Ã— 2 ë‚œì´ë„) | 6 (ê° ë„êµ¬ íŒŒì¼) |
| evaluation_prompts.json | 1 | 1 (evaluator.py) |
| question_generation_prompts.json | 1 | 1 (í…ŒìŠ¤íŠ¸ ìŠ¤í¬ë¦½íŠ¸) |
| golden_dataset.json | 15 ì§ˆë¬¸ | 1 (í…ŒìŠ¤íŠ¸ ìŠ¤í¬ë¦½íŠ¸) |

---

## ğŸ”§ êµ¬í˜„ ìš°ì„ ìˆœìœ„

### Phase 1: ë¼ìš°íŒ… í”„ë¡¬í”„íŠ¸ (ìµœìš°ì„ )
1. `src/agent/nodes.py:router_node` ìˆ˜ì •
   - JSON íŒŒì¼ ë¡œë“œ
   - Few-shot í”„ë¡¬í”„íŠ¸ ì ìš©
2. ë¼ìš°íŒ… ì •í™•ë„ í…ŒìŠ¤íŠ¸ (Golden Dataset ì‚¬ìš©)

### Phase 2: ë„êµ¬ë³„ í”„ë¡¬í”„íŠ¸
1. `src/tools/general_answer.py` ìˆ˜ì •
2. `src/tools/web_search.py` ìˆ˜ì •
3. `src/tools/summarize.py` ìˆ˜ì •
4. `src/tools/glossary.py` ìˆ˜ì • (êµ¬í˜„ í•„ìš”)
5. `src/tools/search_paper.py` ìˆ˜ì • (êµ¬í˜„ í•„ìš”)
6. `src/tools/save_file.py` ìˆ˜ì • (êµ¬í˜„ í•„ìš”)

### Phase 3: í‰ê°€ ì‹œìŠ¤í…œ
1. `src/evaluation/evaluator.py` êµ¬í˜„
2. í‰ê°€ ê²°ê³¼ DB ì €ì¥ ë¡œì§
3. í‰ê°€ ê²°ê³¼ ì‹œê°í™” (Streamlit)

### Phase 4: í…ŒìŠ¤íŠ¸ ìë™í™”
1. ì§ˆë¬¸ ìƒì„± ìŠ¤í¬ë¦½íŠ¸
2. Golden Dataset í…ŒìŠ¤íŠ¸ ìŠ¤í¬ë¦½íŠ¸
3. ë¼ìš°íŒ… ì •í™•ë„ ì¸¡ì • ìŠ¤í¬ë¦½íŠ¸

---

## ğŸ§ª í…ŒìŠ¤íŠ¸ ê°€ì´ë“œ

### ë¼ìš°íŒ… ì •í™•ë„ í…ŒìŠ¤íŠ¸

```python
# scripts/test_routing_accuracy.py

import json
from src.agent.graph import create_agent_graph

# Golden Dataset ë¡œë“œ
with open("src/prompts/golden_dataset.json", "r", encoding="utf-8") as f:
    dataset = json.load(f)

questions = dataset["golden_dataset"]
agent = create_agent_graph()

# í…ŒìŠ¤íŠ¸ ì‹¤í–‰
correct = 0
total = len(questions)

for item in questions:
    result = agent.invoke({
        "question": item["question"],
        "difficulty": item["difficulty"]
    })

    if result["tool_choice"] == item["expected_tool"]:
        correct += 1
        print(f"âœ… {item['question']}: {item['expected_tool']}")
    else:
        print(f"âŒ {item['question']}: Expected {item['expected_tool']}, Got {result['tool_choice']}")

# ì •í™•ë„ ê³„ì‚°
accuracy = correct / total * 100
print(f"\në¼ìš°íŒ… ì •í™•ë„: {accuracy:.2f}% ({correct}/{total})")
```

---

## ğŸ“ í”„ë¡¬í”„íŠ¸ ìˆ˜ì • ê°€ì´ë“œ

### í”„ë¡¬í”„íŠ¸ ìˆ˜ì • ì‹œ ì£¼ì˜ì‚¬í•­

1. **JSON í˜•ì‹ ìœ ì§€**
   - ì˜¬ë°”ë¥¸ JSON ë¬¸ë²• ì‚¬ìš©
   - ë¬¸ìì—´ ë‚´ ì¤„ë°”ê¿ˆì€ `\n` ì‚¬ìš©

2. **í…œí”Œë¦¿ ë³€ìˆ˜ í™•ì¸**
   - `{question}`, `{difficulty}` ë“± ë³€ìˆ˜ëª… ì¼ì¹˜ í™•ì¸
   - ëª¨ë“  ë³€ìˆ˜ê°€ í¬ë§·íŒ… ì‹œ ì „ë‹¬ë˜ëŠ”ì§€ í™•ì¸

3. **ë‚œì´ë„ë³„ í”„ë¡¬í”„íŠ¸**
   - Easy: ì‰¬ìš´ ì–¸ì–´, ë¹„ìœ , ê°„ë‹¨ ìš”ì•½
   - Hard: ê¸°ìˆ  ìš©ì–´, ìˆ˜ì‹, ë³µì¡ë„, ë…¼ë¬¸ ë¹„êµ

4. **Few-shot ì˜ˆì‹œ**
   - ê° ë„êµ¬ë³„ ìµœì†Œ 2ê°œ ì´ìƒ
   - ë‹¤ì–‘í•œ ì§ˆë¬¸ íŒ¨í„´ í¬í•¨

5. **ë²„ì „ ê´€ë¦¬**
   - í”„ë¡¬í”„íŠ¸ ìˆ˜ì • ì‹œ git commit
   - ì„±ëŠ¥ ê°œì„  ì—¬ë¶€ ì¸¡ì • (Golden Dataset í…ŒìŠ¤íŠ¸)

---

## ğŸ”— ì°¸ê³  ë¬¸ì„œ

- [ë‹´ë‹¹ì—­í• _04_ì„ì˜ˆìŠ¬_í”„ë¡¬í”„íŠ¸_ì—”ì§€ë‹ˆì–´ë§.md](../../docs/roles/ë‹´ë‹¹ì—­í• _04_ì„ì˜ˆìŠ¬_í”„ë¡¬í”„íŠ¸_ì—”ì§€ë‹ˆì–´ë§.md)
- [15_í”„ë¡¬í”„íŠ¸_ì—”ì§€ë‹ˆì–´ë§.md](../../docs/PRD/15_í”„ë¡¬í”„íŠ¸_ì—”ì§€ë‹ˆì–´ë§.md)
- [ë©˜í† ë§ ë¬¸ì„œ](../../docs/minutes/20251030/20251030_ë©˜í† ë§.md) - í”„ë¡¬í”„íŠ¸ ì¸ì‚¬ì´íŠ¸ (lines 417-553)

---

## ğŸ“ ë¬¸ì˜

í”„ë¡¬í”„íŠ¸ ê´€ë ¨ ë¬¸ì˜: ì„ì˜ˆìŠ¬ (@ì„ì˜ˆìŠ¬)

---
