# 06. 도구 시스템 (7가지 도구)

## 📋 문서 정보
- **작성일**: 2025-11-03
- **작성자**: 최현화[팀장]
- **시스템명**: 도구 시스템
- **구현 파일**: `src/tools/` (7개 파일)
- **우선순위**: ⭐ (보통 - 기능 확장)
- **참고 문서**: [PRD/자료조사_05_AI_Agent_도구.md](../PRD/자료조사_05_AI_Agent_도구.md)

---

## 📌 시스템 개요

### 목적 및 배경

도구 시스템은 **AI Agent가 다양한 질문 유형에 대응하기 위해 호출할 수 있는 7가지 도구**를 제공하는 시스템입니다. `src/tools/` 폴더에 각각 독립된 모듈로 구현되어 있으며, LangGraph의 Router 노드가 질문을 분석하여 적절한 도구를 자동으로 선택합니다.

### 도구(Tool)의 개념

**도구(Tool)**는 AI Agent가 특정 작업을 수행하기 위해 호출할 수 있는 **함수**입니다:

- LLM이 사용자 질문을 분석하여 어떤 도구를 사용할지 판단
- 필요한 도구의 **arguments(매개변수)**를 추출
- 도구를 실행하고 결과를 받아 최종 답변 생성

**예시 라우팅 패턴:**
- "안녕하세요" → `general_answer` 도구 사용
- "Transformer 논문 설명해줘" → `search_paper` 도구 사용
- "2025년 최신 LLM 논문은?" → `web_search` 도구 사용

### OT 자료 요구사항

| 요구사항 | 충족 여부 | 구현 내용 |
|---------|-----------|-----------|
| **웹 검색 기능** | ✅ 필수 | Tavily Search API 통합 |
| **파일 저장 기능** | ✅ 필수 | ExperimentManager 통합 저장 |
| **3개 이상의 도구** | ✅ 필수 | 총 7개 도구 구현 |
| **직접 구현 도구** | ✅ 필수 | RAG, 용어집, 요약, Text-to-SQL, 파일 저장 |
| **RAG 기능** | ✅ 선택 (가산점) | PostgreSQL + pgvector |
| **Text-to-SQL** | ✅ 선택 (가산점) | 자연어 → SQL 변환 |

---

## 🏗️ 7가지 도구 개요

### 도구 목록

| 도구 | 파일 | 설명 | DB 연동 | 난이도 지원 |
|------|------|------|---------|-------------|
| **일반 답변** | `general_answer.py` | LLM 직접 호출 | 없음 | ✅ |
| **RAG 검색** | `search_paper.py` | 논문 DB 검색 (Top-5) | PostgreSQL + pgvector | ✅ |
| **용어집 검색** | `glossary.py` | 용어 정의 조회 | PostgreSQL | ✅ |
| **웹 검색** | `web_search.py` | Tavily API | 없음 | ✅ |
| **논문 요약** | `summarize.py` | 논문 전체 요약 | PostgreSQL + pgvector | ✅ |
| **Text-to-SQL** | `text2sql.py` | 논문 통계 조회 | PostgreSQL | ✅ |
| **파일 저장** | `save_file.py` | 결과물 저장 | ExperimentManager | ❌ |

### 도구별 라우팅 패턴

| 사용자 질문 예시 | 선택되는 도구 | 선택 이유 |
|-----------------|---------------|----------|
| "안녕하세요" | `general_answer` | 간단한 인사 |
| "Transformer 논문 설명해줘" | `search_paper` | 로컬 DB 논문 검색 |
| "2025년 최신 LLM 논문은?" | `web_search` | 최신 정보 필요 |
| "Attention이 뭐야?" | `glossary` | 용어 정의 질문 |
| "BERT 논문 요약해줘" | `summarize` | 특정 논문 요약 |
| "2024년 논문 몇 편?" | `text2sql` | 통계 조회 |
| "이 내용 저장해줘" | `save_file` | 파일 저장 요청 |

---

## 🔧 도구 1: 일반 답변 (General Answer)

### 기능

- LLM 자체 지식으로 직접 답변
- 인사, 일반 상식 질문 처리
- 난이도별 시스템 프롬프트 적용

### 사용 시점

- "안녕하세요"
- "RAG가 뭐야?"
- "AI Agent가 뭐야?"

### 구현 요소

**LLM 선택:**
- **Easy 모드**: Solar Pro2 (빠르고 경제적)
- **Hard 모드**: GPT-5 (전문적 답변)

**프롬프트 전략:**
- Easy: "초심자도 이해할 수 있도록 쉽고 명확하게"
- Hard: "기술적인 세부사항을 포함하여 정확하고 전문적으로"

**특징:**
- DB 연동 없음 (가장 빠른 응답)
- Temperature: 0.7 (자연스러운 답변)
- ExperimentManager 통합 로깅

---

## 🔧 도구 2: RAG 검색 (Search Paper)

### 기능

- 논문 DB에서 유사도 검색 (Top-5)
- PostgreSQL papers 테이블 조회
- 난이도별 프롬프트 구성

### 사용 시점

- "Transformer 논문 설명해줘"
- "BERT와 GPT의 차이점은?"
- "Attention 메커니즘이 뭐야?"

### DB 연동

**Vector DB (pgvector):**
- 테이블: `paper_chunks`
- 임베딩 모델: `text-embedding-3-small`
- 검색 방식: 코사인 유사도 (Top-5)

**PostgreSQL:**
- 테이블: `papers`
- 메타데이터: title, authors, publish_date, citation_count

### 처리 흐름

```
질문 → 임베딩 변환 → pgvector 검색 (Top-5) → 컨텍스트 구성 → LLM 답변 생성
```

### LLM 설정

- 모델: GPT-5 (복잡한 논문 설명)
- Temperature: 0.7
- 프롬프트: 참고 논문 + 질문

---

## 🔧 도구 3: 용어집 검색 (Glossary)

### 기능

- PostgreSQL glossary 테이블 검색
- 난이도별 설명 제공 (Easy/Hard)
- LLM 기반 용어 추출

### 사용 시점

- "Attention이 뭐야?"
- "Fine-tuning이란?"
- "BLEU 스코어 설명해줘"

### DB 스키마

**glossary 테이블:**
```sql
CREATE TABLE glossary (
    term VARCHAR PRIMARY KEY,
    definition TEXT,
    easy_explanation TEXT,
    hard_explanation TEXT,
    category VARCHAR
);
```

### 처리 흐름

```
질문 → LLM 용어 추출 → PostgreSQL 검색 → 난이도별 설명 선택 → 답변 반환
```

### 난이도별 설명

- **Easy**: `easy_explanation` 필드 사용 (전문 용어 최소화)
- **Hard**: `hard_explanation` 필드 사용 (기술적 세부사항)
- **Fallback**: 기본 `definition` 사용

---

## 🔧 도구 4: 웹 검색 (Web Search)

### 기능

- Tavily Search API 호출
- 검색 결과 LLM 정리
- 난이도별 프롬프트 적용

### 사용 시점

- "2025년 최신 LLM 논문은?"
- "GPT-5가 나왔어?"
- "오늘 arXiv에 올라온 논문 찾아줘"

### API 설정

**Tavily Search API:**
- 최대 검색 결과: 5개
- API 키: `.env` 파일 필수 (`TAVILY_API_KEY`)

**또는 DuckDuckGo (무료 대안):**
- `langchain.tools.DuckDuckGoSearchRun` 사용 가능

### 처리 흐름

```
질문 → Tavily API 호출 → 검색 결과 포맷팅 → LLM 정리 → 답변 반환
```

### arXiv 논문 자동 저장 기능

**ArxivPaperHandler 통합 (신규 기능):**

웹 검색 결과에서 arXiv 논문을 발견하면 자동으로 다운로드하고 DB에 저장합니다.

**처리 워크플로우:**
```
검색 결과 → arXiv URL 감지 → ArxivPaperHandler 호출
    ↓
1. arXiv ID 파싱 (예: "2301.12345")
    ↓
2. arXiv API 메타데이터 추출 (제목, 저자, 초록, 발행일)
    ↓
3. PDF 다운로드 (data/raw/ 폴더)
    ↓
4. PDF 텍스트 추출 (pypdf/PyPDF2/pdfplumber)
    ↓
5. papers 테이블 저장 (중복 체크 포함)
    ↓
6. 텍스트 청킹 (1000자 단위)
    ↓
7. 임베딩 생성 및 pgvector 저장
    ↓
답변에 논문 링크 포함 + DB 저장 완료
```

**구현 파일:**
- `src/tools/arxiv_handler.py`: ArxivPaperHandler 클래스
- `src/tools/web_search.py`: ArxivPaperHandler 통합 로직

**주요 메서드:**
- `parse_arxiv_url()`: URL에서 arXiv ID 추출
- `fetch_arxiv_metadata()`: arXiv API 호출
- `download_pdf()`: PDF 다운로드
- `extract_text_from_pdf()`: pypdf로 텍스트 추출
- `save_to_papers_table()`: PostgreSQL papers 테이블 저장
- `save_to_pgvector()`: 임베딩 생성 및 벡터 DB 저장
- `process_arxiv_paper()`: 전체 파이프라인 실행

**장점:**
- 웹 검색 시 자동으로 논문 DB 확장
- 향후 RAG 검색에서 해당 논문 사용 가능
- 중복 체크로 불필요한 재다운로드 방지
- 에러 발생 시에도 웹 검색 결과는 정상 반환

### 특화 검색 (선택)

- **arXiv API**: 논문 전문 검색 사이트 특화 ✅ **구현됨** (자동 저장)
- **Google Scholar API**: 학술 논문 전용 검색

---

## 🔧 도구 5: 논문 요약 (Summarize)

### 기능

- PostgreSQL papers 테이블 검색
- pgvector 논문 전체 청크 조회
- LangChain load_summarize_chain 통합

### 사용 시점

- "Attention is All You Need 논문 요약해줘"
- "BERT 논문의 핵심 내용은?"
- "이 논문의 주요 기여도는 뭐야?"

### DB 연동

**PostgreSQL:**
- 논문 메타데이터 조회 (title → paper_id)

**pgvector:**
- `paper_id` 필터로 논문 전체 청크 조회 (Top-10)
- 청크를 결합하여 전체 논문 컨텍스트 구성

### 요약 체인

**LangChain load_summarize_chain:**
- **chain_type**: "stuff" (모든 청크를 한 번에 전달)
- **다른 옵션**: "map_reduce", "refine" (대용량 논문)

### 난이도별 프롬프트

**Easy 모드:**
- 전문 용어 풀어서 설명
- 핵심 아이디어 3가지
- 실생활 비유 포함

**Hard 모드:**
- 기술적 세부사항 포함
- 수식 및 알고리즘 설명
- 관련 연구와의 비교

### LLM 설정

- 모델: GPT-5 (정확한 요약)
- Temperature: 0.0 (일관성 중시)

---

## 🔧 도구 6: 파일 저장 (Save File)

### 기능

- 답변 내용을 파일로 저장
- ExperimentManager.save_output() 통합
- `experiments/{날짜}/{날짜}_{시간}_session_XXX/outputs/` 폴더에 저장

### 사용 시점

- "이 요약 내용 파일로 저장해줘"
- "오늘 대화 내용 저장하고 싶어"
- "찾은 논문 리스트 파일로 만들어줘"

### 저장 구조

**파일 경로 생성:**
```
experiments/20251103/20251103_103015_session_001/outputs/
└── response_20251103_103015.txt
```

**자동 파일명 생성:**
- 패턴: `response_{YYYYMMDD}_{HHMMSS}.txt`
- 사용자 지정 파일명도 지원

### ExperimentManager 통합

```python
exp_manager.save_output(filename, content)
```

**장점:**
- 세션별 자동 폴더 관리
- 파일 경로 자동 추적 (metadata.json)
- 로깅 통합

---

## 🔧 도구 7: Text-to-SQL (논문 통계 조회)

### 기능

- 자연어 질문을 SQL 쿼리로 자동 변환
- PostgreSQL papers 테이블 통계 조회
- 화이트리스트 기반 보안 검증
- Markdown 표 형식 결과 반환

### 사용 시점

- "2024년에 발표된 논문 개수는?"
- "카테고리별 논문 수를 보여줘"
- "AI 관련 논문 중 가장 인용이 많은 건?"
- "저자가 3명 이상인 논문은 몇 편이야?"
- "2021년 이후 발표된 논문들의 평균 인용수는?"

### 보안 기능

**화이트리스트 기반 접근 제어:**

Text-to-SQL은 보안을 위해 **허용된 테이블과 컬럼만** 사용합니다.

**허용 테이블:**
- `papers` (논문 메타데이터)

**허용 컬럼:**
```python
{
    "paper_id", "title", "authors", "publish_date",
    "source", "url", "category", "citation_count",
    "abstract", "created_at", "updated_at"
}
```

**금지 패턴 (자동 차단):**
- **DDL 명령**: `DROP`, `ALTER`, `TRUNCATE`, `CREATE`
- **DML 명령**: `INSERT`, `UPDATE`, `DELETE`
- **권한 명령**: `GRANT`, `REVOKE`
- **기타**: `COPY`, SQL 주석 (`--`, `/* */`)

**읽기 전용 쿼리만 허용:**
- `SELECT` 쿼리만 허용
- `WITH` (CTE) 허용
- 집계가 아닌 결과는 자동으로 `LIMIT 100` 적용

### DB 연동

**PostgreSQL papers 테이블:**
```sql
CREATE TABLE papers (
    paper_id SERIAL PRIMARY KEY,
    title TEXT NOT NULL,
    authors TEXT,
    publish_date DATE,
    source VARCHAR(50),
    url TEXT,
    category VARCHAR(100),
    citation_count INTEGER,
    abstract TEXT,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);
```

**스키마 자동 추출:**
- `information_schema.columns`에서 허용 테이블/컬럼만 추출
- LLM에게 스키마 정보 제공하여 정확한 SQL 생성

### 처리 흐름

```
사용자 질문 → 스키마 정보 수집 → LLM SQL 생성 → 보안 검증
    ↓
SQL 추출 (코드펜스 제거) → 금지 패턴 검사 → 화이트리스트 검증
    ↓
LIMIT 자동 추가 → EXPLAIN 검증 → SQL 실행 → Markdown 표 생성
    ↓
결과 반환 + query_logs 테이블 로깅
```

### LLM 설정

**모델 선택 (config 기반):**
- 기본 모델: **Solar Pro2** (`configs/model_config.yaml`)
- Provider: `solar` 또는 `openai`
- Temperature: **0.0** (결정론적 SQL 생성)

**Few-shot 학습:**

Text-to-SQL은 5개의 Few-shot 예시를 LLM에게 제공하여 정확한 SQL 생성을 유도합니다.

| 질문 | 생성 SQL |
|------|---------|
| "2024년에 발표된 논문 개수는?" | `SELECT COUNT(*) FROM papers WHERE EXTRACT(YEAR FROM publish_date)=2024;` |
| "카테고리별 논문 수를 보여줘" | `SELECT category, COUNT(*) FROM papers GROUP BY category ORDER BY COUNT(*) DESC LIMIT 100;` |
| "2021년 이후 논문의 평균 인용수는?" | `SELECT AVG(citation_count) FROM papers WHERE publish_date >= DATE '2021-01-01';` |
| "AI 관련 논문 중 가장 인용이 많은 건?" | `SELECT title, citation_count FROM papers WHERE category ILIKE '%AI%' ORDER BY citation_count DESC LIMIT 1;` |
| "저자가 3명 이상인 논문은 몇 편?" | `SELECT COUNT(*) FROM papers WHERE array_length(string_to_array(authors, ','), 1) >= 3;` |

**프롬프트 전략:**
```python
"""You are a careful Text-to-SQL generator for PostgreSQL.

Rules:
- Output ONLY a single SQL query with no extra prose.
- SELECT / WITH (CTE) only. No writes/DDL/GRANT.
- Use only whitelisted table and columns.
- Prefer COUNT/SUM/AVG/MAX/MIN for numeric answers.
- For year filters, use EXTRACT(YEAR FROM publish_date).
- Add LIMIT 100 when returning rows (non-aggregate).
"""
```

### 안전성 검증

**1. SQL 추출:**
- LLM 응답에서 코드펜스 제거 (```` ```sql ... ``` ````)
- 불필요한 주석/문장 제거

**2. 금지 패턴 검사:**
```python
_FORBIDDEN_PATTERNS = [
    r"\bdrop\b", r"\balter\b", r"\btruncate\b", r"\binsert\b",
    r"\bupdate\b", r"\bdelete\b", r"\bgrant\b", r"\brevoke\b",
    r"\bcopy\b", r"\bcreate\b", r";\s*--", r"/\*", r"\*/"
]
```

**3. 화이트리스트 검증:**
- `FROM`/`JOIN` 절에서 테이블 추출
- `ALLOWED_TABLES`에 포함되지 않은 테이블은 즉시 차단
- 괄호 안의 `FROM` (예: `EXTRACT(YEAR FROM ...)`)은 무시

**4. LIMIT 자동 추가:**
- 집계 함수 (`COUNT`, `AVG`, `SUM` 등)가 없으면 자동으로 `LIMIT 100` 추가
- 이미 `LIMIT`이 있으면 그대로 유지

**5. EXPLAIN 검증:**
- 실행 전 `EXPLAIN` 명령으로 실행 계획 확인
- 너무 큰 Seq Scan 감지 시 차단 가능 (현재는 통과)

### 결과 반환 형식

**성공 시:**
```markdown
**질문**: 2024년에 발표된 논문 개수는?

**생성된 SQL**:
```sql
SELECT COUNT(*) AS paper_count FROM papers WHERE EXTRACT(YEAR FROM publish_date)=2024;
```

**결과**:

paper_count
---
42
```

**실패 시:**
```markdown
**질문**: papers 테이블 삭제해줘

**생성된 SQL(검증 전)**:
```sql
DROP TABLE papers;
```

요청을 처리하는 중 오류가 발생했습니다:
```
ValueError: 금지된 SQL 패턴이 감지되었습니다.
```
```

### 로깅

**query_logs 테이블:**
- 모든 Text-to-SQL 요청을 `query_logs` 테이블에 기록
- 성공/실패 여부, 응답 시간, 에러 메시지 저장

**로그 스키마:**
```sql
CREATE TABLE query_logs (
    log_id SERIAL PRIMARY KEY,
    user_query TEXT,
    difficulty_mode VARCHAR(10),
    tool_used VARCHAR(50),
    response TEXT,
    response_time_ms INTEGER,
    success BOOLEAN,
    error_message TEXT,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);
```

### 특징 및 장점

**장점:**
- 자연어 → SQL 변환 자동화 (사용자 SQL 지식 불필요)
- 화이트리스트 기반 보안 (DB 손상 방지)
- Few-shot 학습으로 정확도 향상
- Markdown 표 형식으로 가독성 높은 결과
- 자동 로깅으로 쿼리 추적 가능

**제약사항:**
- 현재는 `papers` 테이블만 접근 가능
- 복잡한 JOIN/서브쿼리는 제한적
- `glossary` 테이블 등 추가 테이블은 향후 확장 예정

**비용:**
- LLM 호출 1회 (Solar Pro2 사용 시 저비용)
- 평균 응답 시간: 2-3초

---

## 🔄 라우팅 시스템

### LLM 기반 도구 선택

AI Agent의 **Router 노드**가 질문을 분석하여 적절한 도구를 자동으로 선택합니다.

### LangGraph 구조

```python
from langgraph.graph import StateGraph, END

class AgentState(TypedDict):
    question: str
    difficulty: str
    tool_choice: str  # 선택된 도구 이름
    tool_result: str
    final_answer: str
    messages: Sequence[BaseMessage]
```

**노드 구성:**
- **router**: 질문 분석 및 도구 선택
- **general_answer_node**: 일반 답변 도구 실행
- **search_paper_node**: RAG 검색 도구 실행
- **glossary_node**: 용어집 검색 도구 실행
- **web_search_node**: 웹 검색 도구 실행
- **summarize_node**: 논문 요약 도구 실행
- **text2sql_node**: Text-to-SQL 도구 실행
- **save_file_node**: 파일 저장 도구 실행

**엣지 연결:**
```python
workflow.add_conditional_edges(
    "router",
    lambda state: state["tool_choice"],
    {
        "general_answer": "general_answer_node",
        "search_paper": "search_paper_node",
        "glossary": "glossary_node",
        "web_search": "web_search_node",
        "summarize": "summarize_node",
        "text2sql": "text2sql_node",
        "save_file": "save_file_node"
    }
)
```

### Router 로직

**Solar Pro2 사용:**
- Temperature: 0.0 (결정론적 라우팅)
- 빠르고 저렴 (비용 절감)

**라우팅 결정 기준:**
| 질문 키워드 | 도구 선택 |
|------------|----------|
| "안녕", "고마워" | general_answer |
| "논문", "설명", "차이" | search_paper |
| "정의", "뭐야", "용어" | glossary |
| "최신", "2025년", "웹" | web_search |
| "요약", "핵심 내용" | summarize |
| "개수", "몇 편", "통계" | text2sql |
| "저장", "파일" | save_file |

---

## 🎯 난이도별 답변 모드

### Easy 모드 (초심자)

**특징:**
- 전문 용어 최소화 → 쉬운 말로 풀어서 설명
- 비유와 예시 많이 사용
- 단계별 설명 (1, 2, 3 순서)
- 수식 최소화

**프롬프트 전략:**
```
당신은 AI/ML 초심자를 위한 논문 리뷰 어시스턴트입니다.

답변 규칙:
1. 전문 용어가 나오면 반드시 쉬운 말로 풀어서 설명
2. 실생활 비유 사용 (예: "Attention은 사람이 책을 읽을 때 중요한 부분에 집중하는 것과 같습니다")
3. 수식은 최소화하고, 나오면 직관적으로 설명
4. 핵심 아이디어 3가지 이내로 요약
```

### Hard 모드 (전문가)

**특징:**
- 기술적 세부사항 포함
- 수식 및 알고리즘 설명
- 관련 논문 비교 분석
- 구현 세부사항 제공

**프롬프트 전략:**
```
당신은 AI/ML 전문가를 위한 논문 리뷰 어시스턴트입니다.

답변 규칙:
1. 기술적 세부사항 및 수식 포함
2. 알고리즘의 시간/공간 복잡도 분석
3. 관련 논문과의 비교 (장단점)
4. 구현 시 고려사항
5. 최신 연구 동향과의 연결
```

### UI 통합

**Streamlit 난이도 선택:**
```python
difficulty_mode = st.selectbox(
    "답변 난이도 선택",
    ["Easy 모드 (초심자용)", "Hard 모드 (전문가용)"]
)
```

**AgentState 전달:**
```python
state = {
    "question": user_query,
    "difficulty": "easy" if "Easy" in difficulty_mode else "hard",
    "messages": []
}
```

---

## 📋 도구별 통합 요구사항

### 공통 요구사항

**1. ExperimentManager 통합**
- 모든 도구는 `exp_manager` 파라미터 지원
- 도구별 Logger 자동 생성 (`exp_manager.get_tool_logger()`)

**2. 난이도 지원**
- 파일 저장 도구를 제외한 모든 도구가 `difficulty` 파라미터 지원
- Easy/Hard 모드 프롬프트 분리

**3. 에러 핸들링**
- DB 연결 실패 시 Fallback 전략
- API 호출 실패 시 재시도 로직 (tenacity)

**4. 로깅 정책**
- 도구 실행 시작/종료 로그
- 검색 결과 개수 기록
- DB 쿼리 성능 추적

### 도구별 DB 설정

| 도구 | DB 연동 | 환경 변수 | 필수 설정 |
|------|---------|----------|-----------|
| 일반 답변 | ❌ | `OPENAI_API_KEY` | ✅ |
| RAG 검색 | PostgreSQL + pgvector | `DATABASE_URL`, `OPENAI_API_KEY` | ✅ |
| 용어집 검색 | PostgreSQL | `DATABASE_URL`, `OPENAI_API_KEY` | ✅ |
| 웹 검색 | ❌ | `TAVILY_API_KEY`, `OPENAI_API_KEY` | ✅ |
| 논문 요약 | PostgreSQL + pgvector | `DATABASE_URL`, `OPENAI_API_KEY` | ✅ |
| Text-to-SQL | PostgreSQL | `DATABASE_URL`, `SOLAR_API_KEY` | ✅ |
| 파일 저장 | ExperimentManager | 없음 | ❌ |

### API 키 관리

**`.env` 파일 필수 설정:**
```bash
OPENAI_API_KEY=sk-...
TAVILY_API_KEY=tvly-...
DATABASE_URL=postgresql://user:pass@localhost:5432/dbname
```

---

## ⚠️ 주의사항

### 1. DB 연결 관리

**PostgreSQL 연결 풀링:**
- 도구 실행마다 연결 생성/종료 (리소스 누수 방지)
- 에러 발생 시 자동 종료 (try-finally 블록)

**pgvector 인덱스:**
- `paper_chunks` 테이블에 IVF 인덱스 생성 권장
- 검색 속도 향상 (Top-5 검색 1초 이내)

### 2. LLM 비용 관리

**도구별 비용:**
| 도구 | LLM 호출 횟수 | 예상 비용 (1회) |
|------|--------------|----------------|
| 일반 답변 | 1회 | $0.003 |
| RAG 검색 | 1회 | $0.015 (GPT-5) |
| 용어집 검색 | 2회 (용어 추출 + 답변) | $0.005 |
| 웹 검색 | 1회 | $0.005 |
| 논문 요약 | 1회 (대용량) | $0.08 |
| Text-to-SQL | 1회 | $0.001 (Solar Pro2) |
| 파일 저장 | 0회 | $0 |

**비용 절감 전략:**
- 용어집 검색: 용어 추출에 Solar Pro2 사용
- 웹 검색: Solar Pro2로 정리 (Easy 모드)
- 논문 요약: 청크 수 제한 (10개)

### 3. 에러 핸들링

**DB 에러:**
- PostgreSQL 연결 실패 → 사용자에게 안내 메시지
- pgvector 검색 실패 → 일반 답변 도구로 Fallback

**API 에러:**
- Tavily API 호출 실패 → 재시도 3회 (exponential backoff)
- OpenAI API 호출 실패 → Solar로 Fallback

**용어집 없음:**
- glossary 테이블에 용어 없음 → RAG 검색으로 Fallback

---

## 🔗 관련 문서

- **[03_AI_Agent_시스템.md](./03_AI_Agent_시스템.md)** - Agent에서 도구 통합
- **[02_실험_관리_시스템.md](./02_실험_관리_시스템.md)** - ExperimentManager 통합
- **[04_LLM_클라이언트.md](./04_LLM_클라이언트.md)** - 도구에서 LLM 사용
- **[PRD/자료조사_05_AI_Agent_도구.md](../PRD/자료조사_05_AI_Agent_도구.md)** - 도구 시스템 전체 명세

---

## 📝 요약

### 구현된 핵심 기능

1. ✅ 7가지 도구 구현 (일반 답변, RAG, 용어집, 웹 검색, 요약, Text-to-SQL, 파일 저장)
2. ✅ LangGraph 라우팅 통합 (Router 노드)
3. ✅ 난이도별 답변 모드 (Easy/Hard)
4. ✅ PostgreSQL + pgvector 통합 (RAG, 용어집, 요약)
5. ✅ Tavily Search API 통합 (웹 검색)
6. ✅ Text-to-SQL 통합 (논문 통계 조회, 보안 검증)
7. ✅ ExperimentManager 통합 (로깅, 파일 저장)

### 도구별 특징 요약

| 도구 | DB 필요 | API 키 필요 | 난이도 지원 | 복잡도 | 평균 응답 시간 |
|------|---------|-------------|-------------|--------|----------------|
| 일반 답변 | ❌ | ✅ (OpenAI) | ✅ | 낮음 | 2초 |
| RAG 검색 | ✅ (pgvector) | ✅ (OpenAI) | ✅ | 높음 | 5초 |
| 용어집 검색 | ✅ (PostgreSQL) | ✅ (OpenAI) | ✅ | 중간 | 3초 |
| 웹 검색 | ❌ | ✅ (Tavily) | ✅ | 중간 | 4초 |
| 논문 요약 | ✅ (pgvector) | ✅ (OpenAI) | ✅ | 높음 | 10초 |
| Text-to-SQL | ✅ (PostgreSQL) | ✅ (Solar) | ✅ | 중간 | 3초 |
| 파일 저장 | ❌ | ❌ | ❌ | 낮음 | 0.1초 |

### 사용 패턴

**Agent에서 도구 호출:**
```python
# Router 노드가 자동으로 도구 선택
state = {
    "question": "Transformer 논문 설명해줘",
    "difficulty": "easy",
    "messages": []
}

result = agent.invoke(state)
# tool_choice: "search_paper"
# final_answer: "Transformer는..."
```

**직접 도구 호출:**
```python
from src.tools.search_paper import search_paper_tool

answer = search_paper_tool(
    question="Transformer 논문 설명해줘",
    difficulty="easy",
    exp_manager=exp_manager
)
```

### 모범 사례

1. **Router 노드 신뢰**: LLM 라우팅 결정을 따름 (수동 오버라이드 최소화)
2. **난이도 일관성**: 사용자 선택 난이도를 모든 도구에 전달
3. **ExperimentManager 통합**: 도구별 로그 독립 관리
4. **에러 핸들링**: DB 실패 시 Fallback 전략 (RAG → 일반 답변)
5. **비용 관리**: 라우팅에 Solar Pro2, 복잡한 답변에만 GPT-5
6. **도구별 Logger**: `exp_manager.get_tool_logger(tool_name)` 사용
7. **API 키 관리**: `.env` 파일로 중앙 관리

### 향후 개선 사항

- 도구 체이닝 (여러 도구 순차 실행)
- 논문 비교 도구 추가 (BERT vs GPT)
- Text-to-SQL 확장 (glossary 테이블 등 추가 테이블 지원)
- 인용 추출 도구 추가
- 도구별 성능 평가 지표 추적
- Text-to-SQL 복잡한 JOIN/서브쿼리 지원 강화
