# 담당역할: 임예슬 - Streamlit UI & 프롬프트 & 웹검색/파일저장 도구

## 담당자 정보
- **이름**: 임예슬
- **역할**: UI 및 프롬프트 담당
- **참여 기간**: 10/28 ~ 11/6 (전체 기간)
- **핵심 역할**: Streamlit UI 개발, 프롬프트 템플릿, 웹 검색 도구, 파일 저장 도구

---

## 담당 모듈 및 도구

### 1. Streamlit UI (`ui/app.py`)
- 채팅 인터페이스 구현
- LangGraph Agent 스트리밍 연동 (astream_events)
- StreamlitCallbackHandler 구현
- 난이도 선택 UI (Easy/Hard)
- 대화 히스토리 표시 (ChatMessageHistory 연동)
- 파일 다운로드 기능

### 2. 프롬프트 템플릿 (`src/prompts/`)
- Langchain PromptTemplate 구현
- ChatPromptTemplate으로 Easy/Hard 모드 프롬프트 구성
- FewShotPromptTemplate (예시 기반 프롬프트, 선택)
- 도구별 프롬프트 (SystemMessage, HumanMessage)

### 3. 도구 2: 웹 검색 도구 (`src/tools/web_search.py`)
- Langchain TavilySearchResults 도구 연동
- @tool 데코레이터로 커스텀 웹 검색 래퍼 구현
- 검색 결과 포맷팅

### 4. 도구 5: 파일 저장 도구 (`src/tools/file_save.py`)
- Langchain @tool 데코레이터로 save_to_file 구현
- 대화 내용 저장
- 요약 내용 저장
- Streamlit 다운로드 버튼 연동

---

## Streamlit UI 구현

### 1. 기본 채팅 인터페이스
```python
# ui/app.py

import streamlit as st
from src.agent.graph import create_agent_graph
from src.memory.chat_history import ChatMemoryManager
from langchain.callbacks.streamlit import StreamlitCallbackHandler

# 페이지 설정
st.set_page_config(
    page_title="논문 리뷰 챗봇",
    page_icon="📚",
    layout="wide"
)

# 제목
st.title("📚 논문 리뷰 챗봇 (AI Agent + RAG)")
st.markdown("AI/ML 논문을 쉽게 이해할 수 있도록 돕는 챗봇입니다.")

# 사이드바: 난이도 선택
with st.sidebar:
    st.header("⚙️ 설정")

    difficulty_mode = st.selectbox(
        "답변 난이도 선택",
        ["Easy 모드 (초심자용)", "Hard 모드 (전문가용)"]
    )

    difficulty = "easy" if "Easy" in difficulty_mode else "hard"

    st.markdown("---")
    st.markdown("### 📖 사용 방법")
    st.markdown("""
    1. 난이도를 선택하세요
    2. 질문을 입력하세요
    3. AI Agent가 자동으로 적절한 도구를 선택하여 답변합니다

    **예시 질문:**
    - Transformer 논문 설명해줘
    - Attention이 뭐야?
    - 2025년 최신 LLM 논문은?
    - BERT 논문 요약해줘
    """)

# 세션 상태 초기화
if "messages" not in st.session_state:
    st.session_state.messages = []

if "memory_manager" not in st.session_state:
    st.session_state.memory_manager = ChatMemoryManager()

if "agent" not in st.session_state:
    st.session_state.agent = create_agent_graph()

# 대화 히스토리 표시
for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])

# 사용자 입력
if prompt := st.chat_input("논문에 대해 질문해주세요"):
    # 사용자 메시지 추가
    st.session_state.messages.append({"role": "user", "content": prompt})

    with st.chat_message("user"):
        st.markdown(prompt)

    # AI 답변 생성
    with st.chat_message("assistant"):
        with st.spinner("답변 생성 중..."):
            # Agent 실행
            result = st.session_state.agent.invoke({
                "question": prompt,
                "difficulty": difficulty,
                "messages": st.session_state.memory_manager.get_history()
            })

            response = result["final_answer"]

            # 답변 표시
            st.markdown(response)

    # AI 메시지 추가
    st.session_state.messages.append({"role": "assistant", "content": response})

    # 메모리에 추가
    st.session_state.memory_manager.add_user_message(prompt)
    st.session_state.memory_manager.add_ai_message(response)

# 대화 초기화 버튼
if st.sidebar.button("🔄 대화 초기화"):
    st.session_state.messages = []
    st.session_state.memory_manager.clear()
    st.rerun()
```

### 2. 스트리밍 응답 (고급)
```python
# ui/app_streaming.py

import streamlit as st
from langchain.callbacks.streamlit import StreamlitCallbackHandler

# AI 답변 생성 (스트리밍)
with st.chat_message("assistant"):
    st_callback = StreamlitCallbackHandler(st.container())

    response_placeholder = st.empty()
    full_response = ""

    # Agent 스트리밍 실행
    async for event in st.session_state.agent.astream_events(
        {
            "question": prompt,
            "difficulty": difficulty
        },
        callbacks=[st_callback]
    ):
        # LLM 스트리밍 출력
        if event["event"] == "on_chat_model_stream":
            chunk = event["data"]["chunk"].content
            full_response += chunk
            response_placeholder.markdown(full_response + "▌")

    # 최종 응답
    response_placeholder.markdown(full_response)
```

### 3. 파일 다운로드 기능
```python
# ui/app.py (추가)

import os
from datetime import datetime

# 사이드바: 파일 저장 기능
with st.sidebar:
    st.markdown("---")
    st.markdown("### 💾 파일 저장")

    if st.button("대화 내용 저장"):
        if st.session_state.messages:
            # 대화 내용을 텍스트로 변환
            conversation_text = ""
            for msg in st.session_state.messages:
                role = "사용자" if msg["role"] == "user" else "AI"
                conversation_text += f"[{role}]\n{msg['content']}\n\n"

            # 파일명 생성
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            filename = f"conversation_{timestamp}.txt"

            # 다운로드 버튼
            st.download_button(
                label="📥 다운로드",
                data=conversation_text,
                file_name=filename,
                mime="text/plain"
            )

            st.success("대화 내용을 다운로드할 수 있습니다!")
        else:
            st.warning("저장할 대화 내용이 없습니다.")
```

---

## 프롬프트 템플릿 구현

### 1. Easy/Hard 모드 프롬프트
```python
# src/prompts/templates.py

from langchain.prompts import (
    ChatPromptTemplate,
    SystemMessagePromptTemplate,
    HumanMessagePromptTemplate,
    PromptTemplate
)

# Easy 모드 프롬프트
EASY_MODE_SYSTEM_PROMPT = """
당신은 AI/ML 논문을 쉽게 설명하는 전문가입니다.

답변 규칙:
1. 전문 용어가 나오면 반드시 쉬운 말로 풀어서 설명하세요
2. 실생활 비유를 사용하세요
   - 예: "Attention은 사람이 책을 읽을 때 중요한 부분에 집중하는 것과 같습니다"
3. 수식은 최소화하고, 나오면 직관적으로 설명하세요
4. 핵심 아이디어 3가지 이내로 요약하세요
5. 초심자도 이해할 수 있는 언어를 사용하세요
"""

EASY_MODE_PROMPT = ChatPromptTemplate.from_messages([
    SystemMessagePromptTemplate.from_template(EASY_MODE_SYSTEM_PROMPT),
    HumanMessagePromptTemplate.from_template("{question}")
])

# Hard 모드 프롬프트
HARD_MODE_SYSTEM_PROMPT = """
당신은 AI/ML 전문가를 위한 논문 리뷰 어시스턴트입니다.

답변 규칙:
1. 기술적 세부사항 및 수식을 포함하세요
2. 알고리즘의 시간/공간 복잡도를 분석하세요
3. 관련 논문과의 비교를 제공하세요 (장단점)
4. 구현 시 고려사항을 설명하세요
5. 최신 연구 동향과의 연결을 제시하세요
"""

HARD_MODE_PROMPT = ChatPromptTemplate.from_messages([
    SystemMessagePromptTemplate.from_template(HARD_MODE_SYSTEM_PROMPT),
    HumanMessagePromptTemplate.from_template("{question}")
])

# 난이도별 프롬프트 선택 함수
def get_difficulty_prompt(difficulty: str) -> ChatPromptTemplate:
    """난이도에 따른 프롬프트 반환"""
    if difficulty == "easy":
        return EASY_MODE_PROMPT
    else:
        return HARD_MODE_PROMPT
```

### 2. RAG 프롬프트
```python
# RAG 검색 결과를 포함한 프롬프트

RAG_PROMPT_TEMPLATE = ChatPromptTemplate.from_messages([
    SystemMessagePromptTemplate.from_template("""
    당신은 논문 리뷰 전문가입니다.
    아래 논문 검색 결과를 참고하여 사용자의 질문에 답변해주세요.

    [답변 규칙]
    - 검색 결과의 내용을 기반으로 답변하세요
    - 출처를 명시하세요 (논문 제목, 저자)
    - 검색 결과에 없는 내용은 추측하지 마세요
    - 난이도: {difficulty} 모드

    [검색 결과]
    {context}
    """),
    HumanMessagePromptTemplate.from_template("{question}")
])
```

### 3. Few-Shot 프롬프트 (선택)
```python
from langchain.prompts import FewShotPromptTemplate

# 예시 데이터
examples = [
    {
        "question": "Transformer가 뭐야?",
        "difficulty": "easy",
        "answer": "Transformer는 2017년에 발표된 AI 모델 구조입니다. 번역, 요약 등의 작업에 사용됩니다. 가장 큰 특징은 'Attention' 메커니즘을 사용한다는 점입니다."
    },
    {
        "question": "Transformer의 시간 복잡도는?",
        "difficulty": "hard",
        "answer": "Transformer의 self-attention 메커니즘은 O(n²d) 시간 복잡도를 가집니다. 여기서 n은 시퀀스 길이, d는 임베딩 차원입니다. 이는 긴 시퀀스 처리 시 병목이 될 수 있습니다."
    }
]

# Few-Shot 프롬프트 템플릿
example_prompt = PromptTemplate(
    input_variables=["question", "difficulty", "answer"],
    template="질문: {question}\n난이도: {difficulty}\n답변: {answer}"
)

few_shot_prompt = FewShotPromptTemplate(
    examples=examples,
    example_prompt=example_prompt,
    prefix="다음은 논문 리뷰 챗봇의 답변 예시입니다:",
    suffix="질문: {question}\n난이도: {difficulty}\n답변:",
    input_variables=["question", "difficulty"]
)
```

---

## 도구 2: 웹 검색 도구

### 기능 설명
최신 논문 정보를 웹에서 실시간으로 검색하는 도구

### Langchain 구현

#### 1. TavilySearchResults 연동
```python
# src/tools/web_search.py

from langchain_community.tools.tavily_search import TavilySearchResults
from langchain.tools import tool
import os

# Langchain 기본 도구 사용
tavily_search = TavilySearchResults(
    max_results=5,
    search_depth="advanced",
    include_answer=True,
    include_raw_content=False,
    api_key=os.getenv("TAVILY_API_KEY")
)

@tool
def search_latest_papers(query: str) -> str:
    """
    최신 AI/ML 논문을 웹에서 검색합니다.

    Args:
        query: 검색 질문

    Returns:
        검색 결과 (제목, URL, 요약)
    """
    # Tavily 검색 실행
    search_query = f"{query} AI ML paper 2024 2025 arxiv"

    results = tavily_search.invoke({"query": search_query})

    # 결과 포맷팅
    formatted_results = format_web_search_results(results)

    return formatted_results


def format_web_search_results(results: list) -> str:
    """웹 검색 결과 포맷팅"""
    if not results:
        return "검색 결과가 없습니다."

    output = "## 🔍 웹 검색 결과\n\n"

    for i, result in enumerate(results, 1):
        title = result.get("title", "제목 없음")
        url = result.get("url", "")
        content = result.get("content", "")

        output += f"### {i}. {title}\n"
        output += f"- **URL**: {url}\n"
        output += f"- **내용**: {content}\n\n"
        output += "---\n\n"

    return output
```

#### 2. arXiv 검색 (선택)
```python
from langchain_community.document_loaders import ArxivLoader

@tool
def search_arxiv(query: str, max_docs: int = 3) -> str:
    """
    arXiv에서 최신 논문을 검색합니다.

    Args:
        query: 검색 질문
        max_docs: 최대 검색 논문 수

    Returns:
        arXiv 검색 결과
    """
    # ArxivLoader로 검색
    loader = ArxivLoader(query=query, max_docs=max_docs)
    docs = loader.load()

    # 결과 포맷팅
    output = "## 📄 arXiv 검색 결과\n\n"

    for i, doc in enumerate(docs, 1):
        title = doc.metadata.get("Title", "제목 없음")
        authors = doc.metadata.get("Authors", "저자 없음")
        published = doc.metadata.get("Published", "출판일 없음")
        summary = doc.page_content[:500]  # 요약 500자

        output += f"### {i}. {title}\n"
        output += f"- **저자**: {authors}\n"
        output += f"- **출판일**: {published}\n"
        output += f"- **요약**: {summary}...\n\n"
        output += "---\n\n"

    return output
```

### 사용하는 DB
**DB 사용 없음** (외부 API 호출)

---

## 도구 5: 파일 저장 도구

### 기능 설명
대화 내용, 논문 요약, 참고 자료를 파일로 저장하는 도구

### Langchain 구현

#### 1. 텍스트 파일 저장
```python
# src/tools/file_save.py

from langchain.tools import tool
import os
from datetime import datetime

@tool
def save_to_file(content: str, filename: str = None) -> str:
    """
    내용을 텍스트 파일로 저장합니다.

    Args:
        content: 저장할 내용
        filename: 파일명 (선택, 없으면 자동 생성)

    Returns:
        저장된 파일 경로
    """
    if filename is None:
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        filename = f"paper_review_{timestamp}.txt"

    # data/outputs 폴더에 저장
    output_dir = "data/outputs"
    os.makedirs(output_dir, exist_ok=True)

    filepath = os.path.join(output_dir, filename)

    # 파일 저장
    with open(filepath, "w", encoding="utf-8") as f:
        f.write(content)

    return f"✅ 파일이 저장되었습니다: {filepath}"
```

#### 2. Markdown 형식 저장
```python
@tool
def save_to_markdown(content: str, title: str = "논문 리뷰", filename: str = None) -> str:
    """
    내용을 Markdown 형식으로 저장합니다.

    Args:
        content: 저장할 내용
        title: 문서 제목
        filename: 파일명 (선택)

    Returns:
        저장된 파일 경로
    """
    if filename is None:
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        filename = f"paper_review_{timestamp}.md"

    # Markdown 형식으로 포맷팅
    markdown_content = f"""# {title}

생성일: {datetime.now().strftime("%Y-%m-%d %H:%M:%S")}

---

{content}

---

📚 Generated by 논문 리뷰 챗봇 (AI Agent + RAG)
"""

    # 파일 저장
    output_dir = "data/outputs"
    os.makedirs(output_dir, exist_ok=True)
    filepath = os.path.join(output_dir, filename)

    with open(filepath, "w", encoding="utf-8") as f:
        f.write(markdown_content)

    return f"✅ Markdown 파일이 저장되었습니다: {filepath}"
```

#### 3. Streamlit 다운로드 버튼 연동
```python
# ui/app.py (파일 저장 UI)

import streamlit as st

# 파일 저장 UI
with st.sidebar:
    st.markdown("### 💾 파일 저장")

    # 저장할 내용 선택
    save_option = st.radio(
        "저장 내용 선택",
        ["대화 내용", "마지막 답변만"]
    )

    if st.button("파일 저장"):
        if save_option == "대화 내용":
            # 전체 대화 내용
            content = ""
            for msg in st.session_state.messages:
                role = "사용자" if msg["role"] == "user" else "AI"
                content += f"[{role}]\n{msg['content']}\n\n"
        else:
            # 마지막 AI 답변만
            if st.session_state.messages:
                last_ai_msg = [msg for msg in st.session_state.messages if msg["role"] == "assistant"][-1]
                content = last_ai_msg["content"]
            else:
                st.warning("저장할 내용이 없습니다.")
                content = ""

        if content:
            # save_to_file 도구 호출
            result = save_to_file.invoke({"content": content})
            st.success(result)

            # 다운로드 버튼
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            st.download_button(
                label="📥 다운로드",
                data=content,
                file_name=f"paper_review_{timestamp}.txt",
                mime="text/plain"
            )
```

### 사용하는 DB
**DB 사용 없음** (파일 시스템 직접 접근)

---

## LangGraph 통합 (웹 검색/파일 저장 노드)

```python
# src/agent/nodes.py

def web_search_node(state: AgentState):
    """웹 검색 노드"""
    question = state["question"]

    # 웹 검색 도구 호출
    search_result = search_latest_papers.invoke({"query": question})

    # 검색 결과를 상태에 저장
    state["tool_result"] = search_result

    # LLM에 전달하여 최종 답변 생성
    prompt = f"""
    다음 웹 검색 결과를 바탕으로 사용자 질문에 답변해주세요.

    검색 결과:
    {search_result}

    사용자 질문: {question}

    답변:
    """

    response = llm.invoke([
        SystemMessage(content="당신은 최신 AI/ML 정보를 제공하는 전문가입니다."),
        HumanMessage(content=prompt)
    ])

    state["final_answer"] = response.content
    return state


def save_file_node(state: AgentState):
    """파일 저장 노드"""
    # 이전 답변을 파일로 저장
    content = state.get("final_answer", "")

    if content:
        # 파일 저장 도구 호출
        result = save_to_file.invoke({"content": content})
        state["final_answer"] = result
    else:
        state["final_answer"] = "저장할 내용이 없습니다."

    return state
```

---

## 개발 일정

### Phase 1: Streamlit UI 기초 개발 (10/28~10/30)
- 기본 채팅 인터페이스 구현
- 난이도 선택 UI
- 대화 히스토리 표시
- StreamlitCallbackHandler 연동

### Phase 2: 프롬프트 템플릿 개발 (10/31~11/02)
- Easy/Hard 모드 프롬프트
- RAG 프롬프트
- FewShotPromptTemplate (선택)

### Phase 3: 도구 개발 (11/03~11/04)
- 웹 검색 도구 (TavilySearchResults)
- 파일 저장 도구
- Streamlit 다운로드 버튼 연동

### Phase 4: 스트리밍 및 최적화 (11/04~11/05)
- 스트리밍 응답 구현
- UI 디자인 개선
- 통합 테스트

---

## Feature 브랜치

- `feature/streamlit-ui` - Streamlit UI
- `feature/prompts` - 프롬프트 템플릿
- `feature/tool-web-search` - 웹 검색 도구
- `feature/tool-file-save` - 파일 저장 도구

---

## 테스트 코드

```python
# tests/test_tools.py

import pytest
from src.tools.web_search import search_latest_papers
from src.tools.file_save import save_to_file

def test_web_search():
    """웹 검색 도구 테스트"""
    result = search_latest_papers.invoke({
        "query": "transformer 2025"
    })

    assert "검색 결과" in result
    assert len(result) > 0

def test_file_save():
    """파일 저장 도구 테스트"""
    content = "테스트 내용입니다."

    result = save_to_file.invoke({
        "content": content,
        "filename": "test_file.txt"
    })

    assert "저장되었습니다" in result
    assert os.path.exists("data/outputs/test_file.txt")
```

---

## 참고 자료

- Streamlit 공식 문서: https://docs.streamlit.io/
- Streamlit Chat Elements: https://docs.streamlit.io/library/api-reference/chat
- Langchain Prompts: https://python.langchain.com/docs/modules/model_io/prompts/
- Langchain Callbacks: https://python.langchain.com/docs/modules/callbacks/
- TavilySearchResults: https://python.langchain.com/docs/integrations/tools/tavily_search/
- StreamlitCallbackHandler: https://python.langchain.com/docs/integrations/callbacks/streamlit
