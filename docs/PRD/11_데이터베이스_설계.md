# 11. 데이터베이스 설계

## 문서 정보
- **작성일**: 2025-10-30
- **프로젝트명**: 논문 리뷰 챗봇 (AI Agent + RAG)
- **팀명**: 연결의 민족

---

## 1. 데이터베이스 아키텍처

### 1.1 DB 스키마 구조도

```mermaid
graph TB
    subgraph Papers["🔸 논문 관리"]
        direction TB
        P[papers 테이블<br/>paper_id, title, authors<br/>publish_date, abstract]
        P --> PC[paper_chunks<br/>chunk_id, paper_id<br/>chunk_text, embedding]
    end

    subgraph Glossary["🔹 용어집"]
        direction TB
        G[glossary 테이블<br/>term_id, term<br/>easy_explanation<br/>hard_explanation]
        G --> GE[glossary_embeddings<br/>term_id, embedding]
    end

    subgraph Logs["🔺 로그 & 모니터링"]
        direction LR
        QL[query_logs<br/>log_id, user_query<br/>difficulty_mode<br/>tool_used, response_time]
    end

    Papers -.->|메타데이터| P
    Glossary -.->|정의 조회| G
    Papers -.->|벡터 검색| PC
    Glossary -.->|유사 용어| GE

    %% Subgraph 스타일
    style Papers fill:#e1f5ff,stroke:#01579b,stroke-width:3px,color:#000
    style Glossary fill:#f3e5f5,stroke:#4a148c,stroke-width:3px,color:#000
    style Logs fill:#e8f5e9,stroke:#1b5e20,stroke-width:3px,color:#000

    %% 노드 스타일
    style P fill:#90caf9,stroke:#1976d2,color:#000
    style PC fill:#64b5f6,stroke:#1976d2,color:#000
    style G fill:#ce93d8,stroke:#7b1fa2,color:#000
    style GE fill:#ba68c8,stroke:#7b1fa2,color:#fff
    style QL fill:#a5d6a7,stroke:#388e3c,color:#000
```

**DB 스키마 구조도 설명:**
- 데이터베이스를 3개의 주요 영역(논문 관리, 용어집, 로그 & 모니터링)으로 구분하여 각 테이블의 역할과 관계를 표현
- 논문 관리 영역에서는 papers 테이블이 논문 메타데이터를 저장하고, paper_chunks 테이블이 청크 분할된 텍스트와 임베딩을 저장하여 벡터 검색을 지원
- 용어집 영역에서는 glossary 테이블이 용어 정의와 난이도별 설명을 저장하고, glossary_embeddings 테이블이 유사 용어 검색을 위한 임베딩을 관리
- 로그 & 모니터링 영역에서는 query_logs 테이블이 사용자 질문, 난이도, 사용된 도구, 응답 시간 등을 기록하여 시스템 성능 분석을 지원

### 1.2 쿼리 흐름

```mermaid
sequenceDiagram
    autonumber
    participant App as 애플리케이션
    participant PG as PostgreSQL
    participant VDB as pgvector

    App->>App: 사용자 질문 입력
    App->>VDB: 임베딩 벡터로 변환
    VDB->>VDB: 유사도 검색 (Cosine)<br/>Top-K 문서 추출
    VDB-->>App: chunk_id 리스트 반환

    App->>PG: paper_id 조회<br/>FROM paper_chunks
    PG-->>App: paper_id 반환

    App->>PG: 메타데이터 조회<br/>FROM papers
    PG-->>App: title, authors, year

    App->>App: 컨텍스트 구성<br/>LLM에 전달
```

**쿼리 흐름 설명:**
- 사용자 질문이 입력되면 애플리케이션, PostgreSQL, pgvector 간의 상호작용을 통해 관련 논문을 검색하는 전체 프로세스를 순차적으로 표현
- 질문을 임베딩 벡터로 변환한 후 pgvector에서 Cosine 유사도 기반으로 Top-K 문서를 추출
- 검색된 chunk_id로 paper_chunks 테이블에서 paper_id를 조회하고, 해당 paper_id로 papers 테이블에서 제목, 저자, 년도 등의 메타데이터를 가져옴
- 최종적으로 검색된 문서 내용과 메타데이터를 결합하여 컨텍스트를 구성하고 LLM에 전달하여 답변 생성

### 1.3 전체 구조

**선택:** PostgreSQL + pgvector 통합 솔루션

**이유:**
- 관계형 데이터와 벡터 검색을 하나의 DB에서 처리
- 운영 및 유지보수 간소화
- Langchain과 완벽한 통합

---

## 2. PostgreSQL 스키마

### 2.1 papers 테이블 (논문 메타데이터)

```sql
CREATE TABLE papers (
    paper_id SERIAL PRIMARY KEY,
    title VARCHAR(500) NOT NULL,
    authors TEXT,                          -- JSON 또는 TEXT 형식
    publish_date DATE,
    source VARCHAR(100),                   -- 'arXiv', 'IEEE', 'ACL' 등
    url TEXT UNIQUE,                       -- 논문 URL (중복 방지)
    category VARCHAR(100),                 -- 'cs.AI', 'cs.CL', 'cs.CV' 등
    citation_count INT DEFAULT 0,
    abstract TEXT,                         -- 논문 초록
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

-- 인덱스 생성
CREATE INDEX idx_papers_title ON papers USING GIN (to_tsvector('english', title));
CREATE INDEX idx_papers_category ON papers(category);
CREATE INDEX idx_papers_publish_date ON papers(publish_date DESC);
CREATE INDEX idx_papers_created_at ON papers(created_at DESC);
```

### 2.2 glossary 테이블 (용어집)

```sql
CREATE TABLE glossary (
    term_id SERIAL PRIMARY KEY,
    term VARCHAR(200) NOT NULL UNIQUE,     -- 용어
    definition TEXT NOT NULL,              -- 기본 정의
    easy_explanation TEXT,                 -- Easy 모드 설명
    hard_explanation TEXT,                 -- Hard 모드 설명
    category VARCHAR(100),                 -- 'ML', 'NLP', 'CV', 'RL' 등
    difficulty_level VARCHAR(20),          -- 'beginner', 'intermediate', 'advanced'
    related_terms TEXT[],                  -- 관련 용어 배열
    examples TEXT,                         -- 사용 예시
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

-- 인덱스
CREATE INDEX idx_glossary_term ON glossary(term);
CREATE INDEX idx_glossary_category ON glossary(category);
CREATE INDEX idx_glossary_difficulty ON glossary(difficulty_level);
```

### 2.3 query_logs 테이블 (사용자 질의 로그)

```sql
CREATE TABLE query_logs (
    log_id SERIAL PRIMARY KEY,
    user_query TEXT NOT NULL,              -- 사용자 질문
    difficulty_mode VARCHAR(20),           -- 'easy' 또는 'hard'
    tool_used VARCHAR(50),                 -- 사용된 도구명
    response TEXT,                         -- 생성된 응답
    response_time_ms INT,                  -- 응답 시간 (밀리초)
    success BOOLEAN DEFAULT TRUE,          -- 성공 여부
    error_message TEXT,                    -- 오류 메시지 (있는 경우)
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

-- 인덱스
CREATE INDEX idx_query_logs_created_at ON query_logs(created_at DESC);
CREATE INDEX idx_query_logs_tool_used ON query_logs(tool_used);
CREATE INDEX idx_query_logs_success ON query_logs(success);
```

---

## 3. pgvector 컬렉션

### 3.1 컬렉션 구조

**3개의 pgvector 컬렉션:**

1. **paper_chunks**: 논문 본문 청크
2. **paper_abstracts**: 논문 초록
3. **glossary_embeddings**: 용어집 임베딩

### 3.2 Langchain PGVector 설정

```python
from langchain_postgres.vectorstores import PGVector
from langchain_openai import OpenAIEmbeddings

# 임베딩 모델
embeddings = OpenAIEmbeddings(
    model="text-embedding-3-small",
    openai_api_key=os.getenv("OPENAI_API_KEY")
)

# 연결 문자열
CONNECTION_STRING = "postgresql://user:password@localhost:5432/papers"

# 1. 논문 본문 컬렉션
paper_chunks_store = PGVector(
    collection_name="paper_chunks",
    embedding_function=embeddings,
    connection_string=CONNECTION_STRING
)

# 2. 논문 초록 컬렉션
abstract_store = PGVector(
    collection_name="paper_abstracts",
    embedding_function=embeddings,
    connection_string=CONNECTION_STRING
)

# 3. 용어집 컬렉션
glossary_store = PGVector(
    collection_name="glossary_embeddings",
    embedding_function=embeddings,
    connection_string=CONNECTION_STRING
)
```

---

## 4. 데이터 흐름

### 4.1 논문 데이터 저장 흐름

```
1. arXiv API로 논문 메타데이터 수집
2. PostgreSQL papers 테이블에 메타데이터 저장 (paper_id 반환)
3. PDF 다운로드 및 텍스트 추출
4. RecursiveCharacterTextSplitter로 청크 분할
5. OpenAI Embeddings로 임베딩 생성
6. pgvector paper_chunks 컬렉션에 저장 (paper_id 메타데이터 포함)
```

### 4.2 검색 흐름

```
1. 사용자 질문 임베딩 생성
2. pgvector similarity_search로 관련 청크 검색 (Top-K)
3. 청크의 paper_id로 PostgreSQL papers 테이블 조회
4. 메타데이터 (제목, 저자, 년도) + 청크 내용을 LLM에 전달
5. LLM이 답변 생성
```

---

## 5. 샘플 데이터

### 5.1 papers 테이블

```sql
INSERT INTO papers (title, authors, publish_date, source, url, category, abstract)
VALUES (
    'Attention Is All You Need',
    'Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Lukasz Kaiser, Illia Polosukhin',
    '2017-06-12',
    'arXiv',
    'https://arxiv.org/abs/1706.03762',
    'cs.CL',
    'The dominant sequence transduction models are based on complex recurrent or convolutional neural networks...'
);
```

### 5.2 glossary 테이블

```sql
INSERT INTO glossary (term, definition, easy_explanation, hard_explanation, category, difficulty_level)
VALUES (
    'Attention Mechanism',
    'A technique that allows models to focus on specific parts of the input when generating output.',
    '책을 읽을 때 중요한 부분에 집중하는 것처럼, AI가 입력 데이터에서 중요한 부분에 집중하는 기술입니다.',
    'A weighted sum mechanism that computes attention scores between query and key vectors using dot-product similarity, allowing the model to dynamically focus on relevant input positions during sequence processing.',
    'Deep Learning',
    'intermediate'
);
```

---

## 6. 초기화 스크립트

### 6.1 database/schema.sql

```sql
-- pgvector 확장 활성화
CREATE EXTENSION IF NOT EXISTS vector;

-- papers 테이블 생성
CREATE TABLE IF NOT EXISTS papers (
    paper_id SERIAL PRIMARY KEY,
    title VARCHAR(500) NOT NULL,
    authors TEXT,
    publish_date DATE,
    source VARCHAR(100),
    url TEXT UNIQUE,
    category VARCHAR(100),
    citation_count INT DEFAULT 0,
    abstract TEXT,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

-- 인덱스
CREATE INDEX IF NOT EXISTS idx_papers_title ON papers USING GIN (to_tsvector('english', title));
CREATE INDEX IF NOT EXISTS idx_papers_category ON papers(category);
CREATE INDEX IF NOT EXISTS idx_papers_publish_date ON papers(publish_date DESC);

-- glossary 테이블 생성
CREATE TABLE IF NOT EXISTS glossary (
    term_id SERIAL PRIMARY KEY,
    term VARCHAR(200) NOT NULL UNIQUE,
    definition TEXT NOT NULL,
    easy_explanation TEXT,
    hard_explanation TEXT,
    category VARCHAR(100),
    difficulty_level VARCHAR(20),
    related_terms TEXT[],
    examples TEXT,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

-- 인덱스
CREATE INDEX IF NOT EXISTS idx_glossary_term ON glossary(term);
CREATE INDEX IF NOT EXISTS idx_glossary_category ON glossary(category);

-- query_logs 테이블 생성
CREATE TABLE IF NOT EXISTS query_logs (
    log_id SERIAL PRIMARY KEY,
    user_query TEXT NOT NULL,
    difficulty_mode VARCHAR(20),
    tool_used VARCHAR(50),
    response TEXT,
    response_time_ms INT,
    success BOOLEAN DEFAULT TRUE,
    error_message TEXT,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

-- 인덱스
CREATE INDEX IF NOT EXISTS idx_query_logs_created_at ON query_logs(created_at DESC);
CREATE INDEX IF NOT EXISTS idx_query_logs_tool_used ON query_logs(tool_used);
```

### 6.2 실행

```bash
psql -U your_username -d papers -f database/schema.sql
```

---

## 7. 백업 및 복구

### 7.1 백업

```bash
# 전체 데이터베이스 백업
pg_dump -U your_username -d papers -F c -f backup_$(date +%Y%m%d).dump

# 특정 테이블만 백업
pg_dump -U your_username -d papers -t papers -F c -f papers_backup.dump
```

### 7.2 복구

```bash
# 데이터베이스 복원
createdb papers_restored
pg_restore -U your_username -d papers_restored backup_20251030.dump
```

---

## 8. 참고 자료

- PostgreSQL 공식 문서: https://www.postgresql.org/docs/
- pgvector GitHub: https://github.com/pgvector/pgvector
- Langchain PGVector: https://python.langchain.com/docs/integrations/vectorstores/pgvector
