# 03. 개발 및 구현 - 발표 대본 (페이지 22-47)

## 인트로
### 페이지 22: 개발 및 구현 파트 시작

**PPT 내용:**
- 제목: 개발 및 구현
- 부제: 논문 리뷰 챗봇
- 설명: AI/ML 논문을 누구나 쉽게 이해하고 활용할 수 있는 지능형 챗봇 개발

**발표 대본:**
```
이제 3번째 파트인 개발 및 구현 내용을 설명드리겠습니다.

이 파트에서는 설계 단계에서 계획한 시스템을
실제로 어떻게 구현했는지 구체적으로 보여드리겠습니다.

전체 아키텍처, AI Agent 시스템, RAG 시스템, 7가지 도구,
성능 평가 시스템, Streamlit UI, 프롬프트 엔지니어링까지
핵심 구현 내용을 다루겠습니다.
```

---

## 전체 아키텍처
### 페이지 23: 전체 시스템 아키텍처

**PPT 내용:**

**전체 아키텍처 다이어그램 (이미 PPT에 존재)**

**발표 대본:**
```
구현된 전체 시스템 아키텍처를 설명드리겠습니다.

시스템은 크게 5개 레이어로 구성됩니다.

첫째, Frontend Layer는 Streamlit으로 구현한 웹 인터페이스입니다.
사용자는 채팅 형태로 자연스럽게 질문을 입력하고
난이도를 선택할 수 있습니다.

둘째, Agent Layer는 LangGraph 기반으로 구현되었으며,
라우터가 질문을 분석하여 적절한 도구로 라우팅합니다.
대화 메모리를 통해 이전 대화 맥락을 유지합니다.

셋째, Tools Layer는 7개의 도구가 통합되어 있습니다.
RAG 논문 검색, RAG 용어집, 웹 검색, 논문 요약,
Text2SQL, 파일 저장, 일반 답변이 각각의 역할을 수행합니다.

넷째, Data Layer는 PostgreSQL과 pgvector를 사용하여
논문 데이터와 벡터 임베딩을 저장합니다.
단일 DB로 관계형 데이터와 벡터 검색을 모두 처리합니다.

다섯째, LLM Layer는 난이도에 따라
Easy 모드는 Solar Pro2를, Hard 모드는 GPT-4를 사용합니다.

모든 레이어는 명확하게 분리되어 있어
독립적으로 개발하고 테스트할 수 있었으며,
통합 시에도 문제없이 작동했습니다.
```

---

## 로깅 시스템
### 페이지 24: 로깅 및 실험 폴더 관리 시스템

**PPT 내용:**

**실험 폴더 구조 다이어그램 (이미 PPT에 존재)**

**발표 대본:**
```
로깅 및 실험 폴더 관리 시스템을 설명드리겠습니다.

저희는 ExperimentManager 클래스를 구현하여
모든 실행 세션을 자동으로 추적하고 기록합니다.

각 세션은 날짜와 시간을 기반으로 고유한 Session ID를 부여받으며,
experiments/날짜/날짜_시간_session_XXX 형태로 폴더가 생성됩니다.

각 세션 폴더는 7개의 서브 폴더로 구성됩니다.

tools 폴더는 도구별 실행 로그를 저장합니다.
rag_paper.log, rag_glossary.log, web_search.log 등
각 도구의 실행 내역이 개별 파일로 기록됩니다.

database 폴더는 SQL 쿼리, pgvector 검색 기록,
검색 결과, DB 성능 정보를 JSON 형태로 저장합니다.

prompts 폴더는 시스템 프롬프트, 사용자 프롬프트,
최종 프롬프트를 텍스트 파일로 저장하여
어떤 프롬프트가 사용되었는지 추적할 수 있습니다.

ui 폴더는 Streamlit 세션 상태와 사용자 인터랙션을 기록하고,
outputs 폴더는 생성된 답변과 요약 결과물을 저장합니다.

evaluation 폴더는 RAG 평가 지표, Agent 정확도,
응답 시간, 비용 분석 등 모든 평가 지표를 JSON으로 저장합니다.

마지막으로 debug 폴더는 필요시 생성되어
에러 트레이스와 디버그 정보를 저장합니다.

이러한 체계적인 로깅 시스템으로 모든 실험을 완전히 재현할 수 있으며,
성능 분석과 개선 작업이 용이했습니다.
```

---

## 논문 데이터 수집
### 페이지 25: 논문 데이터 수집 파이프라인

**PPT 내용:**

**데이터 수집 파이프라인 다이어그램**

**발표 대본:**
```
논문 데이터 수집 파이프라인을 설명드리겠습니다.

먼저 arXiv API를 통해 AI/ML 분야 논문을 수집합니다.
주요 키워드는 Transformer, BERT, GPT, Attention 등이며,
총 50-100편의 논문을 수집했습니다.

수집된 논문은 PDF 형식으로 다운로드되며,
PyPDF2와 pdfplumber를 사용하여 텍스트를 추출합니다.

추출된 텍스트는 LangChain의 RecursiveCharacterTextSplitter로
청크 단위로 분할합니다. 청크 크기는 1000자,
중복은 200자로 설정하여 문맥 연속성을 유지했습니다.

분할된 각 청크는 OpenAI의 text-embedding-3-small 모델로
1536차원의 벡터로 변환됩니다.

생성된 임베딩은 PostgreSQL의 pgvector extension을 통해
paper_chunks 테이블에 저장되며,
HNSW 인덱스를 사용하여 빠른 유사도 검색이 가능합니다.

논문 메타데이터인 제목, 저자, 초록, 출판일, arXiv ID는
papers 테이블에 별도로 저장되어 관리됩니다.

전체 파이프라인은 자동화되어 있어
새로운 논문을 쉽게 추가할 수 있습니다.
```

---

## AI Agent 시스템
### 페이지 26: AI Agent 시스템 구현

**PPT 내용:**

**AI Agent 구조 및 동작 방식**
- 웹 UI를 통한 대화형 인터페이스
- Easy/Hard 난이도 선택
- AI Agent가 알맞은 도구 자동 선택
- 일반 답변은 fall-back 역할
- Text2SQL 도구 추가

**발표 대본:**
```
AI Agent 시스템 구현을 설명드리겠습니다.

LangGraph StateGraph를 기반으로 Agent를 구현했으며,
사용자 질문을 분석하여 7가지 도구 중 가장 적합한 도구를
자동으로 선택합니다.

Agent의 핵심은 라우터 노드입니다.
라우터는 사용자 질문과 대화 히스토리를 분석하여
질문 유형을 파악하고, Few-shot 예시를 참고하여
적절한 도구를 선택합니다.

라우팅 정확도를 높이기 위해 각 도구별로
2-3개의 대표 예시를 Few-shot 프롬프트에 포함했습니다.

예를 들어, '논문을 찾아줘'는 search_paper 도구로,
'Attention이 뭐야?'는 glossary 도구로,
'최신 논문 알려줘'는 web_search 도구로 라우팅됩니다.

각 도구 노드는 독립적으로 구현되어 있어
새로운 도구를 쉽게 추가할 수 있습니다.

일반 답변 도구는 적절한 도구를 찾지 못했을 때
LLM의 자체 지식으로 답변하는 fall-back 역할을 하여
항상 사용자에게 답변을 제공할 수 있습니다.

Text2SQL 도구는 '논문이 몇 개야?', '가장 많이 인용된 논문'
같은 통계 질문에 대해 자연어를 SQL로 변환하여
정확한 통계를 제공합니다.
```

---

## 패턴 기반 도구 선택
### 페이지 27: AI Agent - 패턴 기반 도구 선택

**PPT 내용:**

**패턴 기반 라우팅 로직**

**발표 대본:**
```
패턴 기반 도구 선택 메커니즘을 설명드리겠습니다.

저희는 라우팅 정확도를 높이기 위해
패턴 기반 라우팅 로직을 추가로 구현했습니다.

먼저 정규표현식을 사용하여 질문에서 키워드를 추출합니다.
'찾아', '검색', '알려줘' 같은 검색 키워드,
'뭐야', '무엇', '설명' 같은 설명 키워드,
'요약', '정리' 같은 요약 키워드를 감지합니다.

키워드가 명확하게 감지되면 해당 도구로 즉시 라우팅하고,
애매한 경우에만 LLM을 통한 라우팅을 수행합니다.

이를 통해 라우팅 속도를 개선하고,
명확한 경우에는 LLM 호출 비용을 절감할 수 있었습니다.

또한 이전 대화 맥락을 고려하여,
'그것에 대해 더 알려줘' 같은 대명사 참조 질문도
올바르게 라우팅할 수 있습니다.
```

---

## 단일 및 다중 요청 처리
### 페이지 28: AI Agent - 단일요청/다중요청 처리

**PPT 내용:**

**단일 요청과 다중 요청 처리 방식**

**발표 대본:**
```
단일 요청과 다중 요청 처리 방식을 설명드리겠습니다.

단일 요청은 하나의 도구만 실행하는 간단한 경우입니다.
예를 들어, 'Transformer 논문 찾아줘'는
search_paper 도구만 실행합니다.

다중 요청은 여러 작업을 순차적으로 수행하는 경우입니다.
예를 들어, 'Attention 논문을 찾아서 요약해줘'는
먼저 search_paper 도구로 논문을 검색한 후,
그 결과를 summarize 도구로 전달하여 요약합니다.

다중 요청 처리를 위해 도구 간 상태 전달 메커니즘을
구현했습니다. tool_result 필드에 이전 도구의 결과를 저장하고,
다음 도구가 이를 참조하여 작업을 수행합니다.

또한 '논문을 찾고 용어를 설명하고 저장해줘' 같은
3단계 이상의 복잡한 요청도 처리할 수 있도록
재귀적 라우팅 로직을 구현했습니다.

다만 현재 버전에서는 최대 3단계까지만 지원하며,
무한 루프 방지를 위한 안전장치를 포함했습니다.
```

---

## LLM 클라이언트
### 페이지 29: LLM 클라이언트 구현

**PPT 내용:**

**LLM 클라이언트 구조 및 기능**
- 다중 LLM 지원 (OpenAI GPT-4, Solar Pro2)
- 에러 핸들링 및 재시도
- 토큰 사용량 추적
- 스트리밍 응답 지원

**발표 대본:**
```
LLM 클라이언트 구현을 설명드리겠습니다.

LLMClient 클래스를 구현하여 여러 LLM을 통합적으로 관리합니다.

난이도에 따라 다른 모델을 사용합니다.
Easy 모드는 Solar Pro2를 사용하여 비용을 절감하고,
Hard 모드는 GPT-4를 사용하여 높은 품질의 답변을 제공합니다.

에러 핸들링을 위해 Tenacity 라이브러리를 사용하여
API 호출 실패 시 지수 백오프 방식으로 최대 3회 재시도합니다.
2초, 4초, 8초로 대기 시간을 늘려가며 재시도하여
일시적인 네트워크 문제를 극복합니다.

토큰 사용량을 추적하여 비용을 모니터링합니다.
OpenAI의 get_openai_callback을 사용하여
각 호출마다 입력 토큰, 출력 토큰, 총 비용을 기록합니다.

Streamlit UI에서 실시간 응답을 제공하기 위해
스트리밍 기능을 구현했습니다.
astream 메서드로 청크 단위로 응답을 받아
사용자에게 점진적으로 표시합니다.

이를 통해 사용자는 기다리는 동안 답변이 생성되는 과정을
실시간으로 볼 수 있어 더 나은 UX를 제공합니다.
```

---

## 멀티턴 대화 메모리
### 페이지 30: 멀티턴 대화 메모리 시스템

**PPT 내용:**

**대화 메모리 시스템**
- ConversationBufferMemory 사용
- 대화 히스토리 관리
- 컨텍스트 윈도우 최적화

**발표 대본:**
```
멀티턴 대화 메모리 시스템을 설명드리겠습니다.

ChatMemoryManager 클래스를 구현하여
이전 대화 내용을 기억하고 맥락을 유지합니다.

LangChain의 ConversationBufferMemory를 사용하여
사용자 메시지와 AI 메시지를 순서대로 저장합니다.

각 턴마다 사용자 질문과 AI 답변을 add_user_message,
add_ai_message 메서드로 추가하여 히스토리를 누적합니다.

컨텍스트 윈도우 최적화를 위해 최근 5턴까지만 유지하고,
그 이전 대화는 요약하여 저장합니다.

이를 통해 '그것에 대해 더 알려줘', '앞에서 말한 논문'
같은 대명사 참조나 생략된 주어를 이해하고
적절한 답변을 제공할 수 있습니다.

또한 PostgreSQL chat_history 테이블에
모든 대화를 영구 저장하여,
세션이 종료되어도 대화를 이어갈 수 있도록 했습니다.
```

---

## RAG 시스템
### 페이지 31: RAG 시스템 구현

**PPT 내용:**

**RAG 시스템 3단계**
1. Indexing: 논문 청크 임베딩 및 저장
2. Retrieval: 유사도 검색 (MMR, MultiQuery)
3. Generation: 난이도별 답변 생성

**발표 대본:**
```
RAG 시스템 구현을 설명드리겠습니다.

RAG는 Retrieval, Augmented, Generation의 3단계로 구성됩니다.

첫째, Indexing 단계입니다.
논문을 1000자 단위로 청크로 나누고,
OpenAI text-embedding-3-small 모델로 임베딩을 생성하여
pgvector에 저장합니다.

둘째, Retrieval 단계입니다.
사용자 질문을 같은 임베딩 모델로 벡터화하고,
pgvector에서 코사인 유사도 기반으로 상위 5개 청크를 검색합니다.

검색 품질을 높이기 위해 두 가지 기법을 사용합니다.
MMR(Maximal Marginal Relevance)로 관련성과 다양성의 균형을 맞추고,
MultiQuery로 질문을 3-5개 변형하여 검색 결과를 확장합니다.

예를 들어, 'Transformer 설명해줘'를
'Transformer 아키텍처란?', 'Attention Is All You Need 논문',
'Transformer 모델의 핵심 메커니즘'으로 확장하여 검색합니다.

셋째, Generation 단계입니다.
검색된 청크를 컨텍스트로 LLM에 전달하고,
난이도에 따른 프롬프트와 함께 답변을 생성합니다.

Easy 모드는 쉬운 용어와 비유를 사용하고,
Hard 모드는 기술적 세부사항과 수식을 포함합니다.

이러한 3단계 RAG 파이프라인으로
정확하고 난이도에 맞는 답변을 제공할 수 있었습니다.
```

---

## 도구 시스템 - 기능 소개
### 페이지 32: Tools - 도구 기능 소개 및 하이브리드 도구 패턴

**PPT 내용:**

**7가지 도구 소개**
- 각 도구의 역할과 특징
- 하이브리드 도구 패턴

**발표 대본:**
```
도구 시스템의 기능과 하이브리드 패턴을 설명드리겠습니다.

저희는 7가지 도구를 구현했습니다.

RAG 논문 검색 도구는 로컬 Vector DB에서 논문을 검색하고,
RAG 용어집 도구는 전문 용어를 난이도별로 설명합니다.

웹 검색 도구는 Tavily API로 최신 논문을 실시간 검색하고,
논문 요약 도구는 긴 논문을 난이도별로 요약합니다.

Text2SQL 도구는 자연어 통계 질문을 SQL로 변환하여
정확한 통계를 제공하고,
파일 저장 도구는 대화 내용을 텍스트 파일로 저장합니다.

일반 답변 도구는 적절한 도구를 찾지 못했을 때
LLM의 자체 지식으로 답변하는 fall-back 역할을 합니다.

하이브리드 도구 패턴도 구현했습니다.
용어집 도구는 PostgreSQL 직접 검색과 Vector 검색을 결합합니다.
먼저 PostgreSQL에서 정확한 매칭을 시도하고,
실패하면 Vector DB에서 유사한 용어를 검색합니다.

이러한 하이브리드 접근으로 정확도와 유연성을
동시에 확보할 수 있었습니다.
```

---

## 요약

**개발 및 구현 파트 대본 작성 완료 (페이지 22-32)**

- 각 페이지마다 PPT 내용 요약과 발표 대본 포함
- 전체 아키텍처, 로깅 시스템, 데이터 수집 파이프라인
- AI Agent 시스템, LLM 클라이언트, 대화 메모리
- RAG 시스템, 도구 시스템 하이브리드 패턴
- modularization 폴더의 구현 문서 참조

**다음 페이지 (33-47):**
- 도구 자동 전환
- 각 도구별 상세 구현 (RAG, 용어집, 웹 검색, 요약, Text2SQL, 저장, 일반)
- 성능 평가 시스템
- Streamlit UI
- 프롬프트 엔지니어링
- 골든 데이터셋
