# ==========================================
# ğŸ“˜ Phase 3: ìš©ì–´ì§‘ ì‹œìŠ¤í…œ êµ¬í˜„
# ğŸ“ Step 5: ìš©ì–´ì§‘ ë„êµ¬(@tool) + í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ + Agent ë…¸ë“œ í†µí•©
# ------------------------------------------
# - @tool: search_glossary (hybrid/sql/vector)
# - PostgreSQL(ILIKE/í•„í„°) + PGVector(ìœ ì‚¬ë„) ë³‘í•©
# - ë‚œì´ë„ ëª¨ë“œ(easy/hard/auto)ë¡œ ì„¤ëª… ì„ íƒ
# - Agent ë…¸ë“œ í†µí•©: glossary_node
# ==========================================

# ------------------------- í‘œì¤€ ë¼ì´ë¸ŒëŸ¬ë¦¬ ------------------------- #
import os
from typing import Any, Dict, List, Optional, Tuple

# ------------------------- ì„œë“œíŒŒí‹° ë¼ì´ë¸ŒëŸ¬ë¦¬ ------------------------- #
import psycopg2
from psycopg2.extras import RealDictCursor
from langchain_core.tools import tool
from langchain_core.documents import Document
from langchain_openai import OpenAIEmbeddings
from langchain_postgres.vectorstores import PGVector

# ------------------------- í”„ë¡œì íŠ¸ ëª¨ë“ˆ ------------------------- #
from src.utils.config_loader import get_postgres_connection_string, get_db_config
from src.prompts import get_tool_prompt
from src.llm.client import LLMClient
from langchain.schema import SystemMessage, HumanMessage


# ==================== ìš©ì–´ ì¶”ì¶œ ìœ í‹¸ë¦¬í‹° ==================== #

def _extract_term_from_question(question: str) -> str:
    """
    ì§ˆë¬¸ì—ì„œ í•µì‹¬ ìš©ì–´ ì¶”ì¶œ

    Args:
        question: ì‚¬ìš©ì ì§ˆë¬¸ (ì˜ˆ: "BLEU Scoreê°€ ë­ì•¼?")

    Returns:
        ì¶”ì¶œëœ ìš©ì–´ (ì˜ˆ: "BLEU Score")

    ì²˜ë¦¬ ê·œì¹™:
    - "ê°€ ë­ì•¼", "ì´ ë­ì•¼", "ëŠ” ë­ì•¼" ë“± ì¡°ì‚¬ ì œê±°
    - ë¬¼ìŒí‘œ ì œê±°
    - ì–‘ìª½ ê³µë°± ì œê±°
    """
    import re

    # ì›ë³¸ ë³´ì¡´
    term = question.strip()

    # í•œêµ­ì–´ ì§ˆë¬¸ íŒ¨í„´ ì œê±° (ìˆœì„œ ì¤‘ìš”: ê¸´ íŒ¨í„´ë¶€í„° ë§¤ì¹­)
    patterns = [
        r'ì—\s*ëŒ€í•´(ì„œ)?\s*ì„¤ëª…í•´[ì¤˜ì£¼ì„¸ìš”]*\??',
        r'ì—\s*ëŒ€í•´(ì„œ)?\s*ì•Œë ¤[ì¤˜ì£¼ì„¸ìš”]*\??',
        r'[ì´ê°€]\s*ë¬´ì—‡ì¸ê°€ìš”?\??',
        r'[ì€ëŠ”]\s*ë¬´ì—‡ì¸ê°€ìš”?\??',
        r'[ì´ê°€]\s*ë­ì•¼\??',
        r'[ì€ëŠ”]\s*ë­ì•¼\??',
        r'[ì„ë¥¼]\s*ì„¤ëª…í•´[ì¤˜ì£¼ì„¸ìš”]*\??',
        r'[ì„ë¥¼]\s*ì•Œë ¤[ì¤˜ì£¼ì„¸ìš”]*\??',
        r'\s*ë­ì•¼\??',
        r'\s*ì •ì˜\??',
        r'\s*ì˜ë¯¸\??',
    ]

    for pattern in patterns:
        term = re.sub(pattern, '', term, flags=re.IGNORECASE | re.UNICODE)

    # ë¬¼ìŒí‘œ ì œê±°
    term = term.replace('?', '').replace('ï¼Ÿ', '')

    # ì–‘ìª½ ê³µë°± ì œê±°
    term = term.strip()

    return term


# ==================== í™˜ê²½/ì»¤ë„¥ì…˜ ìœ í‹¸ë¦¬í‹° ==================== #

def _env(primary: str, alt: str, default: Optional[str] = None) -> Optional[str]:
    """
    í™˜ê²½ë³€ìˆ˜ ì½ê¸° í—¬í¼ í•¨ìˆ˜

    Args:
        primary: ìš°ì„ ìˆœìœ„ í™˜ê²½ë³€ìˆ˜ëª…
        alt: ëŒ€ì²´ í™˜ê²½ë³€ìˆ˜ëª…
        default: ê¸°ë³¸ê°’

    Returns:
        í™˜ê²½ë³€ìˆ˜ ê°’
    """
    return os.getenv(primary) or os.getenv(alt) or default


def _pg_conn_str() -> str:
    """
    PostgreSQL ì—°ê²° ë¬¸ìì—´ ìƒì„±

    configs/db_config.yaml ì„¤ì •ì„ ìš°ì„  ì‚¬ìš©í•˜ê³ ,
    ì—†ìœ¼ë©´ í™˜ê²½ë³€ìˆ˜ë¡œ í´ë°±

    Returns:
        PostgreSQL ì—°ê²° ë¬¸ìì—´
    """
    try:
        # configs/db_config.yaml ì‚¬ìš© (ê¶Œì¥)
        return get_postgres_connection_string()
    except Exception:
        # í™˜ê²½ë³€ìˆ˜ í´ë°±
        user = _env("POSTGRES_USER", "PGUSER", "postgres")
        password = _env("POSTGRES_PASSWORD", "PGPASSWORD", "postgres")
        host = _env("POSTGRES_HOST", "PGHOST", "localhost")
        port = _env("POSTGRES_PORT", "PGPORT", "5432")
        db = _env("POSTGRES_DB", "PGDATABASE", "papers")
        return f"postgresql://{user}:{password}@{host}:{port}/{db}"


def _get_glossary_vectorstore() -> PGVector:
    """
    ìš©ì–´ì§‘ ì „ìš© VectorStore ì´ˆê¸°í™”

    Returns:
        PGVector ì¸ìŠ¤í„´ìŠ¤ (glossary_embeddings ì»¬ë ‰ì…˜)
    """
    # PostgreSQL ì—°ê²° ë¬¸ìì—´ ê°€ì ¸ì˜¤ê¸°
    conn_str = _pg_conn_str()

    # ì»¬ë ‰ì…˜ëª… ê°€ì ¸ì˜¤ê¸° (í™˜ê²½ë³€ìˆ˜ ë˜ëŠ” ê¸°ë³¸ê°’)
    collection = os.getenv("PGV_COLLECTION_GLOSSARY", "glossary_embeddings")

    # Embeddings ì´ˆê¸°í™”
    embeddings = OpenAIEmbeddings(
        model=os.getenv("EMBEDDING_MODEL", "text-embedding-3-small")
    )

    # PGVector VectorStore ìƒì„±
    return PGVector(
        collection_name=collection,
        embeddings=embeddings,
        connection=conn_str,
        use_jsonb=True,
    )


# ==================== SQL 1ì°¨ ì¡°íšŒ ==================== #

def _fetch_glossary_sql(
    query: Optional[str],
    category: Optional[str],
    difficulty: Optional[str],
    limit: int,
) -> List[Dict[str, Any]]:
    """
    PostgreSQL glossary í…Œì´ë¸”ì—ì„œ ê²€ìƒ‰

    Args:
        query: ê²€ìƒ‰ ì¿¼ë¦¬ (term, definition, explanationì—ì„œ ILIKE ê²€ìƒ‰)
        category: ì¹´í…Œê³ ë¦¬ í•„í„°
        difficulty: ë‚œì´ë„ í•„í„° (beginner/intermediate/advanced)
        limit: ìµœëŒ€ ê²°ê³¼ ìˆ˜

    Returns:
        ê²€ìƒ‰ ê²°ê³¼ ë¦¬ìŠ¤íŠ¸ (ë”•ì…”ë„ˆë¦¬)
    """
    # PostgreSQL ì—°ê²°
    conn = psycopg2.connect(_pg_conn_str())

    try:
        # WHERE ì ˆ ì¡°ê±´ êµ¬ì„±
        where = []
        params: List[Any] = []

        # ì¿¼ë¦¬ í•„í„° (term, definition, easy_explanation, hard_explanationì—ì„œ ê²€ìƒ‰)
        if query:
            where.append("(term ILIKE %s OR definition ILIKE %s OR easy_explanation ILIKE %s OR hard_explanation ILIKE %s)")
            like = f"%{query}%"
            params.extend([like, like, like, like])

        # ì¹´í…Œê³ ë¦¬ í•„í„°
        if category:
            where.append("category = %s")
            params.append(category)

        # ë‚œì´ë„ í•„í„°
        if difficulty:
            where.append("difficulty_level = %s")
            params.append(difficulty)

        # SQL ì¿¼ë¦¬ êµ¬ì„±
        sql = """
            SELECT term_id, term, definition, easy_explanation, hard_explanation,
                   category, difficulty_level, related_terms, examples, created_at, updated_at
            FROM glossary
        """
        if where:
            sql += " WHERE " + " AND ".join(where)
        sql += " ORDER BY term_id ASC LIMIT %s"
        params.append(limit)

        # ì¿¼ë¦¬ ì‹¤í–‰
        with conn.cursor(cursor_factory=RealDictCursor) as cur:
            cur.execute(sql, tuple(params))
            rows = cur.fetchall()
            return [dict(r) for r in rows]

    finally:
        # ì—°ê²° ì¢…ë£Œ
        conn.close()


# ==================== Vector 2ì°¨ ì¡°íšŒ ==================== #

def _vector_search_glossary(query: str, k: int) -> List[Tuple[Document, float]]:
    """
    Vector DBì—ì„œ ìš©ì–´ì§‘ ìœ ì‚¬ë„ ê²€ìƒ‰

    Args:
        query: ê²€ìƒ‰ ì¿¼ë¦¬
        k: ë°˜í™˜í•  ë¬¸ì„œ ìˆ˜

    Returns:
        (Document, score) íŠœí”Œ ë¦¬ìŠ¤íŠ¸
    """
    # VectorStore ì´ˆê¸°í™”
    vs = _get_glossary_vectorstore()

    # ìœ ì‚¬ë„ ê²€ìƒ‰ + ì ìˆ˜ ë°˜í™˜
    pairs = vs.similarity_search_with_score(query, k=k)

    return pairs


# ==================== ê²°ê³¼ í¬ë§·/ì„¤ëª… ì„ íƒ ==================== #

def _pick_explanation(row: Dict[str, Any], difficulty_mode: str) -> str:
    """
    ë‚œì´ë„ ëª¨ë“œì— ë§ëŠ” ì„¤ëª… ì„ íƒ

    Args:
        row: glossary í…Œì´ë¸” í–‰ (ë”•ì…”ë„ˆë¦¬)
        difficulty_mode: 'easy' | 'hard' | 'auto'

    Returns:
        ì„ íƒëœ ì„¤ëª… í…ìŠ¤íŠ¸
    """
    # Easy ëª¨ë“œ: easy_explanation ìš°ì„ 
    if difficulty_mode == "easy":
        return row.get("easy_explanation") or row.get("definition") or ""

    # Hard ëª¨ë“œ: hard_explanation ìš°ì„ 
    if difficulty_mode == "hard":
        return row.get("hard_explanation") or row.get("definition") or ""

    # Auto ëª¨ë“œ: difficulty_level ê¸°ì¤€ ìë™ ì„ íƒ
    level = (row.get("difficulty_level") or "").lower()
    if level in ("beginner", "intermediate") and row.get("easy_explanation"):
        return row["easy_explanation"]
    if level == "advanced" and row.get("hard_explanation"):
        return row["hard_explanation"]

    # Fallback: easy â†’ hard â†’ definition ìˆœì„œ
    return row.get("easy_explanation") or row.get("hard_explanation") or row.get("definition") or ""


def _format_glossary_md(items: List[Dict[str, Any]]) -> str:
    """
    ê²€ìƒ‰ ê²°ê³¼ë¥¼ Markdown í˜•ì‹ìœ¼ë¡œ í¬ë§·íŒ…

    Args:
        items: ê²€ìƒ‰ ê²°ê³¼ ë¦¬ìŠ¤íŠ¸ (ë”•ì…”ë„ˆë¦¬)

    Returns:
        Markdown í˜•ì‹ ë¬¸ìì—´
    """
    # ê²°ê³¼ê°€ ì—†ìœ¼ë©´ ì•ˆë‚´ ë©”ì‹œì§€ ë°˜í™˜
    if not items:
        return "ê´€ë ¨ ìš©ì–´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."

    # Markdown ë¬¸ìì—´ êµ¬ì„±
    out: List[str] = ["## ìš©ì–´ì§‘ ê²€ìƒ‰ ê²°ê³¼\n"]

    for i, r in enumerate(items, 1):
        # ìš©ì–´ëª…
        out.append(f"### {i}. {r.get('term','(term)')}")

        # ì¹´í…Œê³ ë¦¬
        out.append(f"- **ì¹´í…Œê³ ë¦¬**: {r.get('category','')}")

        # ë‚œì´ë„
        out.append(f"- **ë‚œì´ë„**: {r.get('difficulty_level','')}")

        # ìœ ì‚¬ë„ ì ìˆ˜ (ìˆìœ¼ë©´)
        if r.get("score") is not None:
            out.append(f"- **ìœ ì‚¬ë„ ì ìˆ˜(ë‚®ì„ìˆ˜ë¡ ìœ ì‚¬)**: {r['score']:.4f}")

        # ì—°ê´€ ìš©ì–´ (ìˆìœ¼ë©´)
        if r.get("related_terms"):
            related = ', '.join(r['related_terms']) if isinstance(r['related_terms'], list) else r['related_terms']
            out.append(f"- **ì—°ê´€ ìš©ì–´**: {related}")

        # ì˜ˆì‹œ (ìˆìœ¼ë©´)
        if r.get("examples"):
            out.append(f"- **ì˜ˆì‹œ**: {r['examples']}")

        # ì •ì˜
        if r.get("definition"):
            out.append(f"- **ì •ì˜**: {r['definition']}")

        # ì„¤ëª…
        if r.get("explanation"):
            out.append(f"\n{r['explanation']}\n")

        # êµ¬ë¶„ì„ 
        out.append("\n---\n")

    return "\n".join(out)


# ==================== @tool: ìš©ì–´ì§‘ ê²€ìƒ‰ ë„êµ¬ ==================== #

@tool
def search_glossary(
    query: Optional[str] = None,
    category: Optional[str] = None,
    difficulty: str = "auto",  # 'easy' | 'hard' | 'auto'
    mode: str = "hybrid",      # 'hybrid' | 'sql' | 'vector'
    top_k: int = 5,
    with_scores: bool = True,
) -> str:
    """
    ìš©ì–´ì§‘ ê²€ìƒ‰ ë„êµ¬ (í•˜ì´ë¸Œë¦¬ë“œ/SQL/Vector ì§€ì›)

    Args:
        query: ê²€ìƒ‰ ì¿¼ë¦¬
        category: ì¹´í…Œê³ ë¦¬ í•„í„°
        difficulty: ë‚œì´ë„ ëª¨ë“œ ('easy', 'hard', 'auto')
        mode: ê²€ìƒ‰ ëª¨ë“œ ('hybrid', 'sql', 'vector')
        top_k: ìµœëŒ€ ê²°ê³¼ ìˆ˜
        with_scores: ìœ ì‚¬ë„ ì ìˆ˜ í¬í•¨ ì—¬ë¶€

    Returns:
        Markdown í˜•ì‹ ê²€ìƒ‰ ê²°ê³¼

    ê²€ìƒ‰ ë°©ì‹:
    - SQL: PostgreSQL ILIKE + í•„í„°
    - Vector: glossary_embeddings ì»¬ë ‰ì…˜ ìœ ì‚¬ë„ ê²€ìƒ‰
    - hybrid: SQL + Vector ê²°ê³¼ ë³‘í•© í›„ ì¤‘ë³µ ì œê±°
    """
    # ---------------------- ì§ˆë¬¸ì—ì„œ í•µì‹¬ ìš©ì–´ ì¶”ì¶œ ---------------------- #
    # "BLEU Scoreê°€ ë­ì•¼?" -> "BLEU Score"
    if query:
        query = _extract_term_from_question(query)

    items: List[Dict[str, Any]] = []

    # ---------------------- Vector ê²€ìƒ‰ ---------------------- #
    if mode in ("hybrid", "vector") and query:
        try:
            # Vector DB ìœ ì‚¬ë„ ê²€ìƒ‰
            vector_pairs = _vector_search_glossary(query, k=top_k)

            # ê²°ê³¼ ë³€í™˜
            for doc, score in vector_pairs:
                md = doc.metadata or {}
                row = {
                    "term": md.get("term") or md.get("title") or "",
                    "category": md.get("category"),
                    "difficulty_level": md.get("difficulty_level"),
                    "related_terms": md.get("related_terms"),
                    "examples": md.get("examples"),
                    "definition": md.get("definition"),
                    "explanation": _pick_explanation(md, difficulty),
                    "score": float(score) if with_scores else None,
                }
                items.append(row)

        except Exception:
            # ë²¡í„° ì¸ë±ìŠ¤ê°€ ë¹„ì–´ ìˆê±°ë‚˜ ì»¬ë ‰ì…˜ ë¯¸ìƒì„± ì‹œ ì¡°ìš©íˆ íŒ¨ìŠ¤
            # hybrid ëª¨ë“œë©´ SQL ê²°ê³¼ë¡œ ë³´ì™„
            pass

    # ---------------------- SQL ê²€ìƒ‰ ---------------------- #
    if mode in ("hybrid", "sql"):
        # difficulty_level ê°’ ë³€í™˜ (easy/hard â†’ beginner/advanced)
        sql_difficulty = None
        if difficulty in ("beginner", "intermediate", "advanced"):
            sql_difficulty = difficulty

        # PostgreSQL ê²€ìƒ‰
        sql_rows = _fetch_glossary_sql(
            query=query,
            category=category,
            difficulty=sql_difficulty,
            limit=top_k,
        )

        # ê²°ê³¼ ë³€í™˜
        for r in sql_rows:
            items.append({
                "term": r.get("term"),
                "category": r.get("category"),
                "difficulty_level": r.get("difficulty_level"),
                "related_terms": r.get("related_terms"),
                "examples": r.get("examples"),
                "definition": r.get("definition"),
                "explanation": _pick_explanation(r, difficulty),
                "score": None,
            })

    # ---------------------- ì¤‘ë³µ ì œê±° ---------------------- #
    seen = set()
    uniq: List[Dict[str, Any]] = []

    for it in items:
        # (term, definition) ì¡°í•©ìœ¼ë¡œ ì¤‘ë³µ ì²´í¬
        key = (it.get("term"), it.get("definition"))
        if key not in seen:
            seen.add(key)
            uniq.append(it)

    # ---------------------- top_k ë³´ì¥ ë° í¬ë§·íŒ… ---------------------- #
    return _format_glossary_md(uniq[:top_k])


# ==================== Agent ë…¸ë“œ: ìš©ì–´ì§‘ ê²€ìƒ‰ ==================== #

def glossary_node(state, exp_manager=None):
    """
    Agent ë…¸ë“œ: glossary í…Œì´ë¸”ì—ì„œ ìš©ì–´ ì •ì˜ ê²€ìƒ‰

    Args:
        state (AgentState): Agent ìƒíƒœ
        exp_manager: ExperimentManager ì¸ìŠ¤í„´ìŠ¤ (ì„ íƒ ì‚¬í•­)

    Returns:
        AgentState: ì—…ë°ì´íŠ¸ëœ ìƒíƒœ
    """
    # -------------- ìƒíƒœì—ì„œ ì§ˆë¬¸ ë° ë‚œì´ë„ ì¶”ì¶œ -------------- #
    question = state["question"]                          # ì‚¬ìš©ì ì§ˆë¬¸
    difficulty = state.get("difficulty", "easy")          # ë‚œì´ë„ (ê¸°ë³¸ê°’: easy)

    # -------------- ë„êµ¬ë³„ Logger ìƒì„± -------------- #
    tool_logger = exp_manager.get_tool_logger('rag_glossary') if exp_manager else None

    if tool_logger:
        tool_logger.write(f"ìš©ì–´ì§‘ ë…¸ë“œ ì‹¤í–‰: {question}")
        tool_logger.write(f"ë‚œì´ë„: {difficulty}")

    # -------------- search_glossary ë„êµ¬ í˜¸ì¶œ -------------- #
    try:
        # Langchain @tool í•¨ìˆ˜ í˜¸ì¶œ
        raw_results = search_glossary.invoke({
            "query": question,                            # ê²€ìƒ‰ ì¿¼ë¦¬
            "category": None,                             # ì¹´í…Œê³ ë¦¬ í•„í„° ì—†ìŒ
            "difficulty": difficulty,                     # ë‚œì´ë„ ëª¨ë“œ
            "mode": "hybrid",                             # í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰
            "top_k": 3,                                   # ìµœëŒ€ 3ê°œ ê²°ê³¼
            "with_scores": True,                          # ìœ ì‚¬ë„ ì ìˆ˜ í¬í•¨
        })

        if tool_logger:
            tool_logger.write(f"ê²€ìƒ‰ ê²°ê³¼: {len(raw_results)} ê¸€ì")

        # -------------- JSON í”„ë¡¬í”„íŠ¸ ë¡œë“œ -------------- #
        system_prompt = get_tool_prompt("glossary", difficulty)  # JSON íŒŒì¼ì—ì„œ ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ ë¡œë“œ

        # -------------- ë‚œì´ë„ë³„ LLM ì´ˆê¸°í™” -------------- #
        llm_client = LLMClient.from_difficulty(
            difficulty=difficulty,
            logger=exp_manager.logger if exp_manager else None
        )

        # -------------- ë©”ì‹œì§€ êµ¬ì„± -------------- #
        user_content = f"""[ìš©ì–´ì§‘ ê²€ìƒ‰ ê²°ê³¼]
{raw_results}

[ì§ˆë¬¸]
{question}

ìœ„ ê²€ìƒ‰ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì§ˆë¬¸ì— ë‹µë³€í•´ì£¼ì„¸ìš”."""

        messages = [
            SystemMessage(content=system_prompt),  # ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸
            HumanMessage(content=user_content)     # ê²€ìƒ‰ ê²°ê³¼ + ì§ˆë¬¸
        ]

        if tool_logger:
            tool_logger.write("LLM ë‹µë³€ ìƒì„± ì‹œì‘")

        # -------------- LLM í˜¸ì¶œ -------------- #
        response = llm_client.llm.invoke(messages)  # LLM ì‘ë‹µ ìƒì„±

        if tool_logger:
            tool_logger.write(f"ë‹µë³€ ìƒì„± ì™„ë£Œ: {len(response.content)} ê¸€ì")
            tool_logger.write("=" * 80)
            tool_logger.write("[LLM ë‹µë³€ ì „ì²´ ë‚´ìš©]")
            tool_logger.write(response.content)
            tool_logger.write("=" * 80)
            tool_logger.close()

        # -------------- ìµœì¢… ë‹µë³€ ì €ì¥ -------------- #
        state["final_answer"] = response.content    # ë‹µë³€ ì €ì¥

    except Exception as e:
        if tool_logger:
            tool_logger.write(f"ìš©ì–´ì§‘ ê²€ìƒ‰ ì‹¤íŒ¨: {e}")
            tool_logger.close()

        # ì—ëŸ¬ ë©”ì‹œì§€ ì €ì¥
        state["final_answer"] = f"ìš©ì–´ì§‘ ê²€ìƒ‰ ì˜¤ë¥˜: {str(e)}"

    # -------------- ì—…ë°ì´íŠ¸ëœ ìƒíƒœ ë°˜í™˜ -------------- #
    return state
