# 자료조사: 기술 스택 비교

## 문서 정보
- **작성일**: 2025-10-29
- **프로젝트**: 논문 리뷰 챗봇 (AI Agent + RAG)
- **팀명**: 연결의 민족

---

## 1. LLM API 비교: OpenAI vs Solar (Upstage)

### 1.1 OpenAI API

#### 장점
1. **높은 성능과 정확도**
   - GPT-4, GPT-4 Turbo, GPT-3.5 등 다양한 모델 제공
   - 복잡한 논문 내용 이해 및 분석에 뛰어난 성능
   - Function Calling, Tool Use 기능이 안정적이고 정교함

2. **풍부한 생태계**
   - Langchain, LlamaIndex 등 주요 프레임워크와 완벽한 호환
   - 방대한 커뮤니티와 문서, 예제 코드
   - 다양한 라이브러리 및 튜토리얼 지원

3. **다국어 지원**
   - 한국어 논문 리뷰에 적합한 한국어 처리 능력
   - 영어 논문의 정확한 번역 및 해석

4. **긴 컨텍스트 윈도우**
   - GPT-4 Turbo: 128K 토큰 (논문 전체 처리 가능)
   - GPT-4: 8K/32K 토큰

#### 단점
1. **비용**
   - GPT-4: $0.03/1K tokens (input), $0.06/1K tokens (output)
   - GPT-3.5-turbo: $0.0015/1K tokens (input), $0.002/1K tokens (output)
   - 사용량에 따라 비용 증가

2. **API 속도**
   - Solar API 대비 응답 속도가 다소 느릴 수 있음

#### 우리 팀 선택 이유
- **논문 리뷰 챗봇의 특성상 정확도와 이해도가 가장 중요**
- 복잡한 학술 용어와 논리적 구조 분석에 우수한 성능 필요
- AI Agent의 도구 호출 및 판단 능력이 뛰어남
- 비용보다 품질을 우선시하는 프로젝트 목표

---

### 1.2 Solar API (Upstage)

#### 장점
1. **비용 효율성**
   - 교육용 크레딧 제공
   - 상대적으로 저렴한 가격

2. **빠른 응답 속도**
   - 국내 서버 기반으로 낮은 레이턴시

3. **한국어 특화**
   - 한국어 데이터로 학습된 모델

#### 단점
1. **제한적인 성능**
   - OpenAI GPT-4 대비 복잡한 추론 능력 부족
   - 논문 분석 같은 고도의 작업에서 정확도 낮을 수 있음

2. **생태계 제한**
   - 상대적으로 적은 예제 및 커뮤니티 지원

3. **Function Calling 안정성**
   - OpenAI 대비 도구 호출 정확도가 낮을 수 있음

---

## 2. 데이터베이스 비교

### 2.1 MySQL (팀원들이 고려한 선택)

#### 장점
1. **팀원 친숙도**
   - 모든 팀원이 사용 경험 있음
   - 학습 곡선이 낮음

2. **관계형 데이터 관리**
   - 논문 메타데이터 (저자, 출판일, 키워드, 인용 수 등) 구조화 저장
   - ACID 트랜잭션 보장

3. **Text-to-SQL 지원**
   - LLM을 통한 자연어 쿼리 변환 가능

#### 단점
1. **벡터 검색 미지원**
   - RAG를 위한 임베딩 벡터 저장/검색 불가능
   - 별도의 Vector DB 필요

2. **확장성 제한**
   - 대용량 논문 데이터 처리 시 성능 저하 가능

---

### 2.2 PostgreSQL + pgvector (추천)

#### 장점
1. **통합 DB 솔루션**
   - 관계형 데이터 + 벡터 검색을 하나의 DB에서 처리
   - pgvector 확장을 통한 벡터 유사도 검색 지원

2. **성능**
   - MySQL보다 복잡한 쿼리 처리 성능 우수
   - 인덱싱 및 최적화 기능 강력

3. **Langchain 지원**
   - Langchain의 PostgreSQL Vector Store 완벽 지원
   - 예제 코드 풍부

4. **오픈소스**
   - 무료 사용 가능
   - 활발한 커뮤니티

#### 단점
1. **학습 곡선**
   - MySQL 대비 설정 및 사용법이 약간 복잡
   - pgvector 확장 설치 필요

#### 사용 예시
```python
from langchain.vectorstores import PGVector

# PostgreSQL + pgvector를 Vector Store로 사용
vectorstore = PGVector(
    connection_string="postgresql://user:password@localhost:5432/papers",
    embedding_function=embeddings,
    collection_name="paper_embeddings"
)
```

---

### 2.3 하이브리드 구조 (이전 고려사항)

**구조**: PostgreSQL (관계형) + 별도 벡터 DB

#### PostgreSQL 역할
- 논문 메타데이터 저장 (제목, 저자, 출판일, 키워드, 카테고리, URL 등)
- 논문 통계 정보 (조회수, 인용 수 등)
- 용어집(Glossary) 테이블 관리
- Text-to-SQL 기능 활용

#### 벡터 DB 역할
- 논문 본문 임베딩 벡터 저장
- 빠른 의미 기반 검색 (Semantic Search)

#### 장점
1. **각 DB의 장점 활용**
   - 구조화된 데이터는 PostgreSQL
   - 비구조화된 텍스트 임베딩은 벡터 DB

2. **개발 편의성**
   - 벡터 DB는 설치 및 사용이 간단
   - PostgreSQL은 복잡한 쿼리 처리에 적합

3. **확장성**
   - 향후 필요에 따라 각각 독립적으로 확장 가능

#### 스키마 예시

**PostgreSQL 테이블**
```sql
-- 논문 메타데이터
CREATE TABLE papers (
    paper_id SERIAL PRIMARY KEY,
    title VARCHAR(500) NOT NULL,
    authors TEXT,
    publish_date DATE,
    source VARCHAR(100),  -- arXiv, IEEE, etc.
    url TEXT,
    category VARCHAR(100),
    citation_count INT DEFAULT 0,
    abstract TEXT,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

-- 논문 용어집
CREATE TABLE glossary (
    term_id SERIAL PRIMARY KEY,
    term VARCHAR(200) NOT NULL UNIQUE,
    definition TEXT NOT NULL,
    category VARCHAR(100),  -- ML, NLP, CV, etc.
    difficulty_level VARCHAR(20),  -- easy, medium, hard
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

-- 사용자 질의 로그
CREATE TABLE query_logs (
    log_id SERIAL PRIMARY KEY,
    user_query TEXT NOT NULL,
    response_mode VARCHAR(20),  -- easy, hard
    agent_tools_used TEXT,
    response_time_ms INT,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);
```

**pgvector 컬렉션**
- `paper_chunks`: 논문 본문을 청크로 나눈 임베딩
- `paper_abstracts`: 논문 초록 임베딩
- `glossary_embeddings`: 용어집 정의 임베딩

---

### 2.4 최종 추천: PostgreSQL + pgvector

**이유:**
1. 하나의 DB로 관계형 + 벡터 검색 모두 처리 가능
2. 운영 및 유지보수 간소화
3. Langchain과 완벽한 통합
4. 짧은 프로젝트 기간에 적합 (설정 단순화)

**결정:** 본 프로젝트에서는 PostgreSQL + pgvector 통합 솔루션을 사용

---

## 3. UI 프레임워크 비교

### 3.1 Streamlit (팀이 선택)

#### 장점
1. **빠른 개발 속도**
   - 순수 Python 코드로 UI 구성
   - 별도의 HTML/CSS/JavaScript 불필요

2. **풍부한 예제**
   - Langchain + Streamlit 조합 예제 많음
   - 유튜브 튜토리얼 풍부 (팀의 선택 이유)

3. **채팅 UI 컴포넌트**
   - `st.chat_message`, `st.chat_input` 등 채팅봇에 최적화된 위젯
   - 멀티턴 대화 UI 구현 쉬움

4. **세션 상태 관리**
   - `st.session_state`로 대화 히스토리 관리 간편

5. **배포 용이성**
   - Streamlit Cloud를 통한 무료 배포 가능

#### 단점
1. **제한적인 커스터마이징**
   - 디자인 커스터마이징이 제한적
   - 복잡한 UI 구현 어려움

2. **성능**
   - 페이지 새로고침 시 전체 스크립트 재실행
   - 대규모 데이터 처리 시 느릴 수 있음

#### 사용 예시
```python
import streamlit as st

st.title("논문 리뷰 챗봇")

# 난이도 선택
difficulty = st.selectbox("답변 난이도", ["Easy 모드 (초심자)", "Hard 모드 (전문가)"])

# 채팅 인터페이스
if "messages" not in st.session_state:
    st.session_state.messages = []

for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])

if prompt := st.chat_input("논문에 대해 질문해주세요"):
    st.session_state.messages.append({"role": "user", "content": prompt})
    with st.chat_message("user"):
        st.markdown(prompt)

    # AI Agent 호출
    with st.chat_message("assistant"):
        response = agent.run(prompt, difficulty=difficulty)
        st.markdown(response)
    st.session_state.messages.append({"role": "assistant", "content": response})
```

---

### 3.2 Gradio

#### 장점
1. **더 간결한 코드**
   - Streamlit보다 더 적은 코드로 UI 구성 가능
   - `gr.ChatInterface`로 채팅봇 즉시 구현

2. **Hugging Face 통합**
   - Hugging Face Spaces에 쉽게 배포

3. **다양한 입력 타입**
   - 이미지, 오디오 등 멀티모달 입력 지원

#### 단점
1. **예제 부족**
   - Streamlit 대비 Langchain 통합 예제 적음

2. **세밀한 제어 어려움**
   - UI 커스터마이징 제한적

---

### 3.3 최종 추천: Streamlit

**이유:**
1. 팀원들의 학습 리소스(유튜브) 풍부
2. Langchain과의 통합 예제 많음
3. 멀티턴 대화 및 난이도 선택 UI 구현 용이
4. 짧은 프로젝트 기간에 적합

---

## 4. 기타 기술 스택

### 4.1 벡터 임베딩 모델

**추천: OpenAI `text-embedding-3-small`**
- 비용 효율적 ($0.02 / 1M tokens)
- 높은 정확도
- Langchain 완벽 지원

**대안: `text-embedding-3-large`**
- 더 높은 정확도 필요 시
- 비용: $0.13 / 1M tokens

### 4.2 Vector Store

**추천 순서:**
1. **PostgreSQL + pgvector** (통합 솔루션) ← **선택**
2. **Pinecone** (클라우드 기반, 확장성 우수하지만 비용 발생)
3. **Weaviate** (오픈소스, 자체 호스팅 가능)

### 4.3 웹 검색 API

**AI Agent 도구로 사용:**
- **Tavily Search API** (Langchain 공식 추천, 무료 티어 제공)
- **SerpAPI** (Google 검색 결과, 유료)
- **DuckDuckGo Search** (무료, Langchain 지원)

### 4.4 텍스트 분할 (Text Splitter)

**추천: RecursiveCharacterTextSplitter**
```python
from langchain.text_splitter import RecursiveCharacterTextSplitter

text_splitter = RecursiveCharacterTextSplitter(
    chunk_size=1000,
    chunk_overlap=200,
    separators=["\n\n", "\n", ". ", " ", ""]
)
```

---

## 5. 최종 기술 스택 요약

| 구분 | 선택 기술 | 이유 |
|------|----------|------|
| **LLM API** | OpenAI (GPT-4/GPT-3.5-turbo) | 높은 성능과 정확도, 안정적인 Function Calling |
| **관계형 DB** | PostgreSQL + pgvector | 관계형 + 벡터 검색 통합, 강력한 성능 |
| **벡터 DB** | pgvector (PostgreSQL 내장) | 관계형 DB와 통합, Langchain 지원 |
| **UI 프레임워크** | Streamlit | 빠른 개발, 풍부한 예제, 채팅 UI 최적화 |
| **임베딩 모델** | OpenAI text-embedding-3-small | 비용 효율적, 높은 정확도 |
| **웹 검색 API** | Tavily Search API | AI Agent 도구, 무료 티어 |
| **프레임워크** | Langchain + LangGraph | AI Agent 및 RAG 통합 개발 |

---

## 6. 참고 자료

- OpenAI API Pricing: https://platform.openai.com/docs/pricing
- Upstage Solar API: https://www.upstage.ai/pricing
- PostgreSQL + pgvector: https://github.com/pgvector/pgvector
- Langchain PostgreSQL Vector Store: https://python.langchain.com/docs/integrations/vectorstores/pgvector
- Streamlit 공식 문서: https://docs.streamlit.io/
- Gradio 공식 문서: https://www.gradio.app/docs
- pgvector GitHub: https://github.com/pgvector/pgvector
