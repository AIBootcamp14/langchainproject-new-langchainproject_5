# ==========================================
# ğŸ“˜ Phase 2: ê³ ê¸‰ ê²€ìƒ‰ ê¸°ëŠ¥ + ë„êµ¬ ë ˆì´ì–´
# ğŸ“ Step 4: RAG ê²€ìƒ‰ ë„êµ¬(@tool) êµ¬í˜„
# ------------------------------------------
# - @tool: search_paper_database
# - ê²€ìƒ‰ ëª¨ë“œ ì„ íƒ (similarity/MMR), MultiQuery ì˜µì…˜
# - ë©”íƒ€ë°ì´í„° í•„í„°(year/author/category)
# - PostgreSQL ë©”íƒ€ ì¡°íšŒ â†’ ê²°ê³¼ í•©ì„± â†’ Markdown ë°˜í™˜
# ==========================================

import os
from typing import Any, Dict, List, Optional, Tuple

import psycopg2
from psycopg2.extras import RealDictCursor
from langchain_core.tools import tool
from langchain_core.documents import Document

from src.rag.retriever import RAGRetriever


# ---------- ë‚´ë¶€ ìœ í‹¸: í™˜ê²½/DB ----------

def _env(primary: str, alt: str, default: Optional[str] = None) -> Optional[str]:
    return os.getenv(primary) or os.getenv(alt) or default

def _pg_conn_str() -> str:
    user = _env("POSTGRES_USER", "PGUSER", "postgres")
    password = _env("POSTGRES_PASSWORD", "PGPASSWORD", "postgres")
    host = _env("POSTGRES_HOST", "PGHOST", "localhost")
    port = _env("POSTGRES_PORT", "PGPORT", "5432")
    db = _env("POSTGRES_DB", "PGDATABASE", "papers")
    return f"postgresql://{user}:{password}@{host}:{port}/{db}"

def _fetch_paper_meta(paper_ids: List[int]) -> Dict[int, Dict[str, Any]]:
    """
    papers í…Œì´ë¸”ì—ì„œ ID ëª©ë¡ì— í•´ë‹¹í•˜ëŠ” ë©”íƒ€ë°ì´í„°ë¥¼ ì¼ê´„ ì¡°íšŒ.
    - title/authors/publish_date/url/category/citation_count
    - ê²°ê³¼: {paper_id: {...}}
    """
    if not paper_ids:
        return {}
    conn = psycopg2.connect(_pg_conn_str())
    try:
        with conn.cursor(cursor_factory=RealDictCursor) as cur:
            cur.execute(
                """
                SELECT paper_id, title, authors, publish_date, url, category, citation_count
                FROM papers
                WHERE paper_id = ANY(%s)
                """,
                (paper_ids,),
            )
            rows = cur.fetchall()
            out: Dict[int, Dict[str, Any]] = {}
            for row in rows:
                out[row["paper_id"]] = dict(row)
            return out
    finally:
        conn.close()

def _format_markdown(results: List[Dict[str, Any]]) -> str:
    """ê²€ìƒ‰ ê²°ê³¼ë¥¼ Markdown ë¬¸ìì—´ë¡œ ë³€í™˜."""
    if not results:
        return "ê´€ë ¨ ë…¼ë¬¸ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."

    lines: List[str] = ["## ê²€ìƒ‰ëœ ë…¼ë¬¸\n"]
    for i, r in enumerate(results, 1):
        score_str = f"{r['score']:.4f}" if r.get("score") is not None else "N/A"

        lines.append(f"### {i}. {r.get('title','(Untitled)')}")
        lines.append(f"- **ì €ì**: {r.get('authors','')}")
        lines.append(f"- **ì¶œíŒì¼**: {r.get('publish_date','')}")
        lines.append(f"- **ì¹´í…Œê³ ë¦¬**: {r.get('category','')}")
        lines.append(f"- **ì¸ìš©ìˆ˜**: {r.get('citation_count','')}")
        lines.append(f"- **URL**: {r.get('url','')}")
        lines.append(f"- **ì„¹ì…˜**: {r.get('section','ë³¸ë¬¸')}")
        lines.append(f"- **ìœ ì‚¬ë„ ì ìˆ˜(ë‚®ì„ìˆ˜ë¡ ìœ ì‚¬)**: {score_str}\n")

        preview = (r.get("content") or "")[:600]
        if preview:
            lines.append(preview + ("..." if len(r.get("content","")) > 600 else ""))
        lines.append("\n---\n")

    return "\n".join(lines)

def _build_filter(year_gte: Optional[int], author: Optional[str], category: Optional[str]) -> Dict[str, Any]:
    """VectorStore ë©”íƒ€ë°ì´í„° í•„í„° êµ¬ì„±.
    - ì—°ë„ ì´ìƒ, ì €ì ë¶€ë¶„ì¼ì¹˜, ì¹´í…Œê³ ë¦¬ ë§¤ì¹˜ ë“±
    """
    f: Dict[str, Any] = {}
    if year_gte is not None:
        # ë©”íƒ€ë°ì´í„°ì— 'year' í‚¤ê°€ ìˆë‹¤ê³  ê°€ì • (ì¸ë±ì‹± ì‹œ ë„£ì–´ë‘ë©´ ì¢‹ìŒ)
        f["year"] = {"$gte": int(year_gte)}
    if author:
        # ê°„ë‹¨ ë§¤ì¹­: author ë¬¸ìì—´ì´ metadata.authorsì— í¬í•¨ëœ ë ˆì½”ë“œ
        f["authors"] = {"$ilike": f"%{author}%"}  # langchain-postgresê°€ ILIKEë¥˜ë¥¼ ì§€ì›
    if category:
        f["category"] = category
    return f

# ---------- @tool: ë…¼ë¬¸ ê²€ìƒ‰ ----------
@tool
def search_paper_database(
    query: str,
    year_gte: Optional[int] = None,
    author: Optional[str] = None,
    category: Optional[str] = None,
    top_k: int = 5,
    with_scores: bool = True,
    use_multi_query: bool = True,
    search_mode: str = "mmr",  # "similarity" | "mmr"
) -> str:
    """
    ë…¼ë¬¸ VectorDB + PostgreSQL ë©”íƒ€ë°ì´í„°ë¥¼ í•¨ê»˜ ì¡°íšŒí•˜ì—¬ ê²°ê³¼ë¥¼ ë°˜í™˜.

    Parameters
    ----------
    query : str
        ì‚¬ìš©ì ì§ˆì˜
    year_gte : Optional[int]
        íŠ¹ì • ì—°ë„ ì´ìƒ í•„í„° (ì˜ˆ: 2020)
    author : Optional[str]
        ì €ì ë¶€ë¶„ì¼ì¹˜ í•„í„°
    category : Optional[str]
        ì¹´í…Œê³ ë¦¬ í•„í„° (ì˜ˆ: 'cs.CL')
    top_k : int
        ë°˜í™˜í•  ë¬¸ì„œ ìˆ˜
    with_scores : bool
        ìœ ì‚¬ë„ ì ìˆ˜ í¬í•¨ ì—¬ë¶€
    use_multi_query : bool
        MultiQuery(LLM ì¿¼ë¦¬ í™•ì¥) ì‚¬ìš© ì—¬ë¶€
    search_mode : str
        "similarity" ë˜ëŠ” "mmr"
    """

    # Retriever ì¤€ë¹„
    r = RAGRetriever(search_type=search_mode, k=top_k)

    # 2) ê²€ìƒ‰ ì‹¤í–‰ (í•„í„°/ë©€í‹°ì¿¼ë¦¬ ì²˜ë¦¬)
    filter_dict = _build_filter(year_gte, author, category)
    docs: List[Document] = []
    pairs: List[Tuple[Document, float]] = []

    if any(filter_dict.values()):
        # ë©”íƒ€ë°ì´í„° í•„í„°ê°€ ìˆìœ¼ë©´ similarity + filterë¡œ ìˆ˜í–‰
        docs = r.search_with_filter(query, filter_dict, k=top_k)
        if with_scores:
            # ì ìˆ˜ í•„ìš” ì‹œ, filterëŠ” retriever ê²½ë¡œë¡œë§Œ ê°€ëŠ¥í•˜ë¯€ë¡œ
            # ì ìˆ˜ëŠ” ë³„ë„ ì¬ê³„ì‚°ì´ í•„ìš”í•©ë‹ˆë‹¤ â†’ ê°„ë‹¨íˆ None ì²˜ë¦¬
            pairs = [(d, None) for d in docs]  # type: ignore
    else:
        if use_multi_query:
            docs = r.multi_query_search(query, k=top_k)
            if with_scores:
                # ë©€í‹°ì¿¼ë¦¬ëŠ” ì—¬ëŸ¬ ì¿¼ë¦¬ë¡œ ë¬¶ì˜€ìœ¼ë‹ˆ, ì ìˆ˜ ì¬ê³„ì‚° ì‹œ ë‹¨ì¼ ì¿¼ë¦¬ ê¸°ì¤€ ê·¼ì‚¬ê°’ìœ¼ë¡œ ê³„ì‚°
                pairs = r.similarity_search_with_score(query, k=len(docs) or top_k)
        else:
            if with_scores:
                pairs = r.similarity_search_with_score(query, k=top_k)
                docs = [d for d, _ in pairs]
            else:
                docs = r.similarity_search(query, k=top_k)

    # paper_id ë©”íƒ€ë¡œ PostgreSQL ë©”íƒ€ë°ì´í„° ì¡°íšŒ
    paper_ids = []
    for d in docs:
        pid = d.metadata.get("paper_id")
        if isinstance(pid, int):
            paper_ids.append(pid)
        else:
            # í˜¹ì‹œ strì´ë©´ int ë¡œ ë³€í™˜ ì‹œë„
            try:
                paper_ids.append(int(pid))
            except Exception:
                pass
    meta_map = _fetch_paper_meta(list(set(paper_ids)))

    # ê²°ê³¼ í•©ì„±
    score_map: Dict[str, float] = {}
    if with_scores and pairs:
        for d, s in pairs:
            # langchain-postgresì—ì„œ scoreëŠ” float (ê±°ë¦¬) â€” ë‚®ì„ìˆ˜ë¡ ìœ ì‚¬
            if s is None:
                continue
            score_map[id(d)] = float(s)

    results: List[Dict[str, Any]] = []
    for d in docs:
        pid = d.metadata.get("paper_id")
        meta = meta_map.get(pid, {}) if pid is not None else {}
        results.append({
            "paper_id": pid,
            "title": meta.get("title") or d.metadata.get("title"),
            "authors": meta.get("authors") or d.metadata.get("authors"),
            "publish_date": meta.get("publish_date") or d.metadata.get("publish_date"),
            "url": meta.get("url") or d.metadata.get("url"),
            "category": meta.get("category") or d.metadata.get("category"),
            "citation_count": meta.get("citation_count"),
            "section": d.metadata.get("section", "ë³¸ë¬¸"),
            "content": d.page_content,
            "score": score_map.get(id(d)) if with_scores else None,
        })

    # Markdown í¬ë§·ìœ¼ë¡œ ë°˜í™˜
    return _format_markdown(results)









