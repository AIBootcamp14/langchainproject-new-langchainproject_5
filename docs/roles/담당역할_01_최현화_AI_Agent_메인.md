# ë‹´ë‹¹ì—­í• : ìµœí˜„í™” - AI Agent ë©”ì¸

## ë¬¸ì„œ ì •ë³´
- **ì‘ì„±ì**: ìµœí˜„í™”[íŒ€ì¥]

## ë‹´ë‹¹ì ì •ë³´
- **ì´ë¦„**: ìµœí˜„í™”
- **ì—­í• **: íŒ€ì¥
- **ì°¸ì—¬ ê¸°ê°„**: ì „ì²´ ê¸°ê°„
- **í•µì‹¬ ì—­í• **: AI Agent ê·¸ë˜í”„ ì„¤ê³„ ë° êµ¬í˜„, LLM í´ë¼ì´ì–¸íŠ¸, ë©”ëª¨ë¦¬ ì‹œìŠ¤í…œ, í”„ë¡œì íŠ¸ ì´ê´„

---

## ë‹´ë‹¹ ëª¨ë“ˆ ë° ë„êµ¬

### 1. AI Agent ê·¸ë˜í”„ (`src/agent/`)
- LangGraph StateGraph ì„¤ê³„ ë° êµ¬í˜„
- ë¼ìš°í„° ë…¸ë“œ (ì§ˆë¬¸ ë¶„ì„ ë° ë„êµ¬ ì„ íƒ)
- ì¡°ê±´ë¶€ ì—£ì§€ (conditional_edges)
- Agent State ê´€ë¦¬ (TypedDict)
- ë„êµ¬ ë…¸ë“œ ì—°ê²° (6ê°€ì§€ ë„êµ¬)

### 2. LLM í´ë¼ì´ì–¸íŠ¸ (`src/llm/`)
- Langchain ChatOpenAI ë° Solar(Upstage) API ë˜í¼ êµ¬í˜„
- ë‹¤ì¤‘ LLM ì„ íƒ ë¡œì§ (OpenAI + Solar)
- ì—ëŸ¬ í•¸ë“¤ë§ ë° ì¬ì‹œë„ ë¡œì§
- ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µ ì²˜ë¦¬ (astream)
- í† í° ì‚¬ìš©ëŸ‰ ì¶”ì  (get_openai_callback)
- Function calling ì„¤ì •

### 3. ëŒ€í™” ë©”ëª¨ë¦¬ ì‹œìŠ¤í…œ (`src/memory/`)
- Langchain ConversationBufferMemory êµ¬í˜„
- ëŒ€í™” íˆìŠ¤í† ë¦¬ ê´€ë¦¬ (ChatMessageHistory)
- ì»¨í…ìŠ¤íŠ¸ ìœˆë„ìš° ìµœì í™”
- ì„¸ì…˜ ê´€ë¦¬

### 4. ë„êµ¬: ë…¼ë¬¸ ìš”ì•½ ë„êµ¬ (`src/tools/summarize.py`)
- Langchain @tool ë°ì½”ë ˆì´í„° í™œìš©
- load_summarize_chain êµ¬í˜„ (stuff, map_reduce, refine)
- ë‚œì´ë„ë³„ ìš”ì•½ (Easy/Hard)
- ì„¹ì…˜ë³„ ìš”ì•½ ê¸°ëŠ¥

### 5. ë„êµ¬: ì¼ë°˜ ë‹µë³€ ë„êµ¬
- LLM ì§ì ‘ í˜¸ì¶œ (ChatOpenAI)
- ê°„ë‹¨í•œ ì¸ì‚¬, ì¼ë°˜ ìƒì‹ ì§ˆë¬¸ ì²˜ë¦¬
- ë‚œì´ë„ë³„ í”„ë¡¬í”„íŠ¸ ì ìš©

### 6. í”„ë¡œì íŠ¸ ì´ê´„
- ê¸°ëŠ¥ í†µí•© ë° ë””ë²„ê¹…
- main.py ì‘ì„± (LangGraph ì»´íŒŒì¼ ë° ì‹¤í–‰)
- ì½”ë“œ ë¦¬ë·° ë° PR ê´€ë¦¬
- ë°œí‘œ ìë£Œ ì´ê´„

---

## ë„êµ¬ 1: ì¼ë°˜ ë‹µë³€ ë„êµ¬

### ê¸°ëŠ¥ ì„¤ëª…
ê°„ë‹¨í•œ ì¸ì‚¬, ì¼ë°˜ ìƒì‹ ì§ˆë¬¸ì— LLMì˜ ìì²´ ì§€ì‹ì„ í™œìš©í•˜ì—¬ ì§ì ‘ ë‹µë³€í•˜ëŠ” ë„êµ¬

### êµ¬í˜„ ë°©ë²•

**íŒŒì¼ ê²½ë¡œ**: `src/agent/nodes.py`

1. **ì¼ë°˜ ë‹µë³€ ë…¸ë“œ í•¨ìˆ˜ ìƒì„±**
   - AgentStateë¥¼ íŒŒë¼ë¯¸í„°ë¡œ ë°›ëŠ” `general_answer_node` í•¨ìˆ˜ ì •ì˜
   - stateì—ì„œ questionê³¼ difficulty ì¶”ì¶œ
   - ë‚œì´ë„ì— ë”°ë¼ ë‹¤ë¥¸ SystemMessage ì„¤ì •
     - Easy: ì¹œì ˆí•˜ê³  ì´í•´í•˜ê¸° ì‰¬ìš´ ì–¸ì–´ë¡œ ë‹µë³€í•˜ë„ë¡ ì§€ì‹œ
     - Hard: ì „ë¬¸ì ì´ê³  ê¸°ìˆ ì ì¸ ì–¸ì–´ë¡œ ë‹µë³€í•˜ë„ë¡ ì§€ì‹œ

2. **LLM í˜¸ì¶œ êµ¬ì„±**
   - langchain_openai.ChatOpenAI ì‚¬ìš©
   - SystemMessageì™€ HumanMessageë¥¼ ë¦¬ìŠ¤íŠ¸ë¡œ êµ¬ì„±
   - llm.invoke() ë©”ì„œë“œë¡œ ë©”ì‹œì§€ ì „ë‹¬
   - ì‘ë‹µ ê²°ê³¼ë¥¼ state["final_answer"]ì— ì €ì¥

3. **ë¼ìš°í„° ë…¸ë“œì—ì„œ ì¼ë°˜ ë‹µë³€ íŒë‹¨ ë¡œì§**
   - ì‚¬ìš©ì ì§ˆë¬¸ì„ LLMì— ì „ë‹¬í•˜ì—¬ ì ì ˆí•œ ë„êµ¬ ì„ íƒ
   - ì§ˆë¬¸ ìœ í˜• ë¶„ë¥˜ í”„ë¡¬í”„íŠ¸ ì‘ì„± (ì¼ë°˜ ì¸ì‚¬, ìƒì‹ ì§ˆë¬¸ ë“±)
   - ì„ íƒëœ ë„êµ¬ë¥¼ state["tool_choice"]ì— ì €ì¥

### ì‚¬ìš©í•˜ëŠ” DB
**DB ì‚¬ìš© ì—†ìŒ** (LLM ìì²´ ì§€ì‹ í™œìš©)

**íŒŒì¼:** `src/agent/nodes.py`

**í•„ìš” ë¼ì´ë¸ŒëŸ¬ë¦¬:**
- `typing.TypedDict`
- `langchain_openai.ChatOpenAI`
- `langchain.schema.SystemMessage`, `HumanMessage`

**AgentState êµ¬ì¡°:**

| í•„ë“œ | íƒ€ì… | ì„¤ëª… |
|------|------|------|
| question | str | ì‚¬ìš©ì ì§ˆë¬¸ |
| difficulty | str | ë‚œì´ë„ (easy/hard) |
| tool_choice | str | ì„ íƒëœ ë„êµ¬ |
| tool_result | str | ë„êµ¬ ì‹¤í–‰ ê²°ê³¼ |
| final_answer | str | ìµœì¢… ë‹µë³€ |
| messages | list | ëŒ€í™” íˆìŠ¤í† ë¦¬ |

**í•¨ìˆ˜: general_answer_node**

| íŒŒë¼ë¯¸í„° | íƒ€ì… | ê¸°ë³¸ê°’ | ì„¤ëª… |
|---------|------|--------|------|
| state | AgentState | (í•„ìˆ˜) | Agent ìƒíƒœ |
| exp_manager | ExperimentManager | None | ì‹¤í—˜ ê´€ë¦¬ì ì¸ìŠ¤í„´ìŠ¤ |

**ì²˜ë¦¬ íë¦„:**

| ë‹¨ê³„ | ë™ì‘ |
|------|------|
| 1 | stateì—ì„œ question, difficulty ì¶”ì¶œ |
| 2 | exp_manager ë¡œê¹… (ì„ íƒ) |
| 3 | difficultyì— ë”°ë¼ SystemMessage ì„¤ì • (easy: ì‰¬ìš´ ì–¸ì–´ / hard: ì „ë¬¸ì  ì–¸ì–´) |
| 4 | ChatOpenAI ì´ˆê¸°í™” (model="gpt-5", temperature=0.7) |
| 5 | [SystemMessage, HumanMessage] êµ¬ì„±í•˜ì—¬ llm.invoke() í˜¸ì¶œ |
| 6 | response.contentë¥¼ state["final_answer"]ì— ì €ì¥ |
| 7 | state ë°˜í™˜ |

---

## ë„êµ¬ 2: ë…¼ë¬¸ ìš”ì•½ ë„êµ¬

### ê¸°ëŠ¥ ì„¤ëª…
íŠ¹ì • ë…¼ë¬¸ì˜ ì „ì²´ ë‚´ìš©ì„ ë‚œì´ë„ë³„(Easy/Hard)ë¡œ ìš”ì•½í•˜ëŠ” ë„êµ¬

### êµ¬í˜„ ë°©ë²•

**íŒŒì¼ ê²½ë¡œ**: `src/tools/summarize.py`, `src/llm/chains.py`

1. **ë…¼ë¬¸ ê²€ìƒ‰ ë° ì „ì²´ ë‚´ìš© ì¡°íšŒ** (`src/tools/summarize.py`)
   - @tool ë°ì½”ë ˆì´í„°ë¡œ `summarize_paper` í•¨ìˆ˜ ì •ì˜
   - íŒŒë¼ë¯¸í„°: paper_title (str), difficulty (str)
   - PostgreSQL ì—°ê²° (psycopg2 ì‚¬ìš©)
   - papers í…Œì´ë¸”ì—ì„œ ILIKEë¡œ ë…¼ë¬¸ ì œëª© ê²€ìƒ‰
   - paper_id ì¶”ì¶œ í›„ Vector DBì—ì„œ í•´ë‹¹ ë…¼ë¬¸ì˜ ëª¨ë“  ì²­í¬ ì¡°íšŒ
   - filter íŒŒë¼ë¯¸í„°ë¡œ {"paper_id": paper_id} ì „ë‹¬
   - ë‚œì´ë„ì— ë”°ë¼ ì ì ˆí•œ ìš”ì•½ ì²´ì¸ ì„ íƒ í›„ ì‹¤í–‰

2. **ìš”ì•½ ì²´ì¸ êµ¬í˜„** (`src/llm/chains.py`)
   - Easy ëª¨ë“œ í”„ë¡¬í”„íŠ¸: PromptTemplateë¡œ ì´ˆì‹¬ììš© ìš”ì•½ ê·œì¹™ ì •ì˜
     - ì „ë¬¸ ìš©ì–´ ì‰½ê²Œ í’€ì´, í•µì‹¬ ì•„ì´ë””ì–´ 3ê°€ì§€ ì´ë‚´, ì‹¤ìƒí™œ ë¹„ìœ  í¬í•¨
   - Hard ëª¨ë“œ í”„ë¡¬í”„íŠ¸: ì „ë¬¸ê°€ìš© ìš”ì•½ ê·œì¹™ ì •ì˜
     - ê¸°ìˆ ì  ì„¸ë¶€ì‚¬í•­, ìˆ˜ì‹/ì•Œê³ ë¦¬ì¦˜ ì„¤ëª…, ê´€ë ¨ ì—°êµ¬ ë¹„êµ
   - load_summarize_chainìœ¼ë¡œ ì²´ì¸ ìƒì„±
     - chain_type: "stuff" (ì§§ì€ ë…¼ë¬¸), "map_reduce" (ì¤‘ê°„ ë…¼ë¬¸), "refine" (ê¸´ ë…¼ë¬¸)

3. **ìš”ì•½ ë°©ì‹ ì„ íƒ ë¡œì§**
   - ë…¼ë¬¸ ì²­í¬ ìˆ˜ì— ë”°ë¼ ì ì ˆí•œ chain_type ì„ íƒ
   - 5ê°œ ì´í•˜: stuff (ëª¨ë“  ì²­í¬ í•œ ë²ˆì— ì²˜ë¦¬)
   - 5~15ê°œ: map_reduce (ê° ì²­í¬ ìš”ì•½ í›„ í†µí•©)
   - 15ê°œ ì´ìƒ: refine (ìˆœì°¨ì  ìš”ì•½)

### ì‚¬ìš©í•˜ëŠ” DB

#### PostgreSQL + pgvector (Vector DB)
- **ì»¬ë ‰ì…˜**: `paper_chunks`
- **ì—­í• **: ë…¼ë¬¸ ì „ì²´ ë‚´ìš©ì„ ì²­í¬ë¡œ ë‚˜ëˆ  ì €ì¥ (pgvector extension ì‚¬ìš©)
- **ë©”íƒ€ë°ì´í„° í•„í„°**: `paper_id`ë¡œ íŠ¹ì • ë…¼ë¬¸ì˜ ëª¨ë“  ì²­í¬ ì¡°íšŒ
- **ê²€ìƒ‰ ë°©ì‹**: ì œëª© ìœ ì‚¬ë„ ê²€ìƒ‰ + ë©”íƒ€ë°ì´í„° í•„í„°
- **ë²¡í„° ê²€ìƒ‰**: Cosine Similarity, L2 Distance

#### PostgreSQL (ê´€ê³„í˜• ë°ì´í„°)
- **í…Œì´ë¸”**: `papers`
- **ì—­í• **: ë…¼ë¬¸ ë©”íƒ€ë°ì´í„° ì¡°íšŒ (ì œëª©ìœ¼ë¡œ paper_id ì°¾ê¸°)
- **ì¿¼ë¦¬**: `SELECT * FROM papers WHERE title ILIKE '%{paper_title}%'`

### ì˜ˆì œ ì½”ë“œ

```python
# src/tools/summarize.py

from langchain.tools import tool
from langchain_postgres.vectorstores import PGVector
from langchain_openai import ChatOpenAI
from langchain.chains.summarize import load_summarize_chain
from langchain.prompts import PromptTemplate
import psycopg2

# ExperimentManagerëŠ” mainì—ì„œ ì „ë‹¬ë°›ì•„ ì‚¬ìš©

@tool
def summarize_paper(paper_title: str, difficulty: str = "easy", exp_manager=None) -> str:
    """
    íŠ¹ì • ë…¼ë¬¸ì„ ìš”ì•½í•©ë‹ˆë‹¤. ë‚œì´ë„ì— ë”°ë¼ ì´ˆì‹¬ììš©/ì „ë¬¸ê°€ìš© ìš”ì•½ì„ ì œê³µí•©ë‹ˆë‹¤.

    Args:
        paper_title: ë…¼ë¬¸ ì œëª©
        difficulty: 'easy' (ì´ˆì‹¬ì) ë˜ëŠ” 'hard' (ì „ë¬¸ê°€)
        exp_manager: ExperimentManager ì¸ìŠ¤í„´ìŠ¤ (ì„ íƒ ì‚¬í•­)

    Returns:
        ë…¼ë¬¸ ìš”ì•½ ë‚´ìš©
    """
    # ë„êµ¬ë³„ Logger ìƒì„±
    tool_logger = exp_manager.get_tool_logger('summary_paper') if exp_manager else None

    if tool_logger:
        tool_logger.write(f"ë…¼ë¬¸ ìš”ì•½ ì‹œì‘: {paper_title}")
        tool_logger.write(f"ë‚œì´ë„: {difficulty}")

    # 1. PostgreSQLì—ì„œ ë…¼ë¬¸ ë©”íƒ€ë°ì´í„° ì¡°íšŒ
    conn = psycopg2.connect("postgresql://user:password@localhost/papers")
    cursor = conn.cursor()

    cursor.execute(
        "SELECT * FROM papers WHERE title ILIKE %s",
        (f"%{paper_title}%",)
    )
    paper_meta = cursor.fetchone()

    if not paper_meta:
        if tool_logger:
            tool_logger.write(f"ë…¼ë¬¸ì„ ì°¾ì„ ìˆ˜ ì—†ìŒ: {paper_title}")
        return f"'{paper_title}' ë…¼ë¬¸ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."

    paper_id = paper_meta[0]
    if tool_logger:
        tool_logger.write(f"ë…¼ë¬¸ ID: {paper_id}")

    # 2. Vector DBì—ì„œ ë…¼ë¬¸ ì „ì²´ ë‚´ìš© ì¡°íšŒ
    vectorstore = PGVector(
        collection_name="paper_chunks",
        connection_string="postgresql://user:password@localhost:5432/papers"
    )

    paper_chunks = vectorstore.similarity_search(
        paper_title,
        k=10,
        filter={"paper_id": paper_id}
    )

    if tool_logger:
        tool_logger.write(f"ê²€ìƒ‰ëœ ì²­í¬ ìˆ˜: {len(paper_chunks)}")

    # 3. ë‚œì´ë„ë³„ í”„ë¡¬í”„íŠ¸
    if difficulty == "easy":
        prompt_template = """
ë‹¤ìŒ ë…¼ë¬¸ì„ ì´ˆì‹¬ìë„ ì´í•´í•  ìˆ˜ ìˆë„ë¡ ì‰½ê²Œ ìš”ì•½í•´ì£¼ì„¸ìš”:
- ì „ë¬¸ ìš©ì–´ëŠ” í’€ì–´ì„œ ì„¤ëª…
- í•µì‹¬ ì•„ì´ë””ì–´ 3ê°€ì§€
- ì‹¤ìƒí™œ ë¹„ìœ  í¬í•¨

ë…¼ë¬¸ ë‚´ìš©: {text}

ì‰¬ìš´ ìš”ì•½:
        """
    else:  # hard
        prompt_template = """
ë‹¤ìŒ ë…¼ë¬¸ì„ ì „ë¬¸ê°€ ìˆ˜ì¤€ìœ¼ë¡œ ìš”ì•½í•´ì£¼ì„¸ìš”:
- ê¸°ìˆ ì  ì„¸ë¶€ì‚¬í•­ í¬í•¨
- ìˆ˜ì‹ ë° ì•Œê³ ë¦¬ì¦˜ ì„¤ëª…
- ê´€ë ¨ ì—°êµ¬ì™€ì˜ ë¹„êµ

ë…¼ë¬¸ ë‚´ìš©: {text}

ì „ë¬¸ê°€ìš© ìš”ì•½:
        """

    PROMPT = PromptTemplate(template=prompt_template, input_variables=["text"])

    # 4. ìš”ì•½ ì²´ì¸ ì‹¤í–‰
    llm = ChatOpenAI(model="gpt-5", temperature=0)
    chain = load_summarize_chain(llm, chain_type="stuff", prompt=PROMPT)

    if tool_logger:
        tool_logger.write("ìš”ì•½ ì²´ì¸ ì‹¤í–‰ ì¤‘...")

    summary = chain.run(paper_chunks)

    if tool_logger:
        tool_logger.write(f"ìš”ì•½ ì™„ë£Œ: {len(summary)} ê¸€ì")
        tool_logger.close()

    return summary
```

---

## ë„êµ¬ 3: RAG ê²€ìƒ‰ ë„êµ¬

### ê¸°ëŠ¥ ì„¤ëª…
ë…¼ë¬¸ ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ ì‚¬ìš©ì ì§ˆë¬¸ê³¼ ê´€ë ¨ëœ ë…¼ë¬¸ì„ ê²€ìƒ‰í•˜ê³ , ë‚œì´ë„ì— ë§ëŠ” ë‹µë³€ì„ ìƒì„±í•˜ëŠ” ë„êµ¬

### êµ¬í˜„ ë°©ë²•

**íŒŒì¼ ê²½ë¡œ**: `src/agent/nodes.py`

1. **RAG ê²€ìƒ‰ ë…¸ë“œ í•¨ìˆ˜ ìƒì„±**
   - AgentStateë¥¼ íŒŒë¼ë¯¸í„°ë¡œ ë°›ëŠ” `search_paper_node` í•¨ìˆ˜ ì •ì˜
   - stateì—ì„œ questionê³¼ difficulty ì¶”ì¶œ
   - Vector DB (pgvector)ì—ì„œ ìœ ì‚¬ë„ ê²€ìƒ‰ ìˆ˜í–‰ (Top-K=5)
   - ê²€ìƒ‰ëœ ë…¼ë¬¸ ì²­í¬ì—ì„œ paper_id ì¶”ì¶œ
   - PostgreSQL papers í…Œì´ë¸”ì—ì„œ ë©”íƒ€ë°ì´í„° ì¡°íšŒ
   - ê²€ìƒ‰ëœ ì»¨í…ìŠ¤íŠ¸ì™€ ë‚œì´ë„ë³„ í”„ë¡¬í”„íŠ¸ë¥¼ ê²°í•©í•˜ì—¬ LLMì— ì „ë‹¬
   - ìƒì„±ëœ ë‹µë³€ì„ state["final_answer"]ì— ì €ì¥

2. **ë‚œì´ë„ë³„ í”„ë¡¬í”„íŠ¸ êµ¬ì„±**
   - Easy ëª¨ë“œ: ì´ˆì‹¬ììš© ì„¤ëª…, ì „ë¬¸ ìš©ì–´ ìµœì†Œí™”
   - Hard ëª¨ë“œ: ê¸°ìˆ ì  ì„¸ë¶€ì‚¬í•­, ìˆ˜ì‹ í¬í•¨, ë…¼ë¬¸ ë¹„êµ

3. **ExperimentManager í†µí•©**
   - ë„êµ¬ë³„ Logger ìƒì„± (`exp.get_tool_logger('rag_paper')`)
   - DB ì¿¼ë¦¬ ê¸°ë¡ (`exp.log_sql_query()`, `exp.log_pgvector_search()`)
   - ê²€ìƒ‰ ê²°ê³¼ ì €ì¥ (`exp.save_search_results()`)
   - í”„ë¡¬í”„íŠ¸ ì €ì¥ (`exp.save_user_prompt()`, `exp.save_system_prompt()`)

### ì‚¬ìš©í•˜ëŠ” DB

#### PostgreSQL + pgvector (Vector DB)
- **ì»¬ë ‰ì…˜**: `paper_chunks`
- **ì—­í• **: ë…¼ë¬¸ ë‚´ìš©ì„ ì²­í¬ë¡œ ë‚˜ëˆ  ì €ì¥, ì„ë² ë”© ë²¡í„° ê²€ìƒ‰
- **ê²€ìƒ‰ ë°©ì‹**: Cosine Similarity ê¸°ë°˜ Top-K ê²€ìƒ‰ (k=5)
- **ë©”íƒ€ë°ì´í„°**: paper_id, chunk_index

#### PostgreSQL (ê´€ê³„í˜• ë°ì´í„°)
- **í…Œì´ë¸”**: `papers`
- **ì—­í• **: ë…¼ë¬¸ ë©”íƒ€ë°ì´í„° ì¡°íšŒ (ì œëª©, ì €ì, ë…„ë„, ì¹´í…Œê³ ë¦¬)
- **ì¿¼ë¦¬**: `SELECT * FROM papers WHERE paper_id IN (...)`

### ì˜ˆì œ ì½”ë“œ

```python
# src/agent/nodes.py

from langchain_postgres.vectorstores import PGVector
from langchain_openai import ChatOpenAI, OpenAIEmbeddings
from langchain.schema import SystemMessage, HumanMessage
import psycopg2
import os

def search_paper_node(state: AgentState, exp_manager=None):
    """
    RAG ê²€ìƒ‰ ë…¸ë“œ: ë…¼ë¬¸ DBì—ì„œ ê´€ë ¨ ë…¼ë¬¸ ê²€ìƒ‰ ë° ë‹µë³€ ìƒì„±

    Args:
        state: Agent ìƒíƒœ
        exp_manager: ExperimentManager ì¸ìŠ¤í„´ìŠ¤ (ì„ íƒ ì‚¬í•­)
    """
    question = state["question"]
    difficulty = state.get("difficulty", "easy")

    # ë„êµ¬ë³„ Logger ìƒì„±
    tool_logger = exp_manager.get_tool_logger('rag_paper') if exp_manager else None

    if tool_logger:
        tool_logger.write(f"RAG ê²€ìƒ‰ ë…¸ë“œ ì‹¤í–‰: {question}")
        tool_logger.write(f"ë‚œì´ë„: {difficulty}")

    # 1. Vector DB ì´ˆê¸°í™”
    embeddings = OpenAIEmbeddings(model="text-embedding-3-small")
    vectorstore = PGVector(
        collection_name="paper_chunks",
        embedding_function=embeddings,
        connection_string=os.getenv("DATABASE_URL")
    )

    # 2. ìœ ì‚¬ë„ ê²€ìƒ‰ (Top-5)
    if tool_logger:
        tool_logger.write("Vector DB ìœ ì‚¬ë„ ê²€ìƒ‰ ì‹œì‘ (Top-5)")

    docs = vectorstore.similarity_search(question, k=5)

    if tool_logger:
        tool_logger.write(f"ê²€ìƒ‰ëœ ë¬¸ì„œ ìˆ˜: {len(docs)}")

        # pgvector ê²€ìƒ‰ ê¸°ë¡
        if exp_manager:
            exp_manager.log_pgvector_search({
                "tool": "rag_paper",
                "query_text": question,
                "top_k": 5,
                "results_count": len(docs)
            })

    # 3. paper_id ì¶”ì¶œ ë° ë©”íƒ€ë°ì´í„° ì¡°íšŒ
    paper_ids = list(set([doc.metadata.get("paper_id") for doc in docs if doc.metadata.get("paper_id")]))

    if not paper_ids:
        if tool_logger:
            tool_logger.write("ê²€ìƒ‰ëœ ë…¼ë¬¸ì´ ì—†ìŒ")
            tool_logger.close()
        state["final_answer"] = "ê´€ë ¨ ë…¼ë¬¸ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
        return state

    # PostgreSQL ì—°ê²°
    conn = psycopg2.connect(os.getenv("DATABASE_URL"))
    cursor = conn.cursor()

    # papers í…Œì´ë¸”ì—ì„œ ë©”íƒ€ë°ì´í„° ì¡°íšŒ
    placeholders = ','.join(['%s'] * len(paper_ids))
    query = f"SELECT paper_id, title, authors, publish_date FROM papers WHERE paper_id IN ({placeholders})"

    if tool_logger:
        tool_logger.write(f"SQL ì¿¼ë¦¬ ì‹¤í–‰: paper_id IN {paper_ids}")

        # SQL ì¿¼ë¦¬ ê¸°ë¡
        if exp_manager:
            exp_manager.log_sql_query(
                query=query,
                description="ë…¼ë¬¸ ë©”íƒ€ë°ì´í„° ì¡°íšŒ",
                tool="rag_paper"
            )

    cursor.execute(query, paper_ids)
    papers_meta = cursor.fetchall()
    cursor.close()
    conn.close()

    # 4. ì»¨í…ìŠ¤íŠ¸ êµ¬ì„±
    context = "\n\n".join([
        f"[ë…¼ë¬¸ {i+1}] {doc.page_content}\nì¶œì²˜: {doc.metadata.get('title', 'Unknown')}"
        for i, doc in enumerate(docs)
    ])

    # 5. ë‚œì´ë„ë³„ í”„ë¡¬í”„íŠ¸
    if difficulty == "easy":
        system_prompt = """
ë‹¹ì‹ ì€ ë…¼ë¬¸ì„ ì‰½ê²Œ ì„¤ëª…í•˜ëŠ” ì „ë¬¸ê°€ì…ë‹ˆë‹¤.
ì´ˆì‹¬ìë„ ì´í•´í•  ìˆ˜ ìˆë„ë¡ ì‰½ê³  ëª…í™•í•˜ê²Œ ë‹µë³€í•´ì£¼ì„¸ìš”.
- ì „ë¬¸ ìš©ì–´ëŠ” í’€ì–´ì„œ ì„¤ëª…
- ë¹„ìœ ì™€ ì˜ˆì‹œ ì‚¬ìš©
- ìˆ˜ì‹ì€ ìµœì†Œí™”
        """
    else:  # hard
        system_prompt = """
ë‹¹ì‹ ì€ ë…¼ë¬¸ ë¶„ì„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.
ê¸°ìˆ ì  ì„¸ë¶€ì‚¬í•­ì„ í¬í•¨í•˜ì—¬ ì •í™•í•˜ê³  ì „ë¬¸ì ìœ¼ë¡œ ë‹µë³€í•´ì£¼ì„¸ìš”.
- ë…¼ë¬¸ì˜ í•µì‹¬ ê¸°ì—¬ ì„¤ëª…
- ìˆ˜ì‹ ë° ì•Œê³ ë¦¬ì¦˜ í¬í•¨
- ê´€ë ¨ ì—°êµ¬ì™€ ë¹„êµ
        """

    user_prompt = f"""
[ì°¸ê³  ë…¼ë¬¸]
{context}

[ì§ˆë¬¸]
{question}

ìœ„ ë…¼ë¬¸ì„ ì°¸ê³ í•˜ì—¬ ì§ˆë¬¸ì— ë‹µë³€í•´ì£¼ì„¸ìš”.
    """

    # í”„ë¡¬í”„íŠ¸ ì €ì¥
    if exp_manager:
        exp_manager.save_system_prompt(system_prompt, metadata={"difficulty": difficulty})
        exp_manager.save_user_prompt(user_prompt, metadata={"papers_count": len(papers_meta)})

    if tool_logger:
        tool_logger.write("LLM ë‹µë³€ ìƒì„± ì‹œì‘")

    # 6. LLM í˜¸ì¶œ
    llm = ChatOpenAI(model="gpt-5", temperature=0.7)
    messages = [
        SystemMessage(content=system_prompt),
        HumanMessage(content=user_prompt)
    ]

    response = llm.invoke(messages)

    if tool_logger:
        tool_logger.write(f"ë‹µë³€ ìƒì„± ì™„ë£Œ: {len(response.content)} ê¸€ì")
        tool_logger.close()

    # 7. ìµœì¢… ë‹µë³€ ì €ì¥
    state["final_answer"] = response.content

    return state
```

---

## ë„êµ¬ 4: ì›¹ ê²€ìƒ‰ ë„êµ¬

### ê¸°ëŠ¥ ì„¤ëª…
Tavily Search APIë¥¼ ì‚¬ìš©í•˜ì—¬ ì›¹ì—ì„œ ìµœì‹  ë…¼ë¬¸ ì •ë³´ë¥¼ ê²€ìƒ‰í•˜ê³  ê²°ê³¼ë¥¼ ì •ë¦¬í•˜ëŠ” ë„êµ¬

### êµ¬í˜„ ë°©ë²•

**íŒŒì¼ ê²½ë¡œ**: `src/agent/nodes.py`

1. **ì›¹ ê²€ìƒ‰ ë…¸ë“œ í•¨ìˆ˜ ìƒì„±**
   - AgentStateë¥¼ íŒŒë¼ë¯¸í„°ë¡œ ë°›ëŠ” `web_search_node` í•¨ìˆ˜ ì •ì˜
   - stateì—ì„œ questionê³¼ difficulty ì¶”ì¶œ
   - Tavily Search API í˜¸ì¶œ (langchain_community.tools.tavily_search ì‚¬ìš©)
   - ê²€ìƒ‰ ê²°ê³¼ë¥¼ LLMì— ì „ë‹¬í•˜ì—¬ ë‚œì´ë„ì— ë§ê²Œ ì •ë¦¬
   - ì •ë¦¬ëœ ë‹µë³€ì„ state["final_answer"]ì— ì €ì¥

2. **Tavily API ì„¤ì •**
   - í™˜ê²½ë³€ìˆ˜ì—ì„œ TAVILY_API_KEY ë¡œë“œ
   - TavilySearchResults ë„êµ¬ ì´ˆê¸°í™” (max_results=5)

3. **ê²€ìƒ‰ ê²°ê³¼ ì •ë¦¬**
   - LLMì—ê²Œ ê²€ìƒ‰ ê²°ê³¼ë¥¼ ì „ë‹¬í•˜ì—¬ ìš”ì•½ ë° ì •ë¦¬
   - ë‚œì´ë„ë³„ í”„ë¡¬í”„íŠ¸ ì ìš©

### ì‚¬ìš©í•˜ëŠ” DB
**DB ì‚¬ìš© ì—†ìŒ** (Tavily API ì™¸ë¶€ ì›¹ ê²€ìƒ‰)

### ì˜ˆì œ ì½”ë“œ

```python
# src/agent/nodes.py

from langchain_community.tools.tavily_search import TavilySearchResults
from langchain_openai import ChatOpenAI
from langchain.schema import SystemMessage, HumanMessage
import os

def web_search_node(state: AgentState, exp_manager=None):
    """
    ì›¹ ê²€ìƒ‰ ë…¸ë“œ: Tavily APIë¡œ ìµœì‹  ë…¼ë¬¸ ì •ë³´ ê²€ìƒ‰

    Args:
        state: Agent ìƒíƒœ
        exp_manager: ExperimentManager ì¸ìŠ¤í„´ìŠ¤ (ì„ íƒ ì‚¬í•­)
    """
    question = state["question"]
    difficulty = state.get("difficulty", "easy")

    # ë„êµ¬ë³„ Logger ìƒì„±
    tool_logger = exp_manager.get_tool_logger('web_search') if exp_manager else None

    if tool_logger:
        tool_logger.write(f"ì›¹ ê²€ìƒ‰ ë…¸ë“œ ì‹¤í–‰: {question}")
        tool_logger.write(f"ë‚œì´ë„: {difficulty}")

    # 1. Tavily Search API ì´ˆê¸°í™”
    search_tool = TavilySearchResults(
        max_results=5,
        api_key=os.getenv("TAVILY_API_KEY")
    )

    if tool_logger:
        tool_logger.write("Tavily Search API í˜¸ì¶œ ì‹œì‘")

    # 2. ì›¹ ê²€ìƒ‰ ì‹¤í–‰
    search_results = search_tool.invoke({"query": question})

    if tool_logger:
        tool_logger.write(f"ê²€ìƒ‰ ê²°ê³¼ ìˆ˜: {len(search_results)}")

    # 3. ê²€ìƒ‰ ê²°ê³¼ í¬ë§·íŒ…
    formatted_results = "\n\n".join([
        f"[ê²°ê³¼ {i+1}]\nì œëª©: {result.get('title', 'N/A')}\në‚´ìš©: {result.get('content', 'N/A')}\nURL: {result.get('url', 'N/A')}"
        for i, result in enumerate(search_results)
    ])

    # 4. ë‚œì´ë„ë³„ í”„ë¡¬í”„íŠ¸
    if difficulty == "easy":
        system_prompt = """
ë‹¹ì‹ ì€ ìµœì‹  ë…¼ë¬¸ ì •ë³´ë¥¼ ì‰½ê²Œ ì„¤ëª…í•˜ëŠ” ì „ë¬¸ê°€ì…ë‹ˆë‹¤.
ì´ˆì‹¬ìë„ ì´í•´í•  ìˆ˜ ìˆë„ë¡ ê²€ìƒ‰ ê²°ê³¼ë¥¼ ì •ë¦¬í•´ì£¼ì„¸ìš”.
- í•µì‹¬ ë‚´ìš© ìš”ì•½
- ì‰¬ìš´ ì–¸ì–´ ì‚¬ìš©
- ì¤‘ìš”í•œ ì •ë³´ë§Œ ì„ ë³„
        """
    else:  # hard
        system_prompt = """
ë‹¹ì‹ ì€ ë…¼ë¬¸ ë¶„ì„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.
ê²€ìƒ‰ ê²°ê³¼ë¥¼ ì „ë¬¸ì ìœ¼ë¡œ ì •ë¦¬í•´ì£¼ì„¸ìš”.
- ê¸°ìˆ ì  ì„¸ë¶€ì‚¬í•­ í¬í•¨
- ìµœì‹  ì—°êµ¬ ë™í–¥ ë¶„ì„
- ê´€ë ¨ ë…¼ë¬¸ ë¹„êµ
        """

    user_prompt = f"""
[ì›¹ ê²€ìƒ‰ ê²°ê³¼]
{formatted_results}

[ì§ˆë¬¸]
{question}

ìœ„ ê²€ìƒ‰ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì§ˆë¬¸ì— ë‹µë³€í•´ì£¼ì„¸ìš”.
    """

    # í”„ë¡¬í”„íŠ¸ ì €ì¥
    if exp_manager:
        exp_manager.save_system_prompt(system_prompt, metadata={"difficulty": difficulty})
        exp_manager.save_user_prompt(user_prompt, metadata={"results_count": len(search_results)})

    if tool_logger:
        tool_logger.write("LLM ë‹µë³€ ìƒì„± ì‹œì‘")

    # 5. LLM í˜¸ì¶œ
    llm = ChatOpenAI(model="gpt-5", temperature=0.7)
    messages = [
        SystemMessage(content=system_prompt),
        HumanMessage(content=user_prompt)
    ]

    response = llm.invoke(messages)

    if tool_logger:
        tool_logger.write(f"ë‹µë³€ ìƒì„± ì™„ë£Œ: {len(response.content)} ê¸€ì")
        tool_logger.close()

    # 6. ìµœì¢… ë‹µë³€ ì €ì¥
    state["final_answer"] = response.content

    return state
```

---

## ë„êµ¬ 5: ìš©ì–´ì§‘ ë„êµ¬

### ê¸°ëŠ¥ ì„¤ëª…
PostgreSQL glossary í…Œì´ë¸”ì—ì„œ ìš©ì–´ ì •ì˜ë¥¼ ê²€ìƒ‰í•˜ê³ , ë‚œì´ë„ì— ë§ëŠ” ì„¤ëª…ì„ ì œê³µí•˜ëŠ” ë„êµ¬

### êµ¬í˜„ ë°©ë²•

**íŒŒì¼ ê²½ë¡œ**: `src/agent/nodes.py`

1. **ìš©ì–´ì§‘ ê²€ìƒ‰ ë…¸ë“œ í•¨ìˆ˜ ìƒì„±**
   - AgentStateë¥¼ íŒŒë¼ë¯¸í„°ë¡œ ë°›ëŠ” `glossary_node` í•¨ìˆ˜ ì •ì˜
   - stateì—ì„œ questionì—ì„œ ìš©ì–´ ì¶”ì¶œ
   - PostgreSQL glossary í…Œì´ë¸”ì—ì„œ ìš©ì–´ ê²€ìƒ‰
   - ë‚œì´ë„ì— ë”°ë¼ easy_explanation ë˜ëŠ” hard_explanation ë°˜í™˜
   - Vector DB glossary_embeddingsì—ì„œ ìœ ì‚¬ ìš©ì–´ ê²€ìƒ‰ (ì„ íƒ)

2. **ìš©ì–´ ì¶”ì¶œ ë¡œì§**
   - LLMì—ê²Œ ì§ˆë¬¸ì—ì„œ í•µì‹¬ ìš©ì–´ ì¶”ì¶œ ìš”ì²­
   - glossary í…Œì´ë¸”ì—ì„œ ILIKE ê²€ìƒ‰

3. **ë‚œì´ë„ë³„ ì„¤ëª… ì œê³µ**
   - Easy: easy_explanation í•„ë“œ ì‚¬ìš©
   - Hard: hard_explanation í•„ë“œ ì‚¬ìš©

### ì‚¬ìš©í•˜ëŠ” DB

#### PostgreSQL (ê´€ê³„í˜• ë°ì´í„°)
- **í…Œì´ë¸”**: `glossary`
- **ì—­í• **: ìš©ì–´ ì •ì˜ ë° ë‚œì´ë„ë³„ ì„¤ëª… ì €ì¥
- **ì¿¼ë¦¬**: `SELECT * FROM glossary WHERE term ILIKE '%{term}%'`

#### PostgreSQL + pgvector (ì„ íƒ)
- **ì»¬ë ‰ì…˜**: `glossary_embeddings`
- **ì—­í• **: ìœ ì‚¬ ìš©ì–´ ê²€ìƒ‰

### ì˜ˆì œ ì½”ë“œ

```python
# src/agent/nodes.py

from langchain_openai import ChatOpenAI
from langchain.schema import SystemMessage, HumanMessage
import psycopg2
import os

def glossary_node(state: AgentState, exp_manager=None):
    """
    ìš©ì–´ì§‘ ë…¸ë“œ: glossary í…Œì´ë¸”ì—ì„œ ìš©ì–´ ì •ì˜ ê²€ìƒ‰

    Args:
        state: Agent ìƒíƒœ
        exp_manager: ExperimentManager ì¸ìŠ¤í„´ìŠ¤ (ì„ íƒ ì‚¬í•­)
    """
    question = state["question"]
    difficulty = state.get("difficulty", "easy")

    # ë„êµ¬ë³„ Logger ìƒì„±
    tool_logger = exp_manager.get_tool_logger('rag_glossary') if exp_manager else None

    if tool_logger:
        tool_logger.write(f"ìš©ì–´ì§‘ ë…¸ë“œ ì‹¤í–‰: {question}")
        tool_logger.write(f"ë‚œì´ë„: {difficulty}")

    # 1. ì§ˆë¬¸ì—ì„œ ìš©ì–´ ì¶”ì¶œ
    llm = ChatOpenAI(model="gpt-5", temperature=0)
    extract_prompt = f"""
ë‹¤ìŒ ì§ˆë¬¸ì—ì„œ í•µì‹¬ ìš©ì–´ë¥¼ ì¶”ì¶œí•˜ì„¸ìš”. ìš©ì–´ë§Œ ë°˜í™˜í•˜ì„¸ìš”:

ì§ˆë¬¸: {question}

ìš©ì–´:
    """

    term = llm.invoke(extract_prompt).content.strip()

    if tool_logger:
        tool_logger.write(f"ì¶”ì¶œëœ ìš©ì–´: {term}")

    # 2. PostgreSQL glossary í…Œì´ë¸”ì—ì„œ ê²€ìƒ‰
    conn = psycopg2.connect(os.getenv("DATABASE_URL"))
    cursor = conn.cursor()

    query = "SELECT term, definition, easy_explanation, hard_explanation, category FROM glossary WHERE term ILIKE %s"

    if tool_logger:
        tool_logger.write(f"SQL ì¿¼ë¦¬ ì‹¤í–‰: term ILIKE '%{term}%'")

        # SQL ì¿¼ë¦¬ ê¸°ë¡
        if exp_manager:
            exp_manager.log_sql_query(
                query=query,
                description="ìš©ì–´ì§‘ ê²€ìƒ‰",
                tool="rag_glossary"
            )

    cursor.execute(query, (f"%{term}%",))
    result = cursor.fetchone()
    cursor.close()
    conn.close()

    # 3. ê²°ê³¼ ì²˜ë¦¬
    if not result:
        if tool_logger:
            tool_logger.write("ìš©ì–´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŒ")
            tool_logger.close()
        state["final_answer"] = f"'{term}' ìš©ì–´ë¥¼ ìš©ì–´ì§‘ì—ì„œ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
        return state

    term_name, definition, easy_exp, hard_exp, category = result

    if tool_logger:
        tool_logger.write(f"ìš©ì–´ ë°œê²¬: {term_name} (ì¹´í…Œê³ ë¦¬: {category})")

    # 4. ë‚œì´ë„ë³„ ì„¤ëª… ì„ íƒ
    if difficulty == "easy":
        explanation = easy_exp if easy_exp else definition
        if tool_logger:
            tool_logger.write("Easy ëª¨ë“œ ì„¤ëª… ì‚¬ìš©")
    else:  # hard
        explanation = hard_exp if hard_exp else definition
        if tool_logger:
            tool_logger.write("Hard ëª¨ë“œ ì„¤ëª… ì‚¬ìš©")

    # 5. ìµœì¢… ë‹µë³€ êµ¬ì„±
    answer = f"""
**ìš©ì–´**: {term_name}

**ì¹´í…Œê³ ë¦¬**: {category}

**ì„¤ëª…**:
{explanation}
    """

    if tool_logger:
        tool_logger.write(f"ë‹µë³€ ìƒì„± ì™„ë£Œ: {len(answer)} ê¸€ì")
        tool_logger.close()

    # 6. ìµœì¢… ë‹µë³€ ì €ì¥
    state["final_answer"] = answer

    return state
```

---

## ë„êµ¬ 6: íŒŒì¼ ì €ì¥ ë„êµ¬

### ê¸°ëŠ¥ ì„¤ëª…
ëŒ€í™” ë‚´ìš©ì´ë‚˜ ìƒì„±ëœ ë‹µë³€ì„ í…ìŠ¤íŠ¸ íŒŒì¼ë¡œ ì €ì¥í•˜ê³ , Streamlit ë‹¤ìš´ë¡œë“œ ê¸°ëŠ¥ê³¼ ì—°ë™í•˜ëŠ” ë„êµ¬

### êµ¬í˜„ ë°©ë²•

**íŒŒì¼ ê²½ë¡œ**: `src/agent/nodes.py`

1. **íŒŒì¼ ì €ì¥ ë…¸ë“œ í•¨ìˆ˜ ìƒì„±**
   - AgentStateë¥¼ íŒŒë¼ë¯¸í„°ë¡œ ë°›ëŠ” `save_file_node` í•¨ìˆ˜ ì •ì˜
   - stateì—ì„œ ì €ì¥í•  ë‚´ìš© ì¶”ì¶œ (ì´ì „ ë‹µë³€ ë˜ëŠ” ìš”ì•½ ë‚´ìš©)
   - ExperimentManagerì˜ `save_output()` ë©”ì„œë“œ ì‚¬ìš©
   - outputs/ í´ë”ì— íŒŒì¼ ì €ì¥
   - íŒŒì¼ ê²½ë¡œë¥¼ state["final_answer"]ì— ì €ì¥

2. **íŒŒì¼ëª… ìƒì„± ë¡œì§**
   - í˜„ì¬ ì‹œê°„ ê¸°ë°˜ íŒŒì¼ëª… ìƒì„± (ì˜ˆ: `response_20251031_103015.txt`)
   - ë˜ëŠ” ì‚¬ìš©ìê°€ ì§€ì •í•œ íŒŒì¼ëª… ì‚¬ìš©

3. **ExperimentManager í†µí•©**
   - `exp.save_output(filename, content)` í˜¸ì¶œ
   - íŒŒì¼ì´ experiments/ë‚ ì§œ/session_XXX/outputs/ ê²½ë¡œì— ì €ì¥ë¨

### ì‚¬ìš©í•˜ëŠ” DB
**DB ì‚¬ìš© ì—†ìŒ** (íŒŒì¼ ì‹œìŠ¤í…œë§Œ ì‚¬ìš©)

### ì˜ˆì œ ì½”ë“œ

```python
# src/agent/nodes.py

from datetime import datetime
import os

def save_file_node(state: AgentState, exp_manager=None):
    """
    íŒŒì¼ ì €ì¥ ë…¸ë“œ: ë‹µë³€ ë‚´ìš©ì„ íŒŒì¼ë¡œ ì €ì¥

    Args:
        state: Agent ìƒíƒœ
        exp_manager: ExperimentManager ì¸ìŠ¤í„´ìŠ¤ (ì„ íƒ ì‚¬í•­)
    """
    question = state["question"]

    # ë„êµ¬ë³„ Logger ìƒì„±
    tool_logger = exp_manager.get_tool_logger('file_save') if exp_manager else None

    if tool_logger:
        tool_logger.write(f"íŒŒì¼ ì €ì¥ ë…¸ë“œ ì‹¤í–‰: {question}")

    # 1. ì €ì¥í•  ë‚´ìš© í™•ì¸
    # ì´ì „ ë‹µë³€ì´ ìˆìœ¼ë©´ ê·¸ê²ƒì„ ì €ì¥, ì—†ìœ¼ë©´ ëŒ€í™” íˆìŠ¤í† ë¦¬ ì €ì¥
    content_to_save = state.get("tool_result") or state.get("final_answer") or "ì €ì¥í•  ë‚´ìš©ì´ ì—†ìŠµë‹ˆë‹¤."

    if tool_logger:
        tool_logger.write(f"ì €ì¥í•  ë‚´ìš© ê¸¸ì´: {len(content_to_save)} ê¸€ì")

    # 2. íŒŒì¼ëª… ìƒì„±
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    filename = f"response_{timestamp}.txt"

    if tool_logger:
        tool_logger.write(f"íŒŒì¼ëª…: {filename}")

    # 3. íŒŒì¼ ì €ì¥
    if exp_manager:
        # ExperimentManagerì˜ save_output ë©”ì„œë“œ ì‚¬ìš©
        file_path = exp_manager.save_output(filename, content_to_save)

        if tool_logger:
            tool_logger.write(f"íŒŒì¼ ì €ì¥ ì™„ë£Œ: {file_path}")
            tool_logger.close()

        # ì„±ê³µ ë©”ì‹œì§€
        answer = f"íŒŒì¼ì´ ì„±ê³µì ìœ¼ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.\níŒŒì¼ ê²½ë¡œ: {file_path}"
    else:
        # ExperimentManager ì—†ì„ ë•Œ (í…ŒìŠ¤íŠ¸ í™˜ê²½)
        output_dir = "outputs"
        os.makedirs(output_dir, exist_ok=True)
        file_path = os.path.join(output_dir, filename)

        with open(file_path, 'w', encoding='utf-8') as f:
            f.write(content_to_save)

        if tool_logger:
            tool_logger.write(f"íŒŒì¼ ì €ì¥ ì™„ë£Œ: {file_path}")
            tool_logger.close()

        answer = f"íŒŒì¼ì´ ì„±ê³µì ìœ¼ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.\níŒŒì¼ ê²½ë¡œ: {file_path}"

    # 4. ìµœì¢… ë‹µë³€ ì €ì¥
    state["final_answer"] = answer

    return state
```

---

## Agent ì•„í‚¤í…ì²˜ ë‹¤ì´ì–´ê·¸ë¨

### 1. LangGraph Agent êµ¬ì¡°

```mermaid
graph LR
    START([ğŸ”¸ ì‹œì‘]) --> Router{ë¼ìš°í„°<br/>ë…¸ë“œ}

    Router -->|ì¼ë°˜ ì§ˆë¬¸| General[ì¼ë°˜ ë‹µë³€]
    Router -->|ë…¼ë¬¸ ê²€ìƒ‰| RAG[RAG ê²€ìƒ‰]
    Router -->|ì›¹ ê²€ìƒ‰| Web[ì›¹ ê²€ìƒ‰]
    Router -->|ìš©ì–´ ì§ˆë¬¸| Glossary[ìš©ì–´ì§‘]
    Router -->|ìš”ì•½ ìš”ì²­| Summarize[ë…¼ë¬¸ ìš”ì•½]
    Router -->|ì €ì¥ ìš”ì²­| Save[íŒŒì¼ ì €ì¥]

    General --> END([âœ… ì¢…ë£Œ])
    RAG --> END
    Web --> END
    Glossary --> END
    Summarize --> END
    Save --> END

    style START fill:#81c784,stroke:#388e3c,color:#000
    style END fill:#66bb6a,stroke:#2e7d32,color:#000
    style Router fill:#ba68c8,stroke:#7b1fa2,color:#000
    style General fill:#ce93d8,stroke:#7b1fa2,color:#000
    style RAG fill:#ce93d8,stroke:#7b1fa2,color:#000
    style Web fill:#ce93d8,stroke:#7b1fa2,color:#000
    style Glossary fill:#ce93d8,stroke:#7b1fa2,color:#000
    style Summarize fill:#ce93d8,stroke:#7b1fa2,color:#000
    style Save fill:#ce93d8,stroke:#7b1fa2,color:#000
```

### 2. LLM ì„ íƒ ì „ëµ

```mermaid
graph TB
    A[ì‘ì—… ìœ í˜•] --> B{ì‘ì—… ë¶„ë¥˜}

    B -->|ë¼ìš°íŒ…| C[Solar<br/>ë¹ ë¥¸ ì‘ë‹µ]
    B -->|ë‹µë³€ ìƒì„±| D[GPT-5<br/>ë†’ì€ ì •í™•ë„]
    B -->|ìš”ì•½| E[GPT-5<br/>í’ˆì§ˆ ì¤‘ìš”]
    B -->|ê¸°íƒ€| F[GPT-5<br/>ë¹„ìš© íš¨ìœ¨]

    C --> G[LLM í˜¸ì¶œ]
    D --> G
    E --> G
    F --> G

    G --> H{ì—ëŸ¬?}
    H -->|Yes| I[ì¬ì‹œë„<br/>ìµœëŒ€ 3íšŒ]
    H -->|No| J[âœ… ê²°ê³¼ ë°˜í™˜]
    I --> G

    style A fill:#90caf9,stroke:#1976d2,color:#000
    style B fill:#ba68c8,stroke:#7b1fa2,color:#000
    style C fill:#ce93d8,stroke:#7b1fa2,color:#000
    style D fill:#ce93d8,stroke:#7b1fa2,color:#000
    style E fill:#ce93d8,stroke:#7b1fa2,color:#000
    style F fill:#ce93d8,stroke:#7b1fa2,color:#000
    style G fill:#a5d6a7,stroke:#388e3c,color:#000
    style H fill:#ba68c8,stroke:#7b1fa2
    style I fill:#ffcc80,stroke:#f57c00,color:#000
    style J fill:#66bb6a,stroke:#2e7d32,color:#000
```

### 3. ì—ëŸ¬ í•¸ë“¤ë§ íë¦„

```mermaid
sequenceDiagram
    autonumber
    participant Agent
    participant LLM
    participant Retry

    Agent->>LLM: API í˜¸ì¶œ

    alt ì„±ê³µ
        LLM-->>Agent: âœ… ì‘ë‹µ ë°˜í™˜
    else ì‹¤íŒ¨ (1ì°¨)
        LLM-->>Retry: âŒ ì—ëŸ¬
        Retry->>Retry: ëŒ€ê¸° 2ì´ˆ
        Retry->>LLM: ì¬ì‹œë„ (1/3)

        alt ì„±ê³µ
            LLM-->>Agent: âœ… ì‘ë‹µ ë°˜í™˜
        else ì‹¤íŒ¨ (2ì°¨)
            LLM-->>Retry: âŒ ì—ëŸ¬
            Retry->>Retry: ëŒ€ê¸° 4ì´ˆ
            Retry->>LLM: ì¬ì‹œë„ (2/3)

            alt ì„±ê³µ
                LLM-->>Agent: âœ… ì‘ë‹µ ë°˜í™˜
            else ì‹¤íŒ¨ (3ì°¨)
                LLM-->>Retry: âŒ ì—ëŸ¬
                Retry->>Retry: ëŒ€ê¸° 8ì´ˆ
                Retry->>LLM: ì¬ì‹œë„ (3/3)

                alt ì„±ê³µ
                    LLM-->>Agent: âœ… ì‘ë‹µ ë°˜í™˜
                else ìµœì¢… ì‹¤íŒ¨
                    LLM-->>Agent: âŒ ì—ëŸ¬ ë°˜í™˜
                end
            end
        end
    end
```

---

## LangGraph Agent ê·¸ë˜í”„ êµ¬í˜„

### êµ¬í˜„ ë°©ë²•

**íŒŒì¼ ê²½ë¡œ**: `src/agent/state.py`, `src/agent/graph.py`

### 1. State ì •ì˜ (`src/agent/state.py`)
- TypedDictë¥¼ ìƒì†í•œ AgentState í´ë˜ìŠ¤ ì •ì˜
- í•„ìˆ˜ í•„ë“œ:
  - question (str): ì‚¬ìš©ì ì§ˆë¬¸
  - difficulty (str): ë‚œì´ë„ (easy/hard)
  - tool_choice (str): ì„ íƒëœ ë„êµ¬
  - tool_result (str): ë„êµ¬ ì‹¤í–‰ ê²°ê³¼
  - final_answer (str): ìµœì¢… ë‹µë³€
  - messages: Annotated[Sequence[BaseMessage], operator.add] - ëŒ€í™” íˆìŠ¤í† ë¦¬

### 2. ê·¸ë˜í”„ êµ¬ì„± (`src/agent/graph.py`)
- `create_agent_graph` í•¨ìˆ˜ ìƒì„±
- StateGraph(AgentState) ì¸ìŠ¤í„´ìŠ¤ ìƒì„±
- ë…¸ë“œ ì¶”ê°€:
  - workflow.add_node("router", router_node)
  - workflow.add_node("general", general_answer_node)
  - workflow.add_node("search_paper", search_paper_node)
  - workflow.add_node("web_search", web_search_node)
  - workflow.add_node("search_glossary", glossary_node)
  - workflow.add_node("summarize_paper", summarize_node)
  - workflow.add_node("save_file", save_file_node)
- ì‹œì‘ì  ì„¤ì •: workflow.set_entry_point("router")
- ì¡°ê±´ë¶€ ì—£ì§€ ì„¤ì •: add_conditional_edgesë¡œ ë¼ìš°í„°ì—ì„œ ê° ë„êµ¬ë¡œ ë¶„ê¸°
- ëª¨ë“  ë„êµ¬ ë…¸ë“œì—ì„œ ENDë¡œ ì—°ê²°
- workflow.compile()ë¡œ ê·¸ë˜í”„ ì»´íŒŒì¼ í›„ ë°˜í™˜

### 3. ë¼ìš°í„° ë…¸ë“œ êµ¬í˜„ (`src/agent/nodes.py`)
- `router_node` í•¨ìˆ˜ ì •ì˜
- ì‚¬ìš©ì ì§ˆë¬¸ì„ ë¶„ì„í•˜ì—¬ ì ì ˆí•œ ë„êµ¬ ì„ íƒ
- ë„êµ¬ ëª©ë¡ê³¼ ê° ë„êµ¬ì˜ ì‚¬ìš© ì¼€ì´ìŠ¤ë¥¼ í¬í•¨í•œ í”„ë¡¬í”„íŠ¸ ì‘ì„±
- LLMì—ê²Œ í”„ë¡¬í”„íŠ¸ ì „ë‹¬í•˜ì—¬ ë„êµ¬ ì´ë¦„ ë°˜í™˜ë°›ê¸°
- ë°˜í™˜ëœ ë„êµ¬ ì´ë¦„ì„ state["tool_choice"]ì— ì €ì¥
- ë¼ìš°íŒ… ê²°ì • ë¡œê·¸ ì¶œë ¥

### 4. ë¼ìš°íŒ… í•¨ìˆ˜ (`src/agent/graph.py`)
- `route_to_tool` í•¨ìˆ˜: state["tool_choice"] ê°’ì„ ë°˜í™˜
- add_conditional_edgesì—ì„œ ì´ í•¨ìˆ˜ë¥¼ ì‚¬ìš©í•˜ì—¬ ë‹¤ìŒ ë…¸ë“œ ê²°ì •

### ì˜ˆì œ ì½”ë“œ

```python
# src/agent/graph.py

from langgraph.graph import StateGraph, END
from typing import TypedDict
from langchain_openai import ChatOpenAI

# ExperimentManagerëŠ” mainì—ì„œ ì „ë‹¬ë°›ì•„ ì‚¬ìš©

class AgentState(TypedDict):
    question: str
    difficulty: str
    tool_choice: str
    tool_result: str
    final_answer: str
    messages: list  # ëŒ€í™” íˆìŠ¤í† ë¦¬

def router_node(state: AgentState, exp_manager=None):
    """
    ì§ˆë¬¸ì„ ë¶„ì„í•˜ì—¬ ì–´ë–¤ ë„êµ¬ë¥¼ ì‚¬ìš©í• ì§€ ê²°ì •

    Args:
        state: Agent ìƒíƒœ
        exp_manager: ExperimentManager ì¸ìŠ¤í„´ìŠ¤ (ì„ íƒ ì‚¬í•­)
    """
    question = state["question"]

    if exp_manager:
        exp_manager.logger.write(f"ë¼ìš°í„° ë…¸ë“œ ì‹¤í–‰: {question}")

    # LLMì—ê²Œ ë¼ìš°íŒ… ê²°ì • ìš”ì²­
    routing_prompt = f"""
ì‚¬ìš©ì ì§ˆë¬¸ì„ ë¶„ì„í•˜ì—¬ ì ì ˆí•œ ë„êµ¬ë¥¼ ì„ íƒí•˜ì„¸ìš”:

ë„êµ¬ ëª©ë¡:
- search_paper: ë…¼ë¬¸ ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ ê²€ìƒ‰
- web_search: ì›¹ì—ì„œ ìµœì‹  ë…¼ë¬¸ ê²€ìƒ‰
- glossary: ìš©ì–´ ì •ì˜ ê²€ìƒ‰
- summarize: ë…¼ë¬¸ ìš”ì•½
- save_file: íŒŒì¼ ì €ì¥
- general: ì¼ë°˜ ë‹µë³€

ì§ˆë¬¸: {question}

í•˜ë‚˜ì˜ ë„êµ¬ ì´ë¦„ë§Œ ë°˜í™˜í•˜ì„¸ìš”:
    """

    llm = ChatOpenAI(model="gpt-5", temperature=0)
    tool_choice = llm.invoke(routing_prompt).content.strip()

    if exp_manager:
        exp_manager.logger.write(f"ë¼ìš°íŒ… ê²°ì •: {tool_choice}")

    state["tool_choice"] = tool_choice
    return state

def route_to_tool(state: AgentState):
    """ë¼ìš°íŒ… ê²°ì •ì— ë”°ë¼ ë‹¤ìŒ ë…¸ë“œ ì„ íƒ"""
    return state["tool_choice"]

def create_agent_graph(exp_manager=None):
    """
    LangGraph Agent ê·¸ë˜í”„ ìƒì„±

    Args:
        exp_manager: ExperimentManager ì¸ìŠ¤í„´ìŠ¤ (ì„ íƒ ì‚¬í•­)
    """
    if exp_manager:
        exp_manager.logger.write("Agent ê·¸ë˜í”„ ìƒì„± ì‹œì‘")

    workflow = StateGraph(AgentState)

    # ë…¸ë“œ ì¶”ê°€
    workflow.add_node("router", router_node)
    workflow.add_node("search_paper", search_paper_node)
    workflow.add_node("web_search", web_search_node)
    workflow.add_node("glossary", glossary_node)
    workflow.add_node("summarize", summarize_node)
    workflow.add_node("save_file", save_file_node)
    workflow.add_node("general", general_answer_node)

    # ì‹œì‘ì  ì„¤ì •
    workflow.set_entry_point("router")

    # ì¡°ê±´ë¶€ ì—£ì§€ ì„¤ì •
    workflow.add_conditional_edges(
        "router",
        route_to_tool,
        {
            "search_paper": "search_paper",
            "web_search": "web_search",
            "glossary": "glossary",
            "summarize": "summarize",
            "save_file": "save_file",
            "general": "general"
        }
    )

    # ëª¨ë“  ë…¸ë“œì—ì„œ ì¢…ë£Œ
    for node in ["search_paper", "web_search", "glossary", "summarize", "save_file", "general"]:
        workflow.add_edge(node, END)

    # ê·¸ë˜í”„ ì»´íŒŒì¼
    agent_executor = workflow.compile()

    if exp_manager:
        exp_manager.logger.write("Agent ê·¸ë˜í”„ ì»´íŒŒì¼ ì™„ë£Œ")

    return agent_executor
```

---

## LLM í´ë¼ì´ì–¸íŠ¸ êµ¬í˜„

### êµ¬í˜„ ë°©ë²•

**íŒŒì¼ ê²½ë¡œ**: `src/llm/client.py`

### 1. ë‹¤ì¤‘ LLM í´ë¼ì´ì–¸íŠ¸ í´ë˜ìŠ¤
- `LLMClient` í´ë˜ìŠ¤ ì •ì˜
- __init__ ë©”ì„œë“œ:
  - provider íŒŒë¼ë¯¸í„°ë¡œ "openai" ë˜ëŠ” "solar" ì„ íƒ
  - providerì— ë”°ë¼ ChatOpenAI ë˜ëŠ” ChatUpstage ì¸ìŠ¤í„´ìŠ¤ ìƒì„±
  - í™˜ê²½ë³€ìˆ˜ì—ì„œ API í‚¤ ë¡œë“œ (OPENAI_API_KEY, SOLAR_API_KEY)
  - streaming=True ì„¤ì •

### 2. ì—ëŸ¬ í•¸ë“¤ë§ ë° ì¬ì‹œë„
- tenacity ë¼ì´ë¸ŒëŸ¬ë¦¬ì˜ @retry ë°ì½”ë ˆì´í„° ì‚¬ìš©
- `invoke_with_retry` ë©”ì„œë“œ:
  - stop_after_attempt(3): ìµœëŒ€ 3íšŒ ì¬ì‹œë„
  - wait_exponential: ì§€ìˆ˜ ë°±ì˜¤í”„ (2ì´ˆ â†’ 4ì´ˆ â†’ 8ì´ˆ)
  - LLM í˜¸ì¶œ ì‹¤íŒ¨ ì‹œ ìë™ ì¬ì‹œë„

### 3. í† í° ì‚¬ìš©ëŸ‰ ì¶”ì 
- `invoke_with_tracking` ë©”ì„œë“œ êµ¬í˜„
- OpenAI ì‚¬ìš© ì‹œ: get_openai_callbackìœ¼ë¡œ í† í° ìˆ˜ì™€ ë¹„ìš© ì¶”ì 
- Solar ì‚¬ìš© ì‹œ: ê¸°ë³¸ ë¡œê·¸ë§Œ ì¶œë ¥
- ê° í˜¸ì¶œë§ˆë‹¤ í† í° ì •ë³´ ì¶œë ¥

### 4. ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µ ì²˜ë¦¬
- `astream` ë¹„ë™ê¸° ë©”ì„œë“œ êµ¬í˜„
- async for ë£¨í”„ë¡œ LLM ì‘ë‹µì„ ì²­í¬ ë‹¨ìœ„ë¡œ yield
- Streamlit UIì—ì„œ ì‹¤ì‹œê°„ ì‘ë‹µ í‘œì‹œì— ì‚¬ìš©

### 5. LLM ì„ íƒ ì „ëµ
- `get_llm_for_task` í•¨ìˆ˜ êµ¬í˜„
- ì‘ì—… ìœ í˜•ë³„ ìµœì  LLM ì„ íƒ:
  - routing: Solar (ë¹ ë¥¸ ì‘ë‹µ)
  - generation: GPT-5 (ë†’ì€ ì •í™•ë„)
  - summarization: GPT-5 (í’ˆì§ˆ ì¤‘ìš”)
  - ê¸°ë³¸ê°’: GPT-5 (ë¹„ìš© íš¨ìœ¨)

### ì˜ˆì œ ì½”ë“œ

```python
# src/llm/client.py

import os
from langchain_openai import ChatOpenAI
from langchain_upstage import ChatUpstage
from tenacity import retry, stop_after_attempt, wait_exponential
from langchain.callbacks import get_openai_callback

# ExperimentManagerëŠ” mainì—ì„œ ì „ë‹¬ë°›ì•„ ì‚¬ìš©

class LLMClient:
    """ë‹¤ì¤‘ LLM í´ë¼ì´ì–¸íŠ¸ í´ë˜ìŠ¤"""

    def __init__(self, provider="openai", model="gpt-5", temperature=0.7, logger=None):
        """
        Args:
            provider: "openai" ë˜ëŠ” "solar"
            model: ëª¨ë¸ ì´ë¦„
            temperature: ì°½ì˜ì„± ìˆ˜ì¤€ (0-1)
            logger: Logger ì¸ìŠ¤í„´ìŠ¤ (ì„ íƒ ì‚¬í•­)
        """
        self.provider = provider
        self.logger = logger

        if self.logger:
            self.logger.write(f"LLM ì´ˆê¸°í™”: provider={provider}, model={model}")

        if provider == "openai":
            self.llm = ChatOpenAI(
                model=model,
                temperature=temperature,
                openai_api_key=os.getenv("OPENAI_API_KEY"),
                streaming=True
            )
        elif provider == "solar":
            self.llm = ChatUpstage(
                model="solar-1-mini-chat",
                temperature=temperature,
                api_key=os.getenv("SOLAR_API_KEY"),
                streaming=True
            )

    @retry(stop=stop_after_attempt(3), wait=wait_exponential(multiplier=2, min=2, max=8))
    def invoke_with_retry(self, messages):
        """
        ì—ëŸ¬ í•¸ë“¤ë§ ë° ì¬ì‹œë„
        ìµœëŒ€ 3íšŒ ì¬ì‹œë„, ì§€ìˆ˜ ë°±ì˜¤í”„ (2ì´ˆ â†’ 4ì´ˆ â†’ 8ì´ˆ)
        """
        if self.logger:
            self.logger.write("LLM í˜¸ì¶œ ì‹œì‘ (ì¬ì‹œë„ ê°€ëŠ¥)")
        return self.llm.invoke(messages)

    def invoke_with_tracking(self, messages):
        """í† í° ì‚¬ìš©ëŸ‰ ì¶”ì """
        if self.provider == "openai":
            with get_openai_callback() as cb:
                response = self.llm.invoke(messages)
                if self.logger:
                    self.logger.write(f"Tokens Used: {cb.total_tokens}")
                    self.logger.write(f"Total Cost: ${cb.total_cost:.4f}")
                return response
        else:
            return self.llm.invoke(messages)

    async def astream(self, messages):
        """ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µ ì²˜ë¦¬"""
        if self.logger:
            self.logger.write("ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µ ì‹œì‘")
        async for chunk in self.llm.astream(messages):
            yield chunk


def get_llm_for_task(task_type, logger=None):
    """
    ì‘ì—… ìœ í˜•ë³„ ìµœì  LLM ì„ íƒ

    Args:
        task_type: ì‘ì—… ìœ í˜•
        logger: Logger ì¸ìŠ¤í„´ìŠ¤ (ì„ íƒ ì‚¬í•­)
    """
    if logger:
        logger.write(f"ì‘ì—… ìœ í˜•ë³„ LLM ì„ íƒ: {task_type}")

    if task_type == "routing":
        return LLMClient(provider="solar", model="solar-1-mini-chat", temperature=0)
    elif task_type == "generation":
        return LLMClient(provider="openai", model="gpt-5", temperature=0.7)
    elif task_type == "summarization":
        return LLMClient(provider="openai", model="gpt-5", temperature=0)
    else:
        return LLMClient(provider="openai", model="gpt-5", temperature=0.7)
```

---

## ëŒ€í™” ë©”ëª¨ë¦¬ ì‹œìŠ¤í…œ

### êµ¬í˜„ ë°©ë²•

**íŒŒì¼ ê²½ë¡œ**: `src/memory/chat_history.py`

### 1. ChatMemoryManager í´ë˜ìŠ¤
- ConversationBufferMemory ì¸ìŠ¤í„´ìŠ¤ ìƒì„±
  - return_messages=True: ë©”ì‹œì§€ ê°ì²´ í˜•íƒœë¡œ ë°˜í™˜
  - memory_key="chat_history": ë©”ëª¨ë¦¬ í‚¤ ì„¤ì •
- `add_user_message`: ì‚¬ìš©ì ë©”ì‹œì§€ ì¶”ê°€
- `add_ai_message`: AI ë©”ì‹œì§€ ì¶”ê°€
- `get_history`: ì „ì²´ ëŒ€í™” íˆìŠ¤í† ë¦¬ ë°˜í™˜
- `clear`: ëŒ€í™” íˆìŠ¤í† ë¦¬ ì´ˆê¸°í™”

### 2. ì„¸ì…˜ ê¸°ë°˜ ë©”ëª¨ë¦¬ (ì„ íƒì‚¬í•­)
- PostgresChatMessageHistory ì‚¬ìš©
- `get_session_history` í•¨ìˆ˜:
  - session_idë¡œ íŠ¹ì • ì„¸ì…˜ì˜ ëŒ€í™” íˆìŠ¤í† ë¦¬ ì¡°íšŒ
  - PostgreSQLì— ëŒ€í™” ë‚´ìš© ì˜êµ¬ ì €ì¥
  - ì—¬ëŸ¬ ì‚¬ìš©ì ì„¸ì…˜ ê´€ë¦¬ ê°€ëŠ¥

### 3. Agentì™€ ë©”ëª¨ë¦¬ í†µí•©
- Agent ì‹¤í–‰ ì‹œ messages í•„ë“œì— ë©”ëª¨ë¦¬ íˆìŠ¤í† ë¦¬ ì „ë‹¬
- ì‘ë‹µ ìƒì„± í›„ ì‚¬ìš©ì ë©”ì‹œì§€ì™€ AI ë©”ì‹œì§€ë¥¼ ë©”ëª¨ë¦¬ì— ì¶”ê°€
- ì´í›„ ì§ˆë¬¸ì—ì„œ ì´ì „ ëŒ€í™” ì»¨í…ìŠ¤íŠ¸ í™œìš©

### ì˜ˆì œ ì½”ë“œ

```python
# src/memory/chat_history.py

from langchain.memory import ConversationBufferMemory
from langchain_postgres import PostgresChatMessageHistory
import os

class ChatMemoryManager:
    """ëŒ€í™” ë©”ëª¨ë¦¬ ê´€ë¦¬ í´ë˜ìŠ¤"""

    def __init__(self):
        """ConversationBufferMemory ì´ˆê¸°í™”"""
        self.memory = ConversationBufferMemory(
            return_messages=True,
            memory_key="chat_history"
        )

    def add_user_message(self, message: str):
        """ì‚¬ìš©ì ë©”ì‹œì§€ ì¶”ê°€"""
        self.memory.chat_memory.add_user_message(message)

    def add_ai_message(self, message: str):
        """AI ë©”ì‹œì§€ ì¶”ê°€"""
        self.memory.chat_memory.add_ai_message(message)

    def get_history(self):
        """ì „ì²´ ëŒ€í™” íˆìŠ¤í† ë¦¬ ë°˜í™˜"""
        return self.memory.load_memory_variables({})

    def clear(self):
        """ëŒ€í™” íˆìŠ¤í† ë¦¬ ì´ˆê¸°í™”"""
        self.memory.clear()


def get_session_history(session_id: str):
    """
    ì„¸ì…˜ ê¸°ë°˜ ë©”ëª¨ë¦¬ (PostgreSQL ì €ì¥)

    Args:
        session_id: ì„¸ì…˜ ID

    Returns:
        PostgresChatMessageHistory ì¸ìŠ¤í„´ìŠ¤
    """
    connection_string = os.getenv("DATABASE_URL", "postgresql://user:password@localhost:5432/papers")

    return PostgresChatMessageHistory(
        session_id=session_id,
        connection_string=connection_string,
        table_name="chat_history"
    )


# ì‚¬ìš© ì˜ˆì‹œ
if __name__ == "__main__":
    # ê¸°ë³¸ ë©”ëª¨ë¦¬ ì‚¬ìš©
    memory_manager = ChatMemoryManager()

    memory_manager.add_user_message("Transformer ë…¼ë¬¸ ì„¤ëª…í•´ì¤˜")
    memory_manager.add_ai_message("TransformerëŠ” 2017ë…„ Googleì—ì„œ ë°œí‘œí•œ...")

    logger.write(f"ë©”ëª¨ë¦¬ íˆìŠ¤í† ë¦¬: {memory_manager.get_history()}")

    # ì„¸ì…˜ ê¸°ë°˜ ë©”ëª¨ë¦¬ ì‚¬ìš©
    session_history = get_session_history("user_123")
    session_history.add_user_message("BERT ë…¼ë¬¸ì€?")
    session_history.add_ai_message("BERTëŠ” 2018ë…„ì—...")

    logger.write(f"ì„¸ì…˜ ë©”ì‹œì§€: {session_history.messages}")
    logger.close()
```

---

## ë¡œê¹… ë° ì‹¤í—˜ ì¶”ì  ê´€ë¦¬

### ExperimentManager ì‚¬ìš©

**ì¤‘ìš”**: ëª¨ë“  ì±—ë´‡ ì‹¤í–‰ì€ ExperimentManagerë¥¼ ì‚¬ìš©í•˜ì—¬ ìë™ìœ¼ë¡œ ê¸°ë¡í•©ë‹ˆë‹¤.

**íŒŒì¼ ê²½ë¡œ**: `src/utils/experiment_manager.py`

**ì£¼ìš” ê¸°ëŠ¥**:
- Session ID ìë™ ë¶€ì—¬ (session_001, 002, ...)
- 7ê°œ ì„œë¸Œ í´ë” ìë™ ìƒì„± (tools, database, prompts, ui, outputs, evaluation, debug)
- metadata.json ê¸°ë°˜ ìë™ ì¶”ì 
- with ë¬¸ ì§€ì› (ìë™ ì´ˆê¸°í™” ë° ì¢…ë£Œ)

**ì‚¬ìš© ë°©ë²•**:

1. **ê¸°ë³¸ ì‚¬ìš© (with ë¬¸)**
   ```python
   from src.utils.experiment_manager import ExperimentManager

   # with ë¬¸ìœ¼ë¡œ ìë™ ì´ˆê¸°í™” ë° ì¢…ë£Œ
   with ExperimentManager() as exp:
       # ìë™ìœ¼ë¡œ ë‹¤ìŒ ì‘ì—… ìˆ˜í–‰:
       # 1. experiments/20251031/20251031_103015_session_001/ ìƒì„±
       # 2. Session ID ìë™ ë¶€ì—¬ (session_001, 002...)
       # 3. chatbot.log íŒŒì¼ ìƒì„±
       # 4. 7ê°œ ì„œë¸Œ í´ë” ìƒì„±
       # 5. metadata.json ì´ˆê¸°í™”
       # 6. Logger ì´ˆê¸°í™”

       # ë©”ì¸ ë¡œê·¸ ê¸°ë¡
       exp.logger.write("Agent ì‹¤í–‰ ì‹œì‘")
       exp.logger.write(f"ì§ˆë¬¸: {question}")

       # ë©”íƒ€ë°ì´í„° ì—…ë°ì´íŠ¸
       exp.update_metadata(
           user_query=question,
           difficulty="easy"
       )

       # with ë¸”ë¡ì´ ëë‚˜ë©´ ìë™ìœ¼ë¡œ Logger ì¢…ë£Œ
   ```

2. **ë„êµ¬ë³„ Logger ì‚¬ìš©**
   ```python
   with ExperimentManager() as exp:
       # ë„êµ¬ë³„ Logger ìƒì„±
       tool_logger = exp.get_tool_logger('rag_paper')
       tool_logger.write("ë…¼ë¬¸ ê²€ìƒ‰ ì‹œì‘")
       tool_logger.write("ê²€ìƒ‰ ì™„ë£Œ: 5ê°œ ë…¼ë¬¸ ë°œê²¬")
       tool_logger.close()
   ```

3. **í‰ê°€ ì§€í‘œ ì €ì¥**
   ```python
   with ExperimentManager() as exp:
       # RAG í‰ê°€ ì§€í‘œ
       exp.save_rag_metrics({
           "recall_at_5": 0.8,
           "faithfulness": 0.95
       })

       # Agent ì •í™•ë„
       exp.save_agent_accuracy({
           "predicted_tool": "rag_paper",
           "correct": True
       })

       # ë¹„ìš© ë¶„ì„
       exp.save_cost_analysis({
           "total_cost_krw": 30.51
       })
   ```

### ì‹¤í—˜ í´ë” êµ¬ì¡°

**ìë™ ìƒì„± êµ¬ì¡°**: `experiments/ë‚ ì§œ/ë‚ ì§œ_ì‹œê°„_session_XXX/`

```
experiments/
â””â”€â”€ 20251031/                                # ë‚ ì§œ (YYYYMMDD)
    â””â”€â”€ 20251031_103015_session_001/         # ì‹œê°„_session_ID
        â”œâ”€â”€ metadata.json                    # â­ ì „ì²´ ì‹¤í—˜ ë©”íƒ€ë°ì´í„°
        â”œâ”€â”€ chatbot.log                      # ë©”ì¸ ì‹¤í–‰ ë¡œê·¸
        â”œâ”€â”€ config.yaml                      # ì „ì²´ ì„¤ì •
        â”œâ”€â”€ tools/                           # ë„êµ¬ ì‹¤í–‰ ë¡œê·¸
        â”œâ”€â”€ database/                        # DB ê´€ë ¨ ê¸°ë¡
        â”œâ”€â”€ prompts/                         # í”„ë¡¬í”„íŠ¸ ê¸°ë¡
        â”œâ”€â”€ ui/                              # UI ê´€ë ¨ ê¸°ë¡
        â”œâ”€â”€ outputs/                         # ê²°ê³¼ë¬¼
        â””â”€â”€ evaluation/                      # í‰ê°€ ì§€í‘œ
```

**í•„ìˆ˜ íŒŒì¼**:
- `metadata.json`: Session ID, ì‹œì‘/ì¢…ë£Œ ì‹œê°„, ë‚œì´ë„, ë„êµ¬, ì‘ë‹µ ì‹œê°„ ë“±
- `chatbot.log`: exp.logger.write() ì¶œë ¥
- `config.yaml`: LLM ì„¤ì •, ëª¨ë¸ ì •ë³´
- `evaluation/`: RAG í‰ê°€, Agent ì •í™•ë„, ì‘ë‹µ ì‹œê°„, ë¹„ìš© ë¶„ì„

### ì°¸ê³  ë¬¸ì„œ

- [05_ë¡œê¹…_ì‹œìŠ¤í…œ.md](../PRD/05_ë¡œê¹…_ì‹œìŠ¤í…œ.md) - ExperimentManager ìƒì„¸ ì‚¬ìš©ë²•
- [06_ì‹¤í—˜_ì¶”ì _ê´€ë¦¬.md](../PRD/06_ì‹¤í—˜_ì¶”ì _ê´€ë¦¬.md) - ì‹¤í—˜ í´ë” êµ¬ì¡° ë° Session ID ê·œì¹™
- [ì‹¤í—˜_í´ë”_êµ¬ì¡°_ìµœì¢…ì•ˆ.md](../references/ì‹¤í—˜_í´ë”_êµ¬ì¡°_ìµœì¢…ì•ˆ.md) - ì „ì²´ í´ë” êµ¬ì¡° ë° ExperimentManager ì „ì²´ ì½”ë“œ
- [ë‹´ë‹¹ì—­í• _01-1_ìµœí˜„í™”_ì‹¤í—˜_ê´€ë¦¬_ì‹œìŠ¤í…œ.md](../roles/ë‹´ë‹¹ì—­í• _01-1_ìµœí˜„í™”_ì‹¤í—˜_ê´€ë¦¬_ì‹œìŠ¤í…œ.md) - ì‹¤í—˜ ê´€ë¦¬ ì‹œìŠ¤í…œ êµ¬í˜„ ê°€ì´ë“œ

---

## ê°œë°œ ì¼ì •

### Phase 1: LLM í´ë¼ì´ì–¸íŠ¸ ë° ê³µí†µ ì¸í”„ë¼
- ChatOpenAI ë˜í¼ êµ¬í˜„
- ì—ëŸ¬ í•¸ë“¤ë§ ë° ì¬ì‹œë„ ë¡œì§
- í† í° ì‚¬ìš©ëŸ‰ ì¶”ì 
- ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µ ì²˜ë¦¬

### Phase 2: LangGraph Agent ê·¸ë˜í”„
- State ì •ì˜
- ë¼ìš°í„° ë…¸ë“œ êµ¬í˜„
- ì¡°ê±´ë¶€ ì—£ì§€ ì„¤ì •
- ì¼ë°˜ ë‹µë³€ ë…¸ë“œ êµ¬í˜„

### Phase 3: ë©”ëª¨ë¦¬ ì‹œìŠ¤í…œ
- ConversationBufferMemory êµ¬í˜„
- ëŒ€í™” íˆìŠ¤í† ë¦¬ ê´€ë¦¬
- ì„¸ì…˜ ê´€ë¦¬

### Phase 4: ë…¼ë¬¸ ìš”ì•½ ë„êµ¬
- load_summarize_chain êµ¬í˜„
- ë‚œì´ë„ë³„ í”„ë¡¬í”„íŠ¸ ì„¤ê³„
- ìš”ì•½ ë°©ì‹ ì„ íƒ ë¡œì§

### Phase 5: í†µí•© ì‘ì—…
- main.py ì‘ì„±
- ëª¨ë“  ëª¨ë“ˆ í†µí•©
- ë””ë²„ê¹… ë° í…ŒìŠ¤íŠ¸

### Phase 6: ë°œí‘œ ì¤€ë¹„
- ë°œí‘œ ìë£Œ ì‘ì„±
- README.md ì‘ì„±
- ìµœì¢… ì ê²€

---

## main.py êµ¬í˜„

### êµ¬í˜„ ë°©ë²•

**íŒŒì¼ ê²½ë¡œ**: `main.py` (í”„ë¡œì íŠ¸ ë£¨íŠ¸)

1. **í•„ìš”í•œ ëª¨ë“ˆ import**
   - src.agent.graphì—ì„œ create_agent_graph
   - src.llm.clientì—ì„œ LLMClient
   - src.memory.chat_historyì—ì„œ ChatMemoryManager

2. **ì´ˆê¸°í™”**
   - LLMClient ì¸ìŠ¤í„´ìŠ¤ ìƒì„± (model="gpt-5", temperature=0.7)
   - create_agent_graph()ë¡œ Agent ìƒì„±
   - ChatMemoryManager ì¸ìŠ¤í„´ìŠ¤ ìƒì„±

3. **Agent ì‹¤í–‰ ë£¨í”„**
   - í…ŒìŠ¤íŠ¸ ì§ˆë¬¸ ë¦¬ìŠ¤íŠ¸ ì¤€ë¹„ (ì§ˆë¬¸, ë‚œì´ë„ íŠœí”Œ)
   - ê° ì§ˆë¬¸ì— ëŒ€í•´:
     - agent.invoke()ë¡œ ì‹¤í–‰ (question, difficulty, messages ì „ë‹¬)
     - ê²°ê³¼ì—ì„œ final_answer ì¶”ì¶œ
     - memory_managerì— ì‚¬ìš©ì ë©”ì‹œì§€ì™€ AI ë©”ì‹œì§€ ì¶”ê°€
     - ê²°ê³¼ ì¶œë ¥

4. **ì‹¤í–‰**
   - if __name__ == "__main__": main() ì¶”ê°€
   - ì»¤ë§¨ë“œë¼ì¸ì—ì„œ python main.pyë¡œ ì‹¤í–‰

---

## Feature ë¸Œëœì¹˜

### ì´ 3ê°œ ë¸Œëœì¹˜ë¡œ êµ¬í˜„

**íš¨ìœ¨ì ì¸ ì‘ì—…ì„ ìœ„í•´ 10ê°œ ë¸Œëœì¹˜ë¥¼ 3ê°œë¡œ í†µí•©**

---

### **1. `feature/agent-system` (Phase 1: ê¸°ë°˜ ì‹œìŠ¤í…œ)**

**ìš°ì„ ìˆœìœ„**: P0 (ìµœìš°ì„ )

**êµ¬í˜„ ë‚´ìš©**:

#### 1-1. LLM í´ë¼ì´ì–¸íŠ¸ êµ¬í˜„
- ChatOpenAI + Solar(Upstage) ë‹¤ì¤‘ LLM ì§€ì›
- ì—ëŸ¬ í•¸ë“¤ë§ ë° ì¬ì‹œë„ ë¡œì§ (tenacity)
- í† í° ì‚¬ìš©ëŸ‰ ì¶”ì  (get_openai_callback)
- ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µ ì²˜ë¦¬ (astream)
- LLM ì„ íƒ ì „ëµ (ì‘ì—… ìœ í˜•ë³„)

#### 1-2. Agent ê·¸ë˜í”„ ê¸°ë³¸ êµ¬ì¡°
- AgentState ì •ì˜ (question, difficulty, tool_choice, tool_result, final_answer, messages)
- ë¹ˆ ë…¸ë“œ í•¨ìˆ˜ë“¤ ì •ì˜ (placeholder í•¨ìˆ˜ 6ê°œ)
- ë¼ìš°í„° ë…¸ë“œ ê¸°ë³¸ êµ¬ì¡°
- StateGraph ìƒì„± ë° ì¡°ê±´ë¶€ ì—£ì§€ ì„¤ì •
- ê·¸ë˜í”„ ì»´íŒŒì¼

**êµ¬í˜„ íŒŒì¼**:
- `src/llm/client.py` - LLMClient í´ë˜ìŠ¤, get_llm_for_task() í•¨ìˆ˜
- `src/agent/state.py` - AgentState TypedDict ì •ì˜
- `src/agent/graph.py` - create_agent_graph() í•¨ìˆ˜, route_to_tool() í•¨ìˆ˜
- `src/agent/nodes.py` - router_node() ë° 6ê°œ ë¹ˆ ë…¸ë“œ í•¨ìˆ˜ (placeholder)

**í…ŒìŠ¤íŠ¸ ë°©ë²•**:
- LLM í´ë¼ì´ì–¸íŠ¸ ë‹¨ë… í…ŒìŠ¤íŠ¸ (OpenAI, Solar API í˜¸ì¶œ)
- Agent ê·¸ë˜í”„ ì»´íŒŒì¼ í…ŒìŠ¤íŠ¸
- ë¼ìš°í„° ë…¸ë“œ í…ŒìŠ¤íŠ¸ (ë„êµ¬ ì„ íƒ ë¡œì§)

**ì˜ì¡´ì„±**: ì—†ìŒ

---

### **2. `feature/agent-tools` (Phase 2~4: 6ê°œ ë„êµ¬ êµ¬í˜„)**

**ìš°ì„ ìˆœìœ„**: P1

**êµ¬í˜„ ë‚´ìš©**:

#### 2-1. ê°„ë‹¨í•œ ë„êµ¬ (DB/API ë¶ˆí•„ìš”)
- **ë„êµ¬ 1: ì¼ë°˜ ë‹µë³€** (general_answer_node)
  - ë‚œì´ë„ë³„ SystemMessage ì„¤ì •
  - LLM ì§ì ‘ í˜¸ì¶œ
  - ExperimentManager í†µí•©

- **ë„êµ¬ 2: íŒŒì¼ ì €ì¥** (save_file_node)
  - ExperimentManager.save_output() ì‚¬ìš©
  - íŒŒì¼ëª… ìë™ ìƒì„± (timestamp)
  - outputs/ í´ë”ì— ì €ì¥

#### 2-2. DB/API í†µí•© ë„êµ¬ (íŒ€ì› í˜‘ì—… í•„ìš”)
- **ë„êµ¬ 3: RAG ê²€ìƒ‰** (search_paper_node) â­ ì‹ ì¤€ì—½ í˜‘ì—…
  - pgvector ìœ ì‚¬ë„ ê²€ìƒ‰ (Top-5)
  - PostgreSQL papers í…Œì´ë¸” ë©”íƒ€ë°ì´í„° ì¡°íšŒ
  - ë‚œì´ë„ë³„ í”„ë¡¬í”„íŠ¸ êµ¬ì„±
  - ExperimentManager í†µí•© (DB ì¿¼ë¦¬ ê¸°ë¡, ê²€ìƒ‰ ê²°ê³¼ ì €ì¥)

- **ë„êµ¬ 4: ìš©ì–´ì§‘** (glossary_node) â­ ì‹ ì¤€ì—½ í˜‘ì—…
  - PostgreSQL glossary í…Œì´ë¸” ê²€ìƒ‰
  - ë‚œì´ë„ë³„ ì„¤ëª… ì œê³µ (easy_explanation / hard_explanation)
  - ìš©ì–´ ì¶”ì¶œ ë¡œì§ (LLM ì‚¬ìš©)
  - ExperimentManager í†µí•©

- **ë„êµ¬ 5: ì›¹ ê²€ìƒ‰** (web_search_node) â­ ì„ì˜ˆìŠ¬ í˜‘ì—…
  - Tavily Search API í˜¸ì¶œ
  - ê²€ìƒ‰ ê²°ê³¼ LLM ì •ë¦¬
  - ë‚œì´ë„ë³„ í”„ë¡¬í”„íŠ¸ ì ìš©
  - ExperimentManager í†µí•©

#### 2-3. ë³µì¡í•œ ë„êµ¬
- **ë„êµ¬ 6: ë…¼ë¬¸ ìš”ì•½** (summarize_node)
  - PostgreSQL papers í…Œì´ë¸”ì—ì„œ ë…¼ë¬¸ ê²€ìƒ‰
  - pgvectorì—ì„œ ë…¼ë¬¸ ì „ì²´ ì²­í¬ ì¡°íšŒ (filter by paper_id)
  - load_summarize_chain (stuff, map_reduce, refine)
  - ë‚œì´ë„ë³„ í”„ë¡¬í”„íŠ¸ ì„¤ê³„
  - ExperimentManager í†µí•©

**êµ¬í˜„ íŒŒì¼**:
- `src/agent/nodes.py` - 6ê°œ ë…¸ë“œ í•¨ìˆ˜ ì „ì²´ êµ¬í˜„ (placeholder â†’ ì‹¤ì œ êµ¬í˜„)
- `src/tools/summarize.py` - ë…¼ë¬¸ ìš”ì•½ ë„êµ¬ (ì„ íƒ)

**í…ŒìŠ¤íŠ¸ ë°©ë²•**:
- ê° ë„êµ¬ë³„ ë‹¨ë… í…ŒìŠ¤íŠ¸
- Agent ê·¸ë˜í”„ì—ì„œ ë„êµ¬ í˜¸ì¶œ í…ŒìŠ¤íŠ¸
- ExperimentManager ë¡œê¹… í™•ì¸

**ì˜ì¡´ì„±**: `feature/agent-system`

**í˜‘ì—… í¬ì¸íŠ¸**:
- ì‹ ì¤€ì—½: RAG ì‹œìŠ¤í…œ, ìš©ì–´ì§‘ ì‹œìŠ¤í…œ
- ì„ì˜ˆìŠ¬: Tavily Search API

---

### **3. `feature/agent-integration` (Phase 5: í†µí•©)**

**ìš°ì„ ìˆœìœ„**: P2

**êµ¬í˜„ ë‚´ìš©**:

#### 3-1. ëŒ€í™” ë©”ëª¨ë¦¬ ì‹œìŠ¤í…œ
- ConversationBufferMemory êµ¬í˜„
- ëŒ€í™” íˆìŠ¤í† ë¦¬ ê´€ë¦¬ (add_user_message, add_ai_message)
- ì„¸ì…˜ ê¸°ë°˜ ë©”ëª¨ë¦¬ (PostgresChatMessageHistory, ì„ íƒ)
- Agentì™€ ë©”ëª¨ë¦¬ í†µí•©

#### 3-2. main.py ì‘ì„±
- Agent ì‹¤í–‰ ë£¨í”„ êµ¬í˜„
- ExperimentManager ì „ì—­ í†µí•©
- í…ŒìŠ¤íŠ¸ ì§ˆë¬¸ ë¦¬ìŠ¤íŠ¸ë¡œ Agent ì‹¤í–‰
- ê²°ê³¼ ì¶œë ¥ ë° ë¡œê¹…

#### 3-3. ì „ì²´ í†µí•© í…ŒìŠ¤íŠ¸
- 10ê°œ ì‹œë‚˜ë¦¬ì˜¤ í…ŒìŠ¤íŠ¸ (PRD 09 í‰ê°€ ê¸°ì¤€)
- ë””ë²„ê¹… ë° ì˜¤ë¥˜ ìˆ˜ì •
- ì„±ëŠ¥ ìµœì í™”

**êµ¬í˜„ íŒŒì¼**:
- `src/memory/chat_history.py` - ChatMemoryManager í´ë˜ìŠ¤
- `main.py` - Agent ì‹¤í–‰ ë©”ì¸ íŒŒì¼
- `tests/test_agent.py` - í†µí•© í…ŒìŠ¤íŠ¸ (ì„ íƒ)

**í…ŒìŠ¤íŠ¸ ë°©ë²•**:
- ì „ì²´ Agent ì‹¤í–‰ í…ŒìŠ¤íŠ¸
- 10ê°œ ì‹œë‚˜ë¦¬ì˜¤ ê²€ì¦
- ë¡œê·¸ íŒŒì¼ í™•ì¸

**ì˜ì¡´ì„±**: `feature/agent-system`, `feature/agent-tools`

---

### ë¸Œëœì¹˜ ì‘ì—… ìˆœì„œ

```
1. feature/agent-system
   â”œâ”€ LLM í´ë¼ì´ì–¸íŠ¸ êµ¬í˜„
   â”œâ”€ Agent ê·¸ë˜í”„ ê¸°ë³¸ êµ¬ì¡°
   â””â”€ ë¹ˆ ë…¸ë“œ í•¨ìˆ˜ë“¤ (placeholder)
   â†“
   ë³‘í•© â†’ develop
   â†“
2. feature/agent-tools
   â”œâ”€ ë„êµ¬ 1: ì¼ë°˜ ë‹µë³€
   â”œâ”€ ë„êµ¬ 2: íŒŒì¼ ì €ì¥
   â”œâ”€ ë„êµ¬ 3: RAG ê²€ìƒ‰ (ì‹ ì¤€ì—½ í˜‘ì—…)
   â”œâ”€ ë„êµ¬ 4: ìš©ì–´ì§‘ (ì‹ ì¤€ì—½ í˜‘ì—…)
   â”œâ”€ ë„êµ¬ 5: ì›¹ ê²€ìƒ‰ (ì„ì˜ˆìŠ¬ í˜‘ì—…)
   â””â”€ ë„êµ¬ 6: ë…¼ë¬¸ ìš”ì•½
   â†“
   ë³‘í•© â†’ develop
   â†“
3. feature/agent-integration
   â”œâ”€ ëŒ€í™” ë©”ëª¨ë¦¬ ì‹œìŠ¤í…œ
   â”œâ”€ main.py ì‘ì„±
   â””â”€ ì „ì²´ í†µí•© í…ŒìŠ¤íŠ¸
   â†“
   ìµœì¢… ë³‘í•© â†’ develop â†’ main
```

---

### í˜‘ì—… í¬ì¸íŠ¸

**ì‹ ì¤€ì—½ íŒ€ì›ê³¼ í˜‘ì—… í•„ìš”:**
- RAG ì‹œìŠ¤í…œ (Vector DB ìŠ¤í‚¤ë§ˆ, ê²€ìƒ‰ ë¡œì§)
- ìš©ì–´ì§‘ ì‹œìŠ¤í…œ (glossary í…Œì´ë¸” ìŠ¤í‚¤ë§ˆ)

**ì„ì˜ˆìŠ¬ íŒ€ì›ê³¼ í˜‘ì—… í•„ìš”:**
- Tavily Search API (API í‚¤, ì‚¬ìš©ë²•)

**íŒ€ ì „ì²´ í˜‘ì—…:**
- ExperimentManager í†µí•© (ëª¨ë“  ë„êµ¬ì—ì„œ ì‚¬ìš©)
- í”„ë¡¬í”„íŠ¸ ì—”ì§€ë‹ˆì–´ë§ (ë‚œì´ë„ë³„ í”„ë¡¬í”„íŠ¸ ê²€í† )

---

## ì°¸ê³  PRD ë¬¸ì„œ

ê°œë°œ ì‹œ ë°˜ë“œì‹œ ì°¸ê³ í•´ì•¼ í•  PRD ë¬¸ì„œ ëª©ë¡:

### í•„ìˆ˜ ì°¸ê³  ë¬¸ì„œ
1. [01_í”„ë¡œì íŠ¸_ê°œìš”.md](../PRD/01_í”„ë¡œì íŠ¸_ê°œìš”.md) - í”„ë¡œì íŠ¸ ì „ì²´ ê°œìš” ë° ëª©í‘œ
2. [02_í”„ë¡œì íŠ¸_êµ¬ì¡°.md](../PRD/02_í”„ë¡œì íŠ¸_êµ¬ì¡°.md) - í´ë” êµ¬ì¡° ë° ëª¨ë“ˆ ë°°ì¹˜
3. [05_ë¡œê¹…_ì‹œìŠ¤í…œ.md](../PRD/05_ë¡œê¹…_ì‹œìŠ¤í…œ.md) â­â­â­ - ExperimentManager ì‚¬ìš©ë²• ë° ë¡œê¹… ê·œì¹™
4. [06_ì‹¤í—˜_ì¶”ì _ê´€ë¦¬.md](../PRD/06_ì‹¤í—˜_ì¶”ì _ê´€ë¦¬.md) â­â­â­ - ì‹¤í—˜ í´ë” êµ¬ì¡° ë° Session ID ìë™ ë¶€ì—¬ ê·œì¹™
5. [09_í‰ê°€_ê¸°ì¤€.md](../PRD/09_í‰ê°€_ê¸°ì¤€.md) â­â­ - RAG í‰ê°€, Agent ì •í™•ë„, ì‘ë‹µ ì‹œê°„, ë¹„ìš© ë¶„ì„
6. [10_ê¸°ìˆ _ìš”êµ¬ì‚¬í•­.md](../PRD/10_ê¸°ìˆ _ìš”êµ¬ì‚¬í•­.md) - ê¸°ìˆ  ìŠ¤íƒ ë° ë¼ì´ë¸ŒëŸ¬ë¦¬
7. [12_AI_Agent_ì„¤ê³„.md](../PRD/12_AI_Agent_ì„¤ê³„.md) - LangGraph êµ¬ì¡° ë° ë„êµ¬ ì •ì˜
8. [14_LLM_ì„¤ì •.md](../PRD/14_LLM_ì„¤ì •.md) - LLM ì„ íƒ ì „ëµ ë° ì—ëŸ¬ í•¸ë“¤ë§

### ì°¸ê³  ì—­í•  ë¬¸ì„œ
- [ë‹´ë‹¹ì—­í• _01-1_ìµœí˜„í™”_ì‹¤í—˜_ê´€ë¦¬_ì‹œìŠ¤í…œ.md](ë‹´ë‹¹ì—­í• _01-1_ìµœí˜„í™”_ì‹¤í—˜_ê´€ë¦¬_ì‹œìŠ¤í…œ.md) â­â­â­ - ExperimentManager êµ¬í˜„ ê°€ì´ë“œ
- [ë‹´ë‹¹ì—­í• _01-2_ìµœí˜„í™”_ë¡œê¹…_ëª¨ë‹ˆí„°ë§.md](ë‹´ë‹¹ì—­í• _01-2_ìµœí˜„í™”_ë¡œê¹…_ëª¨ë‹ˆí„°ë§.md) â­â­ - Logger ë° ì‹¤í—˜ ê´€ë¦¬ ì‹œìŠ¤í…œ

### ì°¸ê³  ë ˆí¼ëŸ°ìŠ¤ ë¬¸ì„œ
- [ì‹¤í—˜_í´ë”_êµ¬ì¡°.md](../rules/ì‹¤í—˜_í´ë”_êµ¬ì¡°.md) â­â­â­ - ì „ì²´ í´ë” êµ¬ì¡° ë° ExperimentManager ì „ì²´ ì½”ë“œ

### ê¸°íƒ€ ì°¸ê³  ë¬¸ì„œ
- [03_ë¸Œëœì¹˜_ì „ëµ.md](../PRD/03_ë¸Œëœì¹˜_ì „ëµ.md) - Feature ë¸Œëœì¹˜ ì „ëµ
- [04_ì¼ì •_ê´€ë¦¬.md](../PRD/04_ì¼ì •_ê´€ë¦¬.md) - ê°œë°œ ì¼ì • ë° ë§ˆì¼ìŠ¤í†¤
- [11_ë°ì´í„°ë² ì´ìŠ¤_ì„¤ê³„.md](../PRD/11_ë°ì´í„°ë² ì´ìŠ¤_ì„¤ê³„.md) - DB ìŠ¤í‚¤ë§ˆ (ìš”ì•½ ë„êµ¬ì—ì„œ ì‚¬ìš©)

---

## ì°¸ê³  ìë£Œ

- LangGraph ê³µì‹ ë¬¸ì„œ: https://langchain-ai.github.io/langgraph/
- Langchain ChatOpenAI: https://python.langchain.com/docs/integrations/chat/openai/
- Langchain Memory: https://python.langchain.com/docs/modules/memory/
- Langchain Summarization: https://python.langchain.com/docs/use_cases/summarization/
- Langchain Callbacks: https://python.langchain.com/docs/modules/callbacks/
