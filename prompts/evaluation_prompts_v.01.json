{
  "evaluation_prompt": {
    "template": "당신은 AI 챗봇 답변 품질을 평가하는 전문가입니다. 다음 AI 챗봇의 답변을 다차원 기준으로 평가해주세요.\n\n[사용자 질문]\n{question}\n\n[AI 답변]\n{answer}\n\n[참고 문서]\n{reference_docs}\n\n[난이도 모드]\n{difficulty}\n\n[평가 기준]\n1. 정확도 (0-10점): 참고 문서의 내용과 일치하는가?\n   - 10점: 완벽히 일치\n   - 7-9점: 대부분 일치하나 일부 누락\n   - 4-6점: 부분적으로 일치\n   - 0-3점: 거의 일치하지 않음\n\n2. 관련성 (0-10점): 질문과 답변이 관련있는가?\n   - 10점: 질문에 완벽히 답변\n   - 7-9점: 대부분 관련 있으나 일부 불필요한 정보\n   - 4-6점: 부분적으로 관련\n   - 0-3점: 거의 관련 없음\n\n3. 난이도 적합성 (0-10점): 난이도 모드에 맞는 답변인가?\n   - Easy 모드:\n     * 10점: 쉬운 용어, 비유 사용, 간단 요약\n     * 7-9점: 대부분 쉬운 언어 사용\n     * 4-6점: 일부 어려운 용어 포함\n     * 0-3점: 전문 용어 과다, 복잡한 설명\n   - Hard 모드:\n     * 10점: 기술 용어, 수식, 복잡도, 논문 비교 포함\n     * 7-9점: 대부분 전문적 설명\n     * 4-6점: 일부만 전문적\n     * 0-3점: 너무 간단, 깊이 부족\n\n4. 출처 명시 (0-10점): 논문 제목, 저자를 명시했는가?\n   - 10점: 제목, 저자, 발행일 모두 명시\n   - 7-9점: 제목과 저자 명시\n   - 4-6점: 제목만 명시\n   - 0-3점: 출처 미명시\n\nJSON 형식으로만 반환하세요:\n{\n    \"accuracy_score\": <점수>,\n    \"relevance_score\": <점수>,\n    \"difficulty_score\": <점수>,\n    \"citation_score\": <점수>,\n    \"total_score\": <총점>,\n    \"comment\": \"<평가 코멘트>\"\n}",
    "input_variables": ["question", "answer", "reference_docs", "difficulty"]
  },

    "evaluation_criteria": {
    "accuracy": {
      "name": "정확도",
      "weight": 0.3,
      "description": "참고 문서의 사실과의 일치도, 환각 및 왜곡 여부",
      "key_questions": [
        "핵심 개념이 정확한가?",
        "수치와 고유명사가 맞는가?",
        "사실 왜곡이 없는가?"
      ]
    },
    "relevance": {
      "name": "관련성",
        "weight": 0.3,
        "description": "질문 의도와의 적합성, 답변 범위의 적절성, 질문과 답변의 관련성, 참고 문서의 내용과 일치 정도"
        "key_questions": [
          "질문이 요구한 정보를 제공하는가?",
          "불필요한 정보가 없는가?",
          "질문의 맥락을 이해했는가?"
        ]
    },
    "difficulty": {
      "name": "난이도 적합성",
      "weight": 0.2,
      "description": "지정된 난이도 모드에 맞는 언어, 깊이, 설명 방식",
      "key_questions": [
        "적절한 용어 수준을 사용했는가?",
        "난이도에 맞는 설명 깊이인가?",
        "일관된 난이도를 유지하는가?"
      ]
    },
    "citation": {
      "name": "출처 명시",
      "weight": 0.2,
      "description": "학술적 출처의 명확한 표기 (제목, 저자, 연도)",
      "key_questions": [
        "논문 제목을 명시했는가?",
        "저자명을 밝혔는가?",
        "인용 위치가 적절한가?"
      ]
    }
  },

  "evaluation_examples": [
    {
      "question": "BERT가 뭐야?",
      "answer": "BERT는 Google이 2018년에 발표한 언어 모델이고, 양방향으로 문맥을 이해하는 것이 특징이야. 예를 들자면, 책을 읽을 때 앞뒤 문맥을 모두 고려하는 것과 같은 거야",
      "reference_docs": "BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding (Devlin et al., 2018)",
      "difficulty": "easy",
      "expected_evaluation": {
        "accuracy_score": 9,
        "accuracy_reason": "BERT의 핵심 특징인 양방향 문맥 이해를 정확히 설명. Google과 2018년 발표 사실도 정확. 다만 'Pre-training'이나 'Transformer' 기반이라는 점은 누락.",
        
        "relevance_score": 10,
        "relevance_reason": "\"BERT가 뭐야?\"라는 질문에 정의와 핵심 특징을 직접적으로 답변. 불필요한 정보 없이 간결하게 핵심만 전달.",
        
        "difficulty_score": 10,
        "difficulty_reason": "Easy 모드에 완벽히 부합. '양방향', '문맥' 등 필수 용어는 사용하되 '책 읽기' 비유로 쉽게 풀어냄. 전문 용어 최소화.",
        
        "citation_score": 6,
        "citation_reason": "논문 제목과 연도는 언급했으나 저자명(Devlin et al.)은 명시하지 않음. 인용 위치는 적절함.",
        
        "total_score": 8.8,
        "overall_comment": "Easy 모드에 적합한 명확하고 이해하기 쉬운 답변. 핵심 개념을 비유로 잘 설명했으나, 저자명 명시와 일부 기술적 배경(Transformer, Pre-training) 추가하면 더 완성도 높은 답변이 될 것.",
        
        "strengths": [
          "효과적인 비유로 양방향 특성을 직관적으로 설명",
          "질문에 직접적이고 간결하게 답변"
        ],
        "weaknesses": [
          "저자명(Devlin et al.) 미명시",
          "Transformer 기반이라는 기술적 배경 누락"
        ]
      }
    },
    {
      "question": "Transformer의 어텐션 메커니즘을 설명해줘",
      "answer": "Transformer는 'Attention is All You Need'(Vaswani et al., 2017)에서 제안된 모델로, Self-Attention 메커니즘을 사용합니다. 이는 Q(Query), K(Key), V(Value) 행렬을 통해 Attention(Q,K,V) = softmax(QK^T/√d_k)V로 계산되며, 각 토큰이 시퀀스 내 모든 토큰과의 관계를 병렬로 학습할 수 있습니다. Multi-Head Attention은 이를 여러 부분공간에서 수행하여 다양한 관계 패턴을 포착합니다.",
      "reference_docs": "Attention is All You Need (Vaswani et al., 2017)",
      "difficulty": "hard",
      "expected_evaluation": {
        "accuracy_score": 10,
        "accuracy_reason": "Self-Attention 수식, Q/K/V 개념, Multi-Head Attention 모두 논문 내용과 정확히 일치. 기술적 세부사항까지 정확하게 설명.",
        
        "relevance_score": 10,
        "relevance_reason": "어텐션 메커니즘 설명 요청에 수식과 함께 구체적 원리를 설명. 질문의 기술적 깊이를 정확히 파악하고 적절한 수준으로 답변.",
        
        "difficulty_score": 10,
        "difficulty_reason": "Hard 모드에 완벽 부합. 수식 표기, 전문 용어(Query/Key/Value, 부분공간), 수학적 표현(√d_k) 모두 포함. 학술적 깊이 있음.",
        
        "citation_score": 10,
        "citation_reason": "논문 제목, 저자명(Vaswani et al.), 연도(2017) 모두 명시. 답변 시작 부분에 자연스럽게 인용.",
        
        "total_score": 10.0,
        "overall_comment": "Hard 모드에 완벽히 부합하는 전문적이고 정확한 답변. 수식과 기술적 세부사항을 포함하여 어텐션 메커니즘의 핵심을 명확히 설명했으며, 출처 인용도 완벽함.",
        
        "strengths": [
          "수식과 함께 수학적으로 정확한 설명",
          "완벽한 출처 인용 (제목, 저자, 연도)",
          "Multi-Head Attention까지 확장 설명"
        ],
        "weaknesses": []
      }
    },
    {
      "question": "GPT는 어떻게 학습되나요?",
      "answer": "GPT는 대량의 텍스트 데이터로 사전학습됩니다. 많은 데이터를 학습해서 언어를 이해하게 됩니다.",
      "reference_docs": "Language Models are Unsupervised Multitask Learners (Radford et al., 2019)\nLanguage Models are Few-Shot Learners (Brown et al., 2020)",
      "difficulty": "easy",
      "expected_evaluation": {
        "accuracy_score": 6,
        "accuracy_reason": "사전학습이라는 핵심 개념은 맞지만 GPT의 특징적 학습 방식인 autoregressive 언어모델링, next token prediction 등 중요 메커니즘 누락. '언어를 이해'는 다소 추상적.",
        
        "relevance_score": 8,
        "relevance_reason": "학습 방법에 대한 질문에 사전학습으로 답변하여 기본적으로 관련성 있음. 다만 '어떻게'라는 질문의 의도(구체적 방법론)에는 충분히 답하지 못함.",
        
        "difficulty_score": 9,
        "difficulty_reason": "Easy 모드에 적합한 쉬운 언어 사용. 전문 용어를 피하고 '많은 데이터', '언어를 이해' 등 일상적 표현 사용. 간결함.",
        
        "citation_score": 0,
        "citation_reason": "참고 문서가 2개 제공되었으나 답변에서 어떠한 출처도 명시하지 않음. 논문 제목, 저자, 연도 모두 누락.",
        
        "total_score": 5.5,
        "overall_comment": "Easy 모드에 맞게 쉽게 설명했으나, 출처를 전혀 명시하지 않았고 GPT의 핵심 학습 메커니즘(autoregressive modeling)이 빠져 정확도가 낮음. 'next token prediction' 같은 개념을 쉬운 비유로 설명하고 출처를 추가해야 함.",
        
        "strengths": [
          "쉽고 이해하기 쉬운 언어 사용"
        ],
        "weaknesses": [
          "출처 완전 미명시",
          "핵심 학습 메커니즘(next token prediction) 누락",
          "'어떻게'에 대한 구체성 부족"
        ]
      }
    }
  ],
  
  "quality_assurance": {
    "consistency_check": "동일한 품질의 답변은 ±1점 이내의 점수를 받아야 합니다.",
    "calibration_rule": "예시 답변들과 비교하여 상대적 품질을 고려하세요.",
    "edge_cases": {
      "no_reference": "참고 문서 없음 → accuracy는 'N/A' 또는 중립점수 5점",
      "answer_refusal": "답변 거부 → relevance 0점, 다른 항목도 0점",
      "off_topic": "주제 완전 이탈 → relevance 0-2점",
      "perfect_copy": "참고문서 그대로 복사 → accuracy 10점이나 difficulty 감점 가능",
      "no_difficulty": "난이도 미지정 → difficulty 평가 제외, 가중치 재분배"
    }
  },
  
  "scorer_guidelines": {
    "approach": "순차적으로 각 기준을 독립적으로 평가",
    "documentation": "각 점수마다 체크리스트 항목 중 충족/미충족 명시",
    "reasoning": "감정적 판단 배제, 객관적 근거 기반 평가",
    "improvement": "weaknesses에는 실행 가능한 개선 방안 제시"
  }
}
