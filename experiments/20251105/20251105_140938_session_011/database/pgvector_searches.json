[
  {
    "tool": "glossary",
    "collection": "glossary_embeddings",
    "query_text": "AI가 뭐야?",
    "search_mode": "hybrid",
    "top_k": 3,
    "with_scores": true,
    "result_length": 764,
    "timestamp": "2025-11-05T14:09:41.326585"
  },
  {
    "tool": "glossary",
    "collection": "glossary_embeddings",
    "query_text": "CNN에서 필터가 하는 일이 뭐야?",
    "search_mode": "hybrid",
    "top_k": 3,
    "with_scores": true,
    "result_length": 17,
    "timestamp": "2025-11-05T14:10:02.753519"
  },
  {
    "tool": "glossary",
    "collection": "glossary_embeddings",
    "query_text": "Transformer가 뭐야?",
    "search_mode": "hybrid",
    "top_k": 3,
    "with_scores": true,
    "result_length": 783,
    "timestamp": "2025-11-05T14:10:22.825462"
  },
  {
    "tool": "glossary",
    "collection": "glossary_embeddings",
    "query_text": "Attention Mechanism이 뭔지 알려줘",
    "search_mode": "hybrid",
    "top_k": 3,
    "with_scores": true,
    "result_length": 17,
    "timestamp": "2025-11-05T14:10:46.692001"
  },
  {
    "tool": "search_paper",
    "collection": "paper_chunks",
    "query_text": "Transformer 관련 논문 찾아줘",
    "search_mode": "similarity",
    "top_k": 5,
    "use_multi_query": false,
    "result_length": 4470,
    "timestamp": "2025-11-05T14:10:55.247057"
  },
  {
    "tool": "search_paper",
    "collection": "paper_chunks",
    "query_text": "BERT 모델 논문 있어?",
    "search_mode": "similarity",
    "top_k": 5,
    "use_multi_query": false,
    "result_length": 4675,
    "timestamp": "2025-11-05T14:11:06.303365"
  },
  {
    "tool": "search_paper",
    "collection": "paper_chunks",
    "query_text": "Few-shot learning 연구 논문 보여줘",
    "search_mode": "similarity",
    "top_k": 5,
    "use_multi_query": false,
    "result_length": 4131,
    "timestamp": "2025-11-05T14:11:16.186337"
  },
  {
    "tool": "search_paper",
    "collection": "paper_chunks",
    "query_text": "\"Attention Is All You Need\" 논문 요약해줘",
    "search_mode": "similarity",
    "top_k": 5,
    "use_multi_query": false,
    "result_length": 4488,
    "timestamp": "2025-11-05T14:11:37.570724"
  },
  {
    "tool": "search_paper",
    "collection": "paper_chunks",
    "query_text": "GPT 논문 찾아서 요약해줘",
    "search_mode": "similarity",
    "top_k": 5,
    "use_multi_query": false,
    "result_length": 2615,
    "timestamp": "2025-11-05T14:12:10.910204"
  },
  {
    "tool": "search_paper",
    "collection": "paper_chunks",
    "query_text": "Attention 관련 논문 정리해줘",
    "search_mode": "similarity",
    "top_k": 5,
    "use_multi_query": false,
    "result_length": 4448,
    "timestamp": "2025-11-05T14:12:22.587849"
  },
  {
    "tool": "glossary",
    "collection": "glossary_embeddings",
    "query_text": "RAG가 뭔지 설명하고 관련 논문도 보여줘",
    "search_mode": "hybrid",
    "top_k": 3,
    "with_scores": true,
    "result_length": 17,
    "timestamp": "2025-11-05T14:12:36.124510"
  },
  {
    "tool": "glossary",
    "collection": "glossary_embeddings",
    "query_text": "Vision Transformer가 뭐야?",
    "search_mode": "hybrid",
    "top_k": 3,
    "with_scores": true,
    "result_length": 258,
    "timestamp": "2025-11-05T14:12:51.944645"
  },
  {
    "tool": "search_paper",
    "collection": "paper_chunks",
    "query_text": "관련 논문 찾아줘",
    "search_mode": "similarity",
    "top_k": 5,
    "use_multi_query": false,
    "result_length": 4300,
    "timestamp": "2025-11-05T14:13:01.432249"
  }
]