{
  "question_generation_prompt": {
    "template": "다음 논문을 기반으로 체계적인 테스트용 질문을 생성해주세요.\n\n[논문 정보]\n제목: {title}\n저자: {authors}\n초록: {abstract}\n주요 키워드: {keywords}\n발행년도: {year}\n연구 분야: {field}\n\n[생성 규칙]\n1. 난이도 분포:\n   - Beginner (초급): 3개 - 기본 개념 이해\n   - Intermediate (중급): 4개 - 방법론 이해\n   - Advanced (고급): 3개 - 심층 분석 및 비교\n\n2. 도구 활용 분포:\n   - search_paper: 2개 (관련 논문 검색)\n   - web_search: 2개 (최신 동향, 실제 응용)\n   - glossary: 2개 (용어 정의)\n   - summarize: 2개 (내용 요약)\n   - general: 2개 (일반 질문, 비교 분석)\n\n3. 질문 유형 다양성:\n   - 정의형 (What): 2개\n   - 방법형 (How): 2개\n   - 비교형 (Compare): 2개\n   - 분석형 (Why): 2개\n   - 평가형 (Evaluate): 2개\n\n4. 질문 품질 기준:\n   - 명확성: 모호하지 않은 표현\n   - 구체성: 측정 가능한 답변 유도\n   - 관련성: 논문 내용과 직접 연관\n   - 다양성: 중복되지 않는 관점\n\n[출력 형식]\nJSON 형식으로 반환:\n{\n  \"paper_metadata\": {\n    \"title\": \"{title}\",\n    \"difficulty_level\": \"추정된 논문 난이도\",\n    \"research_domain\": \"연구 영역\"\n  },\n  \"questions\": [\n    {\n      \"id\": \"Q001\",\n      \"question\": \"질문 내용\",\n      \"difficulty\": \"beginner|intermediate|advanced\",\n      \"question_type\": \"definition|method|comparison|analysis|evaluation\",\n      \"expected_tool\": \"search_paper|web_search|glossary|summarize|general\",\n      \"expected_answer_keywords\": [\"키워드1\", \"키워드2\", \"키워드3\"],\n      \"evaluation_criteria\": {\n        \"required_elements\": [\"필수 포함 요소1\", \"필수 포함 요소2\"],\n        \"quality_indicators\": [\"품질 지표1\", \"품질 지표2\"],\n        \"min_answer_length\": 50\n      },\n      \"context\": \"질문의 배경 및 의도\",\n      \"follow_up_questions\": [\"후속 질문1\", \"후속 질문2\"]\n    }\n  ],\n  \"quality_metrics\": {\n    \"difficulty_distribution\": {\"beginner\": 3, \"intermediate\": 4, \"advanced\": 3},\n    \"tool_distribution\": {\"search_paper\": 2, \"web_search\": 2, \"glossary\": 2, \"summarize\": 2, \"general\": 2},\n    \"type_distribution\": {\"definition\": 2, \"method\": 2, \"comparison\": 2, \"analysis\": 2, \"evaluation\": 2}\n  }\n}",
    "input_variables": ["title", "authors", "abstract", "keywords", "year", "field"]
  },

  "difficulty_definitions": {
    "easy": {
      "description": "기본~중급 수준 (beginner + intermediate 통합)",
      "cognitive_level": "기억, 이해, 적용",
      "sub_levels": {
        "beginner": {
          "focus": "기본 개념과 용어 이해",
          "characteristics": [
            "단순한 정의 요구",
            "Yes/No 또는 단답형 가능",
            "논문의 표면적 내용",
            "일반적인 배경 지식"
          ]
        },
        "intermediate": {
          "focus": "방법론과 구현 이해",
          "characteristics": [
            "과정과 절차 이해",
            "중간 길이 설명 필요",
            "논문의 핵심 내용",
            "방법론적 세부사항"
          ]
        }
      },
      "example_patterns": [
        "{term}이 뭐야?",
        "{method}이 뭐야?",
        "{method}는 어떻게 작동해?",
        "{algorithm}의 주요 단계?"
      ],
      "distribution": "easy 질문의 60%는 beginner, 40%는 intermediate 수준"
    },
    "hard": {
      "description": "고급 수준 (advanced)",
      "cognitive_level": "분석, 평가, 창조",
      "characteristics": [
        "복잡한 비교와 대조",
        "상세한 설명 필요",
        "논문의 함의와 한계",
        "연구 맥락과 영향",
        "비판적 사고 요구"
      ],
      "example_patterns": [
        "{method1}과 {method2}를 비교 분석해줘",
        "이 연구의 한계점과 개선 방향은 뭐가 있어?",
        "{approach}의 이론적 기반을 설명해줘",
        "연구 결과의 장기적 영향 알려줘"
      ]
    }
  },
 "question_templates_enhanced": {
    "definition": {
      "beginner": [
        "{term} 설명해줘",
        "{concept} 정의가 뭐야?",
        "{abbreviation}가 무슨 뜻이야?",
        "논문에 {keyword}가 어떤거야?"
      ],
      "intermediate": [
        "{term} 특징 설명해줘",
        "{concept}이 {field}에서 왜 중요해?",
        "{method}의 구성 요소가 뭐야?"
      ],
      "advanced": [
        "{term}의 이론적 배경과 발전 과정 설명해줘",
        "{concept}에 대한 다양한 관점을 비교해줘",
        "{paradigm}이 등장한 역사적 맥락이 뭐야?"
      ]
    },
  "question_templates": {
    "easy": [
      "{term}가 뭐야?",
      "{paper_title} 간단히 설명해줘",
      "{concept} 쉽게 알려줘",
      "{paper_title} 요약해줘",
      "{method}는 어떻게 작동해?"
    ],
    "hard": [
      "{algorithm}의 시간 복잡도는?",
      "{paper_title}의 핵심 기여는?",
      "{method1}과 {method2}의 차이는?",
      "{paper_title}의 한계점은?",
      "{architecture}의 구조를 자세히 설명해줘"
    ]
  },

  "tool_based_templates": {
    "search_paper": [
      "{keyword} 논문 찾아줘",
      "{topic}에 대한 연구 검색해줘",
      "{author}의 논문 찾아줘"
    ],
    "web_search": [
      "최신 {topic} 뉴스",
      "2024년 {field} 연구 동향",
      "최근 {method} 발전"
    ],
    "glossary": [
      "{term}이 뭐야?",
      "{concept}의 정의는?",
      "{abbreviation} 설명해줘"
    ],
    "summarize": [
      "{paper_title} 요약해줘",
      "{paper_title} 핵심 내용",
      "{paper_title} 간단히 정리해줘"
    ],
    "general": [
      "{A}와 {B}의 차이는?",
      "{method}가 {baseline}보다 나은 이유는?",
      "{concept} 설명해줘"
    ],
    "save_file": [
      "대화 내용 저장해줘",
      "파일로 다운로드",
      "결과 저장"
    ],
    "text2sql": [
      "{year}년에 발표된 논문 개수는?",
      "카테고리별 논문 수 보여줘",
      "가장 많이 인용된 논문 Top {n}는?",
      "{category} 분야 논문 몇 편?",
      "논문 통계 알려줘",
      "년도별 논문 분포 보여줘"
    ]
  },

  "examples": [
    {
      "paper": {
        "title": "BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding",
        "authors": "Devlin et al.",
        "abstract": "We introduce BERT, a new language representation model...",
        "keywords": ["BERT", "pre-training", "bidirectional", "Transformer", "NLP"],
        "year": "2019",
        "field": "Natural Language Processing"
      },
      "generated_questions": [
        {
          "id": "Q001",
          "question": "BERT가 뭐야?",
          "difficulty": "beginner",
          "question_type": "definition",
          "expected_tool": "glossary",
          "expected_answer_keywords": ["Bidirectional", "Transformer", "pre-training", "언어 모델"],
          "evaluation_criteria": {
            "required_elements": ["양방향", "사전학습", "Transformer 기반"],
            "quality_indicators": ["명확한 정의", "핵심 특징 언급"],
            "min_answer_length": 50
          },
          "context": "BERT의 기본 개념 이해를 평가",
          "follow_up_questions": [
            "BERT는 어떤 문제를 해결하기 위해 만들어졌나요?",
            "BERT와 GPT의 차이는 무엇인가요?"
          ]
        },
        {
          "id": "Q002",
          "question": "BERT 논문 찾아줘",
          "difficulty": "beginner",
          "question_type": "definition",
          "expected_tool": "search_paper",
          "expected_answer_keywords": ["Devlin", "2019", "Google"],
          "evaluation_criteria": {
            "required_elements": ["저자명", "발표연도"],
            "quality_indicators": ["정확한 정보"],
            "min_answer_length": 30
          },
          "context": "논문 검색 기능 테스트",
          "follow_up_questions": []
        },
        {
          "id": "Q003",
          "question": "Masked Language Model(MLM)가 뭐야?어떻게 작동해?",
          "difficulty": "intermediate",
          "question_type": "method",
          "expected_tool": "general",
          "expected_answer_keywords": ["마스킹", "토큰 예측", "15%", "양방향 문맥"],
          "evaluation_criteria": {
            "required_elements": ["마스킹 비율", "예측 메커니즘", "학습 목표"],
            "quality_indicators": ["단계별 설명", "예시 포함"],
            "min_answer_length": 100
          },
          "context": "BERT의 핵심 학습 방법 이해",
          "follow_up_questions": [
            "왜 15%를 마스킹하나요?",
            "MLM과 전통적인 언어 모델의 차이는?"
          ]
        },
        {
          "id": "Q004",
          "question": "BERT 논문 3문장으로 요약해줘",
          "difficulty": "intermediate",
          "question_type": "evaluation",
          "expected_tool": "summarize",
          "expected_answer_keywords": ["양방향", "사전학습", "fine-tuning", "SOTA"],
          "evaluation_criteria": {
            "required_elements": ["핵심 방법", "주요 기여", "결과"],
            "quality_indicators": ["간결성", "완결성"],
            "min_answer_length": 80
          },
          "context": "논문 핵심 이해도 평가",
          "follow_up_questions": []
        },
        {
          "id": "Q005",
          "question": "BERT의 최신 발전 동향",
          "difficulty": "intermediate",
          "question_type": "analysis",
          "expected_tool": "web_search",
          "expected_answer_keywords": ["RoBERTa", "ALBERT", "DistilBERT", "효율화"],
          "evaluation_criteria": {
            "required_elements": ["후속 연구", "개선 방향"],
            "quality_indicators": ["최신 정보", "구체적 사례"],
            "min_answer_length": 100
          },
          "context": "BERT 이후 연구 동향 파악",
          "follow_up_questions": [
            "RoBERTa는 BERT를 어떻게 개선했나요?"
          ]
        },
        {
          "id": "Q006",
          "question": "BERT를 사용한 최신 논문?",
          "difficulty": "intermediate",
          "question_type": "method",
          "expected_tool": "search_paper",
          "expected_answer_keywords": ["BERT 응용", "2024", "downstream task"],
          "evaluation_criteria": {
            "required_elements": ["논문 제목", "저자", "주요 내용"],
            "quality_indicators": ["최신성", "관련성"],
            "min_answer_length": 80
          },
          "context": "BERT 응용 연구 검색 능력",
          "follow_up_questions": []
        }