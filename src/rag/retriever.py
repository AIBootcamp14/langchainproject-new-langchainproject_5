# ==========================================
# ğŸ“˜ Phase 1: RAG ì‹œìŠ¤í…œ ê¸°ì´ˆ êµ¬í˜„
# ğŸ“ Step 1~2: PGVector ê¸°ë°˜ Retriever ë° ê¸°ë³¸ ê²€ìƒ‰ ë¡œì§
# ------------------------------------------
# - OpenAI Embeddings ì´ˆê¸°í™” (embeddings.py)
# - VectorStore (PGVector) ì—°ë™ (vector_store.py)
# - similarity / MMR ê²€ìƒ‰ ì§€ì›
# - MultiQueryRetriever(ì¿¼ë¦¬ í™•ì¥) í†µí•© (Phase 2)
# - ë©”íƒ€ë°ì´í„° í•„í„° ê²€ìƒ‰ ì œê³µ (ë…„ë„/ì¹´í…Œê³ ë¦¬ ë“±)
# ==========================================

import os
import hashlib
from typing import List, Dict, Any, Optional, Tuple

from langchain_core.documents import Document
from langchain_openai import ChatOpenAI
# ---------- MultiQueryRetriever ì„í¬íŠ¸(ë²„ì „ í˜¸í™˜) ----------
# - í”„ë¡œì íŠ¸ í™˜ê²½ì—ì„œ í™•ì¸ëœ ì•ˆì • ê²½ë¡œ: langchain_classic.retrievers
# - í™˜ê²½ì— ë”°ë¼ ë‹¤ë¥¼ ìˆ˜ ìˆìœ¼ë¯€ë¡œ í•„ìš” ì‹œ ëŒ€ì²´ ê²½ë¡œ ì‚¬ìš© ê°€ëŠ¥
from langchain_classic.retrievers import MultiQueryRetriever # ê¶Œì¥
# ëŒ€ì²´: ì‹ /êµ¬ë²„ì „ ê²½ë¡œ íƒìƒ‰ (í•„ìš” ì‹œ í™•ì¥)
# from langchain.retrievers.multi_query import MultiQueryRetriever # type: ignore

from .vector_store import get_pgvector_store


# ---------- ìƒìˆ˜/í™˜ê²½ ----------
COLLECTION_CHUNKS = os.getenv("PGV_COLLECTION_CHUNKS", "paper_chunks")
DEFAULT_LLM_MODEL = os.getenv("LLM_MODEL", "gpt-5")

# ---------- ìœ í‹¸: ë¬¸ì„œ ì¤‘ë³µ ì œê±° ----------
def _dedup_docs(docs: List[Document]) -> List[Document]:
    """
    ë¬¸ì„œ ë¦¬ìŠ¤íŠ¸ì—ì„œ page_content+metadata ê¸°ì¤€ìœ¼ë¡œ ì¤‘ë³µ ì œê±°.
    - ë™ì¼ ë¬¸ì¥ì´ ë‹¤ì–‘í•œ ì¿¼ë¦¬ì—ì„œ ì¬íƒìƒ‰ë˜ëŠ” ê²½ìš° ì¤‘ë³µì„ ì¤„ì—¬ ìµœì¢… kê°œ í’ˆì§ˆ í™•ë³´.
    """
    seen = set()
    uniq: List[Document] = []
    for d in docs:
        key = hashlib.md5((d.page_content + str(d.metadata)).encode("utf-8")).hexdigest()
        if key not in seen:
            seen.add(key)
            uniq.append(d)
    return uniq

class RAGRetriever:
    """
    RAG ê²€ìƒ‰ìš© Retriever ì§‘í•© í´ë˜ìŠ¤
    - PGVector VectorStoreë¥¼ ê¸°ë°˜ìœ¼ë¡œ similarity/MMR ê²€ìƒ‰ ì œê³µ
    - MultiQueryRetrieverë¡œ ì¿¼ë¦¬ í™•ì¥(Phase 2)
    - ë©”íƒ€ë°ì´í„° í•„í„° ê²€ìƒ‰ ì§€ì›


    Parameters
    ----------
    collection_name : str
        pgvector ì»¬ë ‰ì…˜ëª… (ê¸°ë³¸: paper_chunks)
    search_type : str
        "similarity" ë˜ëŠ” "mmr"
    k : int
        ìµœì¢… ë°˜í™˜ ë¬¸ì„œ ìˆ˜
    fetch_k : int
        MMR í›„ë³´ ìˆ˜ (search_type="mmr"ì¼ ë•Œ ì‚¬ìš©)
    lambda_mult : float
        MMR ê´€ë ¨ì„±/ë‹¤ì–‘ì„± ê· í˜• (0~1)
    llm_model : Optional[str]
        MultiQueryì— ì‚¬ìš©í•  LLM ì´ë¦„ (ê¸°ë³¸ í™˜ê²½ë³€ìˆ˜ LLM_MODEL)
    llm_temperature : float
        LLM temperature
    """

    # ---------- ì´ˆê¸°í™” ----------
    def __init__(
        self,
        collection_name: str = COLLECTION_CHUNKS,
        search_type: str = "mmr",
        k: int = 5,
        fetch_k: int = 20,
        lambda_mult: float = 0.5,
        llm_model: Optional[str] = None,
        llm_temperature: float = 0.0,
    ):
        # VectorStore ì¤€ë¹„
        self.vectorstore = get_pgvector_store(collection_name)


        # ê²€ìƒ‰ íŒŒë¼ë¯¸í„° ë³´ê´€
        self.search_type = search_type
        self.k = k
        self.fetch_k = fetch_k
        self.lambda_mult = lambda_mult


        # Base retriever êµ¬ì„±
        self._retriever = self._build_retriever()


        # LLM/MQR ì„¤ì • (ì—†ìœ¼ë©´ ìë™ í´ë°±)
        self.llm_model = llm_model or DEFAULT_LLM_MODEL
        self.llm_temperature = llm_temperature
        self._multi_query_retriever: Optional[MultiQueryRetriever] = None # type: ignore
        self._maybe_build_multiquery()


        # ---------- ë‚´ë¶€: retriever êµ¬ì„± ----------
    def _build_retriever(self):
        if self.search_type == "mmr":
            return self.vectorstore.as_retriever(
                search_type="mmr",
                search_kwargs={
                    "k": self.k,
                    "fetch_k": self.fetch_k,
                    "lambda_mult": self.lambda_mult,
                },
            )
        # ê¸°ë³¸: similarity
        return self.vectorstore.as_retriever(
            search_type="similarity",
            search_kwargs={"k": self.k},
        )

    # ---------- ë‚´ë¶€: MultiQueryRetriever êµ¬ì„± (ìˆìœ¼ë©´ ì‚¬ìš©) ----------
    def _maybe_build_multiquery(self):
    api_key = os.getenv("OPENAI_API_KEY")
    if not api_key or MultiQueryRetriever is None:
        self._multi_query_retriever = None
        return
    try:
        llm = ChatOpenAI(model=self.llm_model, temperature=self.llm_temperature)
        base = self.vectorstore.as_retriever(
            search_type=self.search_type,
            search_kwargs={
                "k": self.k,
                **(
                    {"fetch_k": self.fetch_k, "lambda_mult": self.lambda_mult}
                    if self.search_type == "mmr"
                    else {}
                ),
            },
        )
        self._multi_query_retriever = MultiQueryRetriever.from_llm(
            retriever=base,
            llm=llm,
        )
    except Exception:
        # LLM/ë„¤íŠ¸ì›Œí¬ ë¬¸ì œ ë“± ë°œìƒ ì‹œ í´ë°±
        self._multi_query_retriever = None

    # ---------- ê³µê°œ API: ê¸°ë³¸ ê²€ìƒ‰ ----------
    def invoke(self, query: str) -> List[Document]:
        """ê¸°ë³¸ ê²€ìƒ‰ ì‹¤í–‰ (í˜„ì¬ ì„¤ì •ëœ search_type ì‚¬ìš©)."""
        return self._retriever.invoke(query)

    def similarity_search(self, query: str, k: Optional[int] = None) -> List[Document]:
        """VectorStore ìœ ì‚¬ë„ ê²€ìƒ‰ (ìƒìœ„ k)."""
        k = k or self.k
        return self.vectorstore.similarity_search(query, k=k)

    def similarity_search_with_score(self, query: str, k: Optional[int] = None) -> List[Tuple[Document, float]]:
        """ìœ ì‚¬ë„ ê²€ìƒ‰ + ì ìˆ˜ ë°˜í™˜."""
        k = k or self.k
        return self.vectorstore.similarity_search_with_score(query, k=k)

    # ---------- ê³µê°œ API: ëª¨ë“œ ì „í™˜ ----------
    def set_mode(self, search_type: str = "similarity"):
        """ëŸ°íƒ€ì„ ê²€ìƒ‰ ëª¨ë“œ ì „í™˜ (similarity/MMR)."""
        self.search_type = search_type
        self._retriever = self._build_retriever()
        self._maybe_build_multiquery()

    # ---------- ê³µê°œ API: í•„í„° ê²€ìƒ‰ ----------
    def search_with_filter(self, query: str, filter_dict: Dict[str, Any], k: Optional[int] = None):
        """ë©”íƒ€ë°ì´í„° í•„í„°ì™€ í•¨ê»˜ ê²€ìƒ‰ (ì˜ˆ: ì—°ë„/ì €ì/ì¹´í…Œê³ ë¦¬)."""
        k = k or self.k
        filtered = self.vectorstore.as_retriever(
            search_type="similarity",
            search_kwargs={"k": k, "filter": filter_dict},
        )
        return filtered.invoke(query)

    # ---------- ê³µê°œ API: ë©€í‹°ì¿¼ë¦¬ ê²€ìƒ‰ ----------
    def multi_query_search(self, query: str, k: Optional[int] = None) -> List[Document]:
        """
        LLMìœ¼ë¡œ ì¿¼ë¦¬ë¥¼ í™•ì¥í•˜ì—¬ ë³‘ë ¬ ê²€ìƒ‰ í›„ ì¤‘ë³µ ì œê±°.
        - API Key/LLM ë¬¸ì œë¡œ MultiQueryê°€ ë¹„í™œì„±í™”ëœ ê²½ìš° base retrieverë¡œ í´ë°±.
        """
        k = k or self.k
        if not self._multi_query_retriever:
            return self._retriever.invoke(query)


        docs = self._multi_query_retriever.invoke(query)
        docs = _dedup_docs(docs)
        return docs[:k]