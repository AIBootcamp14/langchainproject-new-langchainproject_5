from __future__ import annotations
import os
import re
import time
import json
import psycopg2
import psycopg2.extras
from typing import List, Tuple, Any, Optional

from langchain.tools import tool
from dotenv import load_dotenv

# LLMClient import ì¶”ê°€ (config ê¸°ë°˜)
from src.utils.config_loader import get_model_config
from src.llm.client import LLMClient
from src.prompts import get_tool_prompt

load_dotenv()
# ==============================================================================
# ğŸ“˜ ëª¨ë“ˆ ëª©ì  (Text-to-SQL for PostgreSQL)
# ------------------------------------------------------------------------------
# - ìì—°ì–´ ì§ˆë¬¸ â†’ ì•ˆì „í•œ SELECT/WITH ì¿¼ë¦¬ ìƒì„± â†’ ì‹¤í–‰ â†’ Markdown í‘œë¡œ ë°˜í™˜
# - ì ‘ê·¼ í—ˆìš© í…Œì´ë¸”/ì»¬ëŸ¼(í™”ì´íŠ¸ë¦¬ìŠ¤íŠ¸)ë§Œ ì‚¬ìš©í•˜ì—¬ ë³´ì•ˆÂ·ì•ˆì •ì„± ê°•í™”
# - ì§‘ê³„ê°€ ì•„ë‹Œ ê²°ê³¼ëŠ” ê¸°ë³¸ LIMIT 100 ë¶€ì—¬
# - ê¸ˆì§€ íŒ¨í„´(DDL/DML/ê¶Œí•œ ëª…ë ¹ ë“±) í•„í„°ë§ + ê°„ë‹¨í•œ EXPLAIN ì•ˆì „ ì ê²€
#
# ğŸ“Œ í™˜ê²½ ë³€ìˆ˜(í•„ìˆ˜/ì„ íƒ)
#   - POSTGRES_HOST/PORT/USER/PASSWORD/DB      : DB ì ‘ì† ì •ë³´
#   - SOLAR_API_KEY ë˜ëŠ” OPENAI_API_KEY       : LLM API Key (configì—ì„œ ì§€ì •ëœ providerì— ë”°ë¼)
#   âš ï¸ configs/model_config.yamlì˜ text2sql ì„¹ì…˜ì—ì„œ ëª¨ë¸ ì„¤ì •
#
# ğŸ” ì‚¬ìš© ì˜ˆì‹œ
#   >>> from text2sql import text2sql
#   >>> print(text2sql.run("2024ë…„ì— ë°œí‘œëœ ë…¼ë¬¸ ê°œìˆ˜ëŠ”?"))
#
# âš ï¸ ì£¼ì˜
#   - í˜„ì¬ëŠ” public.papers í…Œì´ë¸”ë§Œ í—ˆìš©(ALLOWED_TABLES/ALLOWED_COLUMNS)
#   - INSERT/UPDATE/DELETE/DDL ë“±ì€ ì² ì €íˆ ì°¨ë‹¨ë©ë‹ˆë‹¤.
# ==============================================================================
 


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# DB ì—°ê²° ìœ í‹¸
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def _get_conn():
    return psycopg2.connect(
        host=os.getenv("POSTGRES_HOST", "localhost"),
        port=int(os.getenv("POSTGRES_PORT", "5432")),
        user=os.getenv("POSTGRES_USER", "postgres"),
        password=os.getenv("POSTGRES_PASSWORD", "postgres"),
        dbname=os.getenv("POSTGRES_DB", "postgres"),
    )


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ìŠ¤í‚¤ë§ˆ ìŠ¤ëƒ…ìƒ·
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
ALLOWED_TABLES = {"papers"}  # í˜„ì¬ ë²„ì „ì€ papersë§Œ í—ˆìš©
ALLOWED_COLUMNS = {
    "paper_id", "title", "authors", "publish_date",
    "source", "url", "category", "citation_count",
    "abstract", "created_at", "updated_at",
}


def _fetch_schema_snapshot() -> str:
    """
    information_schemaì—ì„œ í—ˆìš© í…Œì´ë¸”/ì»¬ëŸ¼ë§Œ ìŠ¤ëƒ…ìƒ· í…ìŠ¤íŠ¸ ìƒì„±
    """
    q = """
    SELECT table_name, column_name, data_type
    FROM information_schema.columns
    WHERE table_schema='public'
      AND table_name = ANY(%s)
    ORDER BY table_name, ordinal_position;
    """
    with _get_conn() as conn, conn.cursor() as cur:
        cur.execute(q, (list(ALLOWED_TABLES),))
        rows = cur.fetchall()

    lines = []
    for t, c, dt in rows:
        if c in ALLOWED_COLUMNS:
            lines.append(f"- {t}.{c} :: {dt}")
    return "\n".join(lines)


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# í”„ë¡¬í”„íŠ¸ ì„¤ì •
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
_SYS_PROMPT = """You are a careful Text-to-SQL generator for PostgreSQL.

Rules:
- Output ONLY a single SQL query with no extra prose or comments.
- SELECT / WITH (CTE) only. No writes (INSERT/UPDATE/DELETE), no DDL (ALTER/DROP/CREATE), no GRANT/REVOKE.
- Use only the whitelisted table and columns below.
- Prefer COUNT/SUM/AVG/MAX/MIN for numeric answers.
- For year filters, use EXTRACT(YEAR FROM publish_date).
- For keyword search in text columns, use ILIKE with %...%.
- IMPORTANT: When combining AND/OR in WHERE clause, use parentheses to group OR conditions. Example: WHERE date >= '2022-01-01' AND (field1 ILIKE '%keyword%' OR field2 ILIKE '%keyword%')
- Add LIMIT 100 when returning rows (non-aggregate).
- Do NOT reference tables not listed below; do NOT call undefined functions.
- Use single semicolon at the end.

Whitelisted schema (public):
{schema}

Only these columns are guaranteed to exist:
papers(paper_id, title, authors, publish_date, source, url, category, citation_count, abstract, created_at, updated_at)
"""

# Few-shot: ì‹¤ì œ ìŠ¤í‚¤ë§ˆì— ë§ì¶° êµ¬ì„±
_FEW_SHOTS = [
    (
        "2024ë…„ì— ë°œí‘œëœ ë…¼ë¬¸ ê°œìˆ˜ëŠ”?",
        "SELECT COUNT(*) AS paper_count FROM papers WHERE EXTRACT(YEAR FROM publish_date)=2024;"
    ),
    (
        "ì¹´í…Œê³ ë¦¬ë³„ ë…¼ë¬¸ ìˆ˜ë¥¼ ë³´ì—¬ì¤˜",
        "SELECT category, COUNT(*) AS paper_count FROM papers GROUP BY category ORDER BY paper_count DESC LIMIT 100;"
    ),
    (
        "2021ë…„ ì´í›„ ë°œí‘œëœ ë…¼ë¬¸ë“¤ì˜ í‰ê·  ì¸ìš©ìˆ˜ëŠ”?",
        "SELECT AVG(citation_count) AS avg_citations FROM papers WHERE publish_date >= DATE '2021-01-01';"
    ),
    (
        "AI ê´€ë ¨ ë…¼ë¬¸ ì¤‘ ê°€ì¥ ì¸ìš©ì´ ë§ì€ ê±´?",
        "SELECT title, citation_count FROM papers WHERE category ILIKE '%AI%' ORDER BY citation_count DESC LIMIT 1;"
    ),
    (
        "ì €ìê°€ 3ëª… ì´ìƒì¸ ë…¼ë¬¸ì€ ëª‡ í¸ì´ì•¼?",
        "SELECT COUNT(*) AS paper_count FROM papers WHERE array_length(string_to_array(authors, ','), 1) >= 3;"
    ),
]


def _fewshot_block() -> str:
    parts = []
    for q, s in _FEW_SHOTS:
        parts.append(f"-- Q: {q}\n{s}")
    return "\n\n".join(parts)


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ìƒì„± SQL ì •ë¦¬/ê²€ì¦
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
_FORBIDDEN_PATTERNS = [
    r"\bdrop\b", r"\balter\b", r"\btruncate\b", r"\binsert\b",
    r"\bupdate\b", r"\bdelete\b", r"\bgrant\b", r"\brevoke\b",
    r"\bcopy\b", r"\bcreate\b", r";\s*--", r"/\*", r"\*/"
]
_READONLY_START = {"select", "with"}


def _extract_sql(text: str) -> str:
    """LLMì´ ì½”ë“œíœìŠ¤ ë“±ì„ í¬í•¨í•´ë„ SQLë§Œ ì¶”ì¶œ"""
    s = text.strip()
    # ```sql ... ```
    m = re.search(r"```sql(.*?)```", s, flags=re.I | re.S)
    if m:
        s = m.group(1).strip()
    # ``` ... ```
    m = re.search(r"```(.*?)```", s, flags=re.S)
    if m:
        s = m.group(1).strip()
    # ì²« ì¤„ì— ì£¼ì„/ë¬¸ì¥ ì œê±° ì‹œë„
    # ì—¬ëŸ¬ ì¤„ ì¤‘ SQLë¡œ ë³´ì´ëŠ” ì²« ì„¸ë¯¸ì½œë¡  ì „ê¹Œì§€
    if s.count(";") > 1:
        s = s.split(";")[0] + ";"
    return s

def _find_tables_outside_parens(sql_lower: str) -> set:
    """
    ê´„í˜¸ ë°–ì—ì„œë§Œ FROM/JOINì„ ì¸ì‹í•˜ì—¬ í…Œì´ë¸”ëª…ì„ ì¶”ì¶œí•©ë‹ˆë‹¤.
    ì˜ˆ: EXTRACT(YEAR FROM publish_date) ë‚´ë¶€ì˜ 'from'ì€ ë¬´ì‹œë©ë‹ˆë‹¤.
    """
    tokens = re.findall(r"[A-Za-z_][A-Za-z0-9_]*|[(),]", sql_lower)
    paren = 0
    tables = set()
    i = 0
    while i < len(tokens):
        tok = tokens[i]
        if tok == "(":
            paren += 1
        elif tok == ")":
            paren = max(0, paren - 1)
        else:
            if paren == 0 and tok in {"from", "join"}:
                # ë‹¤ìŒ í† í°ë“¤ì´ (ì˜µì…˜) schema.table í˜•íƒœì¼ ìˆ˜ ìˆìŒ
                j = i + 1
                # ê³µë°± í† í°ì€ ì •ê·œì‹ì—ì„œ ì´ë¯¸ ì œê±°ë¨
                if j < len(tokens):
                    # public.schema ê°™ì€ prefix ë¬´ì‹œ
                    tname = tokens[j]
                    # ì‰¼í‘œ/ê´„í˜¸/ì˜ˆì•½ì–´ëŠ” í…Œì´ë¸” ì•„ë‹˜
                    if re.match(r"[a-z_][a-z0-9_]*", tname):
                        tables.add(tname)
            # else: ê´„í˜¸ ì•ˆì˜ from/joinì€ ë¬´ì‹œ
        i += 1
    return tables

def _sanitize(sql: str) -> str:
    s = sql.strip()
    if not s.endswith(";"):
        s += ";"
    s = s.rstrip(";")  # ì¼ë‹¨ ë ì„¸ë¯¸ì½œë¡  ì œê±° í›„ ì ê²€ â†’ ë‹¤ì‹œ 1ê°œ ë¶™ì„
    low = s.lower()

    # ê¸ˆì§€ íŒ¨í„´
    for pat in _FORBIDDEN_PATTERNS:
        if re.search(pat, low):
            raise ValueError("ê¸ˆì§€ëœ SQL íŒ¨í„´ì´ ê°ì§€ë˜ì—ˆìŠµë‹ˆë‹¤.")

    # ì½ê¸° ì „ìš© ë™ì‚¬ë§Œ í—ˆìš©
    first = re.split(r"\s+", low, maxsplit=1)[0]
    if first not in _READONLY_START:
        raise ValueError("SELECT/WITH ì¿¼ë¦¬ë§Œ í—ˆìš©ë©ë‹ˆë‹¤.")

    # papers í…Œì´ë¸”ë§Œ í—ˆìš©
    # FROM/JOIN ê·¼ì²˜ì— ë“±ì¥í•˜ëŠ” í…Œì´ë¸” í† í° ê²€ì¦(ê°„ë‹¨ ë²„ì „)
    tbl_tokens = re.findall(r"\bfrom\s+([a-zA-Z0-9_\.]+)|\bjoin\s+([a-zA-Z0-9_\.]+)", low)
    flat_tbls = _find_tables_outside_parens(low)
    for t in flat_tbls:
        tname = t.split(".")[-1]
        if tname not in ALLOWED_TABLES:
            raise ValueError(f"í—ˆìš©ë˜ì§€ ì•Šì€ í…Œì´ë¸” ì°¸ì¡°: {tname}")

    # í—ˆìš© ì»¬ëŸ¼ íŒíŠ¸(ê°•ì œëŠ” ì•„ë‹˜): SELECT ëª©ë¡ì˜ í† í° ì¤‘ ëª…ë°±í•œ ì™¸ë¶€ ì‹ë³„ì ê²½ê³ 
    # (ì‹¤ì„œë¹„ìŠ¤ì—ì„œëŠ” ì‹¤ì œ íŒŒì„œ/ì¹´íƒˆë¡œê·¸ë¥¼ ê¶Œì¥)
    return s + ";"  # ë‹¨ì¼ ì„¸ë¯¸ì½œë¡  ê°•ì œ


def _ensure_limit(sql: str) -> str:
    """ì§‘ê³„ê°€ ì•„ë‹Œ ê²½ìš° LIMIT 100 ìë™ ë¶€ì—¬"""
    low = sql.lower()
    if any(k in low for k in ["count(", "avg(", "sum(", "max(", "min("]):
        return sql
    if " limit " in low:
        return sql
    # ORDER BYê°€ ìˆë“  ì—†ë“  ë§ˆì§€ë§‰ì— LIMIT ì¶”ê°€
    return sql.rstrip(";") + " LIMIT 100;"

def _explain_safe(sql: str) -> bool:
    """
    ê°„ë‹¨í•œ ì‹¤í–‰ê³„íš ì‚¬ì „ì ê²€: ë„ˆë¬´ í° Seq Scan ë“±ì„ ì™„í™”(í”„ë¡œë•ì…˜ì—ì„œëŠ” ì„ê³„ê°’/í†µê³„ ê¸°ë°˜ ê¶Œì¥)
    """
    try:
        with _get_conn() as conn, conn.cursor() as cur:
            cur.execute("EXPLAIN " + sql)
            plan_rows = cur.fetchall()
            plan_text = "\n".join(r[0] for r in plan_rows)
            # ë°ëª¨ìš©ìœ¼ë¡œ ë¬´ì¡°ê±´ í†µê³¼(ì›í•˜ë©´ ì—¬ê¸°ì„œ rows= ì¶”ì •ì¹˜ íŒŒì‹±í•´ ì„ê³„ì¹˜ ì°¨ë‹¨)
            return True
    except Exception:
        return False


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ì‹¤í–‰ & í¬ë§·
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def _run_query(sql: str) -> Tuple[List[str], List[Tuple[Any, ...]]]:
    with _get_conn() as conn, conn.cursor(cursor_factory=psycopg2.extras.DictCursor) as cur:
        cur.execute(sql)
        cols = [d.name for d in cur.description]
        rows = cur.fetchall()
        return cols, rows

def _to_markdown_table(cols: List[str], rows: List[Tuple[Any, ...]]) -> str:
    if not rows:
        return "_ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤._"
    header = " | ".join(cols)
    sep = " | ".join(["---"] * len(cols))
    body_lines = []
    for r in rows:
        body_lines.append(" | ".join("" if v is None else str(v) for v in r))
    return f"{header}\n{sep}\n" + "\n".join(body_lines)



# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ë¡œê¹…
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def _log_query(user_query: str,
               generated_sql: str,
               response_text: str,
               success: bool,
               response_time_ms: int,
               error_message: Optional[str] = None) -> None:
    """
    query_logs í…Œì´ë¸”ì— ê¸°ë¡ (ìŠ¤í‚¤ë§ˆ: log_id, user_query, difficulty_mode, tool_used, response,
                           response_time_ms, success, error_message, created_at)
    """
    try:
        with _get_conn() as conn, conn.cursor() as cur:
            cur.execute(
                """
                INSERT INTO query_logs (user_query, difficulty_mode, tool_used, response,
                                        response_time_ms, success, error_message)
                VALUES (%s, %s, %s, %s, %s, %s, %s);
                """,
                (
                    user_query,
                    None,  # difficulty_modeëŠ” í˜„ì¬ ë¯¸ì‚¬ìš©
                    "text2sql",
                    response_text,
                    response_time_ms,
                    success,
                    error_message,
                ),
            )
            conn.commit()
    except Exception:
        # ë¡œê¹… ì‹¤íŒ¨ëŠ” ë¬´ì‹œ(ì„œë¹„ìŠ¤ íë¦„ ë°©í•´ X)
        pass



# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ë©”ì¸ Tool
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
@tool("text2sql", return_direct=False)
def text2sql(user_question: str, difficulty: str = "easy") -> str:
    """
    ë…¼ë¬¸ í†µê³„ ì „ìš© Text-to-SQL ë„êµ¬ì…ë‹ˆë‹¤.
    - ìì—°ì–´ ì§ˆë¬¸ì„ ì•ˆì „í•œ SQLë¡œ ë³€í™˜í•˜ê³  ì‹¤í–‰í•©ë‹ˆë‹¤.
    - í˜„ì¬ëŠ” public.papers í…Œì´ë¸”ë§Œ ì ‘ê·¼í•©ë‹ˆë‹¤.
    - ë‚œì´ë„ì— ë”°ë¼ ë‹µë³€ ìŠ¤íƒ€ì¼ì´ ë‹¬ë¼ì§‘ë‹ˆë‹¤.

    Args:
        user_question: ì‚¬ìš©ìì˜ í†µê³„ ì§ˆë¬¸
        difficulty: ë‚œì´ë„ (elementary/beginner/intermediate/advanced ë˜ëŠ” easy/hard)

    ì‚¬ìš© ì˜ˆì‹œ)
      - "2024ë…„ì— ë°œí‘œëœ ë…¼ë¬¸ ê°œìˆ˜ëŠ”?"
      - "ì¹´í…Œê³ ë¦¬ë³„ ë…¼ë¬¸ ìˆ˜ë¥¼ ë³´ì—¬ì¤˜"
      - "AI ê´€ë ¨ ë…¼ë¬¸ ì¤‘ ê°€ì¥ ì¸ìš©ì´ ë§ì€ ê±´?"
    """
    t0 = time.time()

    # ==================== configì—ì„œ text2sql ëª¨ë¸ ì„¤ì • ì½ê¸° ==================== #
    try:
        model_config = get_model_config()
        text2sql_config = model_config.get("text2sql", {})
        provider = text2sql_config.get("provider", "solar")
        model = text2sql_config.get("model", "solar-pro2")
        temperature = text2sql_config.get("temperature", 0.0)
    except Exception:
        # config ë¡œë“œ ì‹¤íŒ¨ ì‹œ ê¸°ë³¸ê°’
        provider = "solar"
        model = "solar-pro2"
        temperature = 0.0

    # LLMClient ìƒì„± (config ê¸°ë°˜)
    llm_client = LLMClient(provider=provider, model=model, temperature=temperature)

    schema = _fetch_schema_snapshot()
    sys_prompt = _SYS_PROMPT.format(schema=schema)
    few_shot = _fewshot_block()
    user_block = f"-- Q: {user_question}\n-- Generate ONE SQL ONLY."

    # LLM í˜¸ì¶œ
    from langchain.schema import SystemMessage, HumanMessage
    raw = llm_client.llm.invoke(
        [
            SystemMessage(content=sys_prompt),
            HumanMessage(content=few_shot + "\n\n" + user_block),
        ]
    ).content

    # LLM ì‘ë‹µ ë¡œê¹… (ì„ íƒì )
    # tool_loggerê°€ í•„ìš”í•œ ê²½ìš° ì—¬ê¸°ì„œ Logger ì´ˆê¸°í™” ê°€ëŠ¥
    # from src.utils.logger import Logger
    # tool_logger = Logger("logs/text2sql.log")

    # SQL ì¶”ì¶œ/ê²€ì¦/ë³´ì •
    sql_generated = _extract_sql(raw)
    try:
        sql_sanitized = _sanitize(sql_generated)
        sql_ready = _ensure_limit(sql_sanitized)
        if not _explain_safe(sql_ready):
            raise ValueError("ì‹¤í–‰ ê³„íš ê²€ì¦ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
        cols, rows = _run_query(sql_ready)
        table_md = _to_markdown_table(cols, rows)

        # ==================== ë‚œì´ë„ë³„ í”„ë¡¬í”„íŠ¸ ë¡œë“œ ë° ìµœì¢… ë‹µë³€ ìƒì„± ==================== #
        try:
            # 1. text2sql í”„ë¡¬í”„íŠ¸ ë¡œë“œ
            system_prompt = get_tool_prompt("text2sql", difficulty)

            # 2. ë°ì´í„°ë² ì´ìŠ¤ ê²°ê³¼ í¬ë§·íŒ… (SQL + í…Œì´ë¸”)
            db_results = (
                f"**ìƒì„±ëœ SQL**:\n```sql\n{sql_ready}\n```\n\n"
                f"**ê²°ê³¼ í…Œì´ë¸”**:\n{table_md}"
            )

            # 3. user_prompt_template ë¡œë“œ
            from src.prompts.loader import load_tool_prompts, map_difficulty
            tool_prompts_data = load_tool_prompts()
            mapped_diff = map_difficulty(difficulty)
            complexity_level = "easy" if mapped_diff in ["elementary", "beginner"] else "hard"
            user_template = tool_prompts_data["text2sql_prompts"][complexity_level][mapped_diff]["user_prompt_template"]

            # 4. í…œí”Œë¦¿ì— ë°ì´í„° ì‚½ì…
            user_content = user_template.format(
                db_results=db_results,
                question=user_question
            )

            # 5. LLM í˜¸ì¶œí•˜ì—¬ ìµœì¢… ë‹µë³€ ìƒì„±
            final_answer_raw = llm_client.llm.invoke(
                [
                    SystemMessage(content=system_prompt),
                    HumanMessage(content=user_content),
                ]
            ).content

            # 6. ìµœì¢… ì‘ë‹µ êµ¬ì„± (SQL ì •ë³´ í¬í•¨)
            out = (
                f"**ì§ˆë¬¸**: {user_question}\n\n"
                f"**ìƒì„±ëœ SQL**:\n```sql\n{sql_ready}\n```\n\n"
                f"**ë¶„ì„ ê²°ê³¼**:\n\n{final_answer_raw}"
            )

        except Exception as prompt_error:
            # í”„ë¡¬í”„íŠ¸ ë¡œë“œ ì‹¤íŒ¨ ì‹œ ê¸°ë³¸ ì‘ë‹µ
            out = (
                f"**ì§ˆë¬¸**: {user_question}\n\n"
                f"**ìƒì„±ëœ SQL**:\n```sql\n{sql_ready}\n```\n"
                f"**ê²°ê³¼**:\n\n{table_md}"
            )

        elapsed = int((time.time() - t0) * 1000)

        # ë¡œê·¸ ì €ì¥(ì‘ë‹µ ì¼ë¶€ë§Œ ì €ì¥í•˜ì—¬ í¬ê¸° ì œí•œ)
        _log_query(
            user_query=user_question,
            generated_sql=sql_ready,
            response_text=out[:2000],
            success=True,
            response_time_ms=elapsed,
        )
        return out

    except Exception as e:
        elapsed = int((time.time() - t0) * 1000)
        err = f"{type(e).__name__}: {str(e)}"
        # ì—ëŸ¬ ë¡œê·¸
        _log_query(
            user_query=user_question,
            generated_sql=sql_generated,
            response_text=err,
            success=False,
            response_time_ms=elapsed,
            error_message=err,
        )
        return (
            f"**ì§ˆë¬¸**: {user_question}\n\n"
            f"**ìƒì„±ëœ SQL(ê²€ì¦ ì „)**:\n```sql\n{sql_generated}\n```\n"
            f"ìš”ì²­ì„ ì²˜ë¦¬í•˜ëŠ” ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤:\n```\n{err}\n```"
        )


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ë¡œì»¬ í…ŒìŠ¤íŠ¸ìš© ì§„ì…ì (ì„ íƒ)
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
if __name__ == "__main__":
    # ê°„ë‹¨ ìˆ˜ë™ í…ŒìŠ¤íŠ¸
    q = "AI ê´€ë ¨ ë…¼ë¬¸ ì¤‘ ê°€ì¥ ì¸ìš©ì´ ë§ì€ ê±´?"
    print(text2sql.run(q))

