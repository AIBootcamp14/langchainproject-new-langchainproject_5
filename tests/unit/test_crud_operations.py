# tests/unit/test_crud_operations.py

"""
RDBMS CRUD ì‘ì—… í…ŒìŠ¤íŠ¸

ë°ì´í„°ë² ì´ìŠ¤ì— ìƒ˜í”Œ ë…¼ë¬¸ ë°ì´í„°ë¥¼ ì‚½ì…í•˜ê³  ì¡°íšŒ/ìˆ˜ì •/ì‚­ì œ ì‘ì—…ì„ í…ŒìŠ¤íŠ¸í•©ë‹ˆë‹¤.
"""

# ------------------------- í”„ë¡œì íŠ¸ ëª¨ë“ˆ ------------------------- #
from src.database.db import execute_query


# ==================== CREATE (ì‚½ì…) ==================== #
def insert_paper(title, authors, publish_date, source, url, category, abstract):
    """
    papers í…Œì´ë¸”ì— ë…¼ë¬¸ ë°ì´í„° ì‚½ì…

    Args:
        title: ë…¼ë¬¸ ì œëª©
        authors: ì €ì ëª©ë¡
        publish_date: ë°œí‘œ ë‚ ì§œ (YYYY-MM-DD)
        source: ì¶œì²˜ (arXiv, IEEE ë“±)
        url: ë…¼ë¬¸ URL
        category: ì¹´í…Œê³ ë¦¬
        abstract: ì´ˆë¡

    Returns:
        ì‚½ì…ëœ paper_id
    """
    query = """
        INSERT INTO papers (title, authors, publish_date, source, url, category, abstract)
        VALUES (%s, %s, %s, %s, %s, %s, %s)
        ON CONFLICT (url) DO NOTHING
        RETURNING paper_id;
    """

    params = (title, authors, publish_date, source, url, category, abstract)
    result = execute_query(query, params, fetch=True)

    if result:
        paper_id = result[0][0]
        print(f"âœ… ë…¼ë¬¸ ì‚½ì… ì™„ë£Œ: paper_id = {paper_id}")
        return paper_id
    else:
        print("â„¹ï¸  ì´ë¯¸ ì¡´ì¬í•˜ëŠ” ë…¼ë¬¸ì…ë‹ˆë‹¤ (URL ì¤‘ë³µ)")
        return None


# ==================== READ (ì¡°íšŒ) ==================== #
def get_all_papers(limit=10):
    """
    ëª¨ë“  ë…¼ë¬¸ ì¡°íšŒ

    Args:
        limit: ì¡°íšŒí•  ìµœëŒ€ ê°œìˆ˜

    Returns:
        ë…¼ë¬¸ ë°ì´í„° ë¦¬ìŠ¤íŠ¸
    """
    query = """
        SELECT paper_id, title, authors, publish_date, source, category
        FROM papers
        ORDER BY created_at DESC
        LIMIT %s;
    """

    result = execute_query(query, (limit,), fetch=True)

    # ì¶œë ¥
    print(f"\nğŸ“š ì „ì²´ ë…¼ë¬¸ ëª©ë¡ (ìµœëŒ€ {limit}ê°œ):")
    print("=" * 80)
    for row in result:
        print(f"[{row[0]}] {row[1]} ({row[3]})")
        print(f"    ì €ì: {row[2][:50]}...")
        print(f"    ì¹´í…Œê³ ë¦¬: {row[5]}")
        print()

    return result


def search_papers_by_title(keyword):
    """
    ì œëª©ì— í‚¤ì›Œë“œê°€ í¬í•¨ëœ ë…¼ë¬¸ ê²€ìƒ‰

    Args:
        keyword: ê²€ìƒ‰ í‚¤ì›Œë“œ

    Returns:
        ê²€ìƒ‰ ê²°ê³¼ ë¦¬ìŠ¤íŠ¸
    """
    query = """
        SELECT paper_id, title, authors, publish_date
        FROM papers
        WHERE title ILIKE %s
        ORDER BY publish_date DESC;
    """

    # ILIKE: ëŒ€ì†Œë¬¸ì êµ¬ë¶„ ì—†ëŠ” ê²€ìƒ‰
    result = execute_query(query, (f"%{keyword}%",), fetch=True)

    # ì¶œë ¥
    print(f"\nğŸ” '{keyword}' ê²€ìƒ‰ ê²°ê³¼:")
    print("=" * 80)
    for row in result:
        print(f"[{row[0]}] {row[1]} ({row[3]})")

    return result


# ==================== UPDATE (ìˆ˜ì •) ==================== #
def update_citation_count(paper_id, citation_count):
    """
    ë…¼ë¬¸ ì¸ìš© ìˆ˜ ì—…ë°ì´íŠ¸

    Args:
        paper_id: ë…¼ë¬¸ ID
        citation_count: ìƒˆë¡œìš´ ì¸ìš© ìˆ˜
    """
    query = """
        UPDATE papers
        SET citation_count = %s, updated_at = CURRENT_TIMESTAMP
        WHERE paper_id = %s;
    """

    execute_query(query, (citation_count, paper_id))
    print(f"âœ… paper_id {paper_id}ì˜ ì¸ìš© ìˆ˜ë¥¼ {citation_count}ë¡œ ì—…ë°ì´íŠ¸ ì™„ë£Œ")


# ==================== ë©”ì¸ í…ŒìŠ¤íŠ¸ ==================== #
if __name__ == "__main__":
    print("=" * 80)
    print("PostgreSQL CRUD ì‘ì—… í…ŒìŠ¤íŠ¸ ì‹œì‘")
    print("=" * 80)

    # ---------------------- 1. CREATE: ìƒ˜í”Œ ë…¼ë¬¸ ì‚½ì… ---------------------- #
    print("\n[1] CREATE: ìƒ˜í”Œ ë…¼ë¬¸ ì‚½ì…")
    print("-" * 80)

    papers_data = [
        {
            "title": "Attention Is All You Need",
            "authors": "Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Lukasz Kaiser, Illia Polosukhin",
            "publish_date": "2017-06-12",
            "source": "arXiv",
            "url": "https://arxiv.org/abs/1706.03762",
            "category": "cs.CL",
            "abstract": "The dominant sequence transduction models are based on complex recurrent or convolutional neural networks that include an encoder and a decoder. The best performing models also connect the encoder and decoder through an attention mechanism. We propose a new simple network architecture, the Transformer, based solely on attention mechanisms, dispensing with recurrence and convolutions entirely."
        },
        {
            "title": "BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding",
            "authors": "Jacob Devlin, Ming-Wei Chang, Kenton Lee, Kristina Toutanova",
            "publish_date": "2018-10-11",
            "source": "arXiv",
            "url": "https://arxiv.org/abs/1810.04805",
            "category": "cs.CL",
            "abstract": "We introduce a new language representation model called BERT, which stands for Bidirectional Encoder Representations from Transformers. Unlike recent language representation models, BERT is designed to pre-train deep bidirectional representations from unlabeled text by jointly conditioning on both left and right context in all layers."
        },
        {
            "title": "Language Models are Few-Shot Learners",
            "authors": "Tom B. Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, et al.",
            "publish_date": "2020-05-28",
            "source": "arXiv",
            "url": "https://arxiv.org/abs/2005.14165",
            "category": "cs.CL",
            "abstract": "Recent work has demonstrated substantial gains on many NLP tasks and benchmarks by pre-training on a large corpus of text followed by fine-tuning on a specific task. While typically task-agnostic in architecture, this method still requires task-specific fine-tuning datasets of thousands or tens of thousands of examples."
        }
    ]

    paper_ids = []
    for paper in papers_data:
        paper_id = insert_paper(
            title=paper['title'],
            authors=paper['authors'],
            publish_date=paper['publish_date'],
            source=paper['source'],
            url=paper['url'],
            category=paper['category'],
            abstract=paper['abstract']
        )
        if paper_id:
            paper_ids.append(paper_id)

    print(f"\nì´ {len(paper_ids)}ê°œ ë…¼ë¬¸ ì‚½ì… ì™„ë£Œ")

    # ---------------------- 2. READ: ë…¼ë¬¸ ì¡°íšŒ ---------------------- #
    print("\n[2] READ: ë…¼ë¬¸ ì¡°íšŒ")
    print("-" * 80)
    get_all_papers(limit=5)

    # ---------------------- 3. READ: í‚¤ì›Œë“œ ê²€ìƒ‰ ---------------------- #
    print("\n[3] READ: í‚¤ì›Œë“œ ê²€ìƒ‰")
    print("-" * 80)
    search_papers_by_title("Transformer")

    # ---------------------- 4. UPDATE: ì¸ìš© ìˆ˜ ì—…ë°ì´íŠ¸ ---------------------- #
    if paper_ids:
        print("\n[4] UPDATE: ì¸ìš© ìˆ˜ ì—…ë°ì´íŠ¸")
        print("-" * 80)
        update_citation_count(paper_ids[0], 50000)

    print("\n" + "=" * 80)
    print("âœ… CRUD ì‘ì—… í…ŒìŠ¤íŠ¸ ì™„ë£Œ")
    print("=" * 80)
