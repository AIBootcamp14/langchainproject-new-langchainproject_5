# 도구별 역할 배분 계획

## 문서 정보
- **작성일**: 2025-10-30
- **프로젝트**: 논문 리뷰 챗봇 (AI Agent + RAG)
- **팀명**: 연결의 민족
- **목적**: 6가지 도구별 기능 분석 및 팀원 역할 배분

---

## 전체 도구 개요

시스템 아키텍처(자료조사_03_시스템_아키텍처.md)의 **2.1 High-Level Architecture**에 따르면, AI Agent는 사용자 질문을 분석하여 다음 6가지 도구 중 하나를 선택하여 실행합니다.

**모든 도구는 Langchain 기반으로 구현됩니다.**

---

## 도구 1: RAG 검색 도구 (Paper Search Tool)

### 도구 설명
로컬 Vector DB와 PostgreSQL에 저장된 논문 데이터베이스에서 관련 논문을 검색하는 도구

### Langchain 구현 여부
✅ **Langchain 사용**
- `@tool` 데코레이터로 도구 정의
- `PGVector.similarity_search()` 또는 `VectorStoreRetriever` 사용
- `MultiQueryRetriever`, `ContextualCompressionRetriever` 등 고급 검색 기법 활용

### 구현해야 할 기능

#### 1. Vector DB 유사도 검색
```python
from langchain.tools import tool
from langchain_postgres.vectorstores import PGVector
from langchain.retrievers import MultiQueryRetriever

@tool
def search_paper_database(query: str, year_filter: int = None) -> str:
    """논문 데이터베이스에서 관련 논문을 검색합니다."""
    # Vector DB에서 유사도 검색 (Top-K)
    docs = vectorstore.similarity_search(query, k=5)

    # PostgreSQL에서 메타데이터 조회
    # 검색 결과 포맷팅
    return formatted_results
```

#### 2. 메타데이터 필터링
- 년도별 필터링 (`year >= 2020`)
- 저자별 필터링
- 카테고리별 필터링 (NLP, CV, ML 등)

#### 3. 검색 결과 재순위화 (선택)
- Cohere Rerank API 사용
- `ContextualCompressionRetriever` 활용

#### 4. 결과 포맷팅
- 논문 제목, 저자, 년도, 초록, 관련도 점수 반환
- LLM에 전달할 수 있는 프롬프트 형식으로 구성

### 사용하는 DB

#### Vector DB (pgvector)
- **컬렉션**: `paper_chunks`
- **저장 데이터**: 논문 본문을 청크로 나눈 임베딩 벡터
- **메타데이터**: paper_id, section, page_num, title, authors, year
- **검색 방식**: Cosine Similarity, MMR (Maximal Marginal Relevance)

#### PostgreSQL
- **테이블**: `papers`
  ```sql
  CREATE TABLE papers (
      paper_id SERIAL PRIMARY KEY,
      title VARCHAR(500) NOT NULL,
      authors TEXT,
      publish_date DATE,
      source VARCHAR(100),
      url TEXT UNIQUE,
      category VARCHAR(100),
      citation_count INT DEFAULT 0,
      abstract TEXT,
      created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
  );
  ```
- **역할**: 논문 메타데이터 저장 및 조회
- **인덱스**: title, category, publish_date

### 담당 팀원 추천
**신준엽** (전체 기간 참여)
- RAG 시스템 전문 담당
- Langchain VectorStoreRetriever 구현
- MultiQueryRetriever, ContextualCompressionRetriever 구현

---

## 도구 2: 웹 검색 도구 (Web Search Tool)

### 도구 설명
최신 논문 정보를 웹에서 실시간으로 검색하는 도구 (로컬 DB에 없는 최신 논문 대응)

### Langchain 구현 여부
✅ **Langchain 사용**
- Langchain 제공 `TavilySearchResults` 도구 직접 사용
- `@tool` 데코레이터로 커스텀 래퍼 구현

### 구현해야 할 기능

#### 1. Tavily Search API 연동
```python
from langchain_community.tools.tavily_search import TavilySearchResults

# Langchain 기본 도구 사용
web_search_tool = TavilySearchResults(
    max_results=5,
    search_depth="advanced",
    include_answer=True
)
```

#### 2. 커스텀 웹 검색 래퍼 (선택)
```python
from langchain.tools import tool

@tool
def search_latest_papers(query: str) -> str:
    """최신 AI/ML 논문을 웹에서 검색합니다."""
    # Tavily API 호출
    results = tavily_search.invoke({
        "query": f"{query} AI ML paper 2024 2025"
    })

    # 결과 정리 및 포맷팅
    return formatted_results
```

#### 3. arXiv API 검색 (선택)
- arXiv 최신 논문 직접 검색
- `ArxivLoader` 사용

#### 4. 검색 결과 요약
- LLM을 사용해 검색 결과를 간결하게 요약
- 논문 제목, 저자, 주요 내용 추출

### 사용하는 DB
**DB 사용 없음** (외부 API 호출)

### 담당 팀원 추천
**임예슬** (전체 기간 참여)
- Streamlit UI 및 웹 검색 도구 담당
- Langchain `TavilySearchResults` 연동
- 커스텀 웹 검색 래퍼 구현

---

## 도구 3: 용어집 도구 (Glossary Search Tool)

### 도구 설명
논문에 자주 등장하는 전문 용어(Attention, Fine-tuning, BLEU Score 등)를 검색하여 난이도별 설명을 제공하는 도구

### Langchain 구현 여부
✅ **Langchain 사용**
- `@tool` 데코레이터로 도구 정의
- 용어집 전용 Vector DB 검색
- 난이도별 설명 반환 (Easy/Hard)

### 구현해야 할 기능

#### 1. 용어집 검색
```python
from langchain.tools import tool

@tool
def search_glossary(term: str, difficulty: str = "easy") -> str:
    """논문 용어집에서 전문 용어를 검색하여 설명합니다."""
    # 1. PostgreSQL glossary 테이블에서 직접 검색
    result = db.execute(
        "SELECT term, easy_explanation, hard_explanation FROM glossary WHERE term ILIKE %s",
        (f"%{term}%",)
    ).fetchone()

    if result:
        explanation = result['easy_explanation'] if difficulty == "easy" else result['hard_explanation']
        return f"**{result['term']}**: {explanation}"

    # 2. 용어집에 없으면 Vector DB에서 검색
    glossary_docs = glossary_vectorstore.similarity_search(term, k=2)
    return glossary_docs
```

#### 2. 하이브리드 검색
- PostgreSQL 직접 검색 (빠름)
- Vector DB 유사도 검색 (유연함)
- 논문 본문에서 용어 컨텍스트 추출

#### 3. 난이도별 설명 생성
- **Easy 모드**: 쉬운 용어, 실생활 비유 사용
- **Hard 모드**: 기술적 세부사항, 수식 포함

#### 4. 질문 분석 시 용어 자동 추출 및 컨텍스트 추가
```python
def extract_and_add_glossary_context(user_query):
    """사용자 질문에서 전문 용어를 추출하여 프롬프트에 추가"""
    # 용어집 DB에서 용어 검색
    cursor.execute("""
        SELECT term, definition, easy_explanation
        FROM glossary
        WHERE %s ILIKE '%' || term || '%'
    """, (user_query,))

    terms_found = cursor.fetchall()

    if terms_found:
        glossary_context = "\n\n[용어 정의]\n"
        for term, definition, easy_exp in terms_found:
            glossary_context += f"- **{term}**: {easy_exp}\n"

        return glossary_context
    return ""
```

### 사용하는 DB

#### PostgreSQL
- **테이블**: `glossary`
  ```sql
  CREATE TABLE glossary (
      term_id SERIAL PRIMARY KEY,
      term VARCHAR(200) NOT NULL UNIQUE,
      definition TEXT NOT NULL,
      easy_explanation TEXT,
      hard_explanation TEXT,
      category VARCHAR(100),  -- ML, NLP, CV, RL 등
      difficulty_level VARCHAR(20),  -- beginner, intermediate, advanced
      related_terms TEXT[],
      examples TEXT,
      created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
  );

  -- 인덱스
  CREATE INDEX idx_glossary_term ON glossary(term);
  ```
- **역할**: 용어 정의 및 난이도별 설명 저장

#### Vector DB (pgvector)
- **컬렉션**: `glossary_embeddings`
- **저장 데이터**: 용어 + 정의를 임베딩한 벡터
- **메타데이터**: term, category, difficulty_level
- **검색 방식**: 유사도 검색 (사용자가 정확한 용어를 모를 때)

### 담당 팀원 추천
**신준엽** (전체 기간 참여)
- RAG 시스템 및 용어집 통합 담당
- Langchain `@tool` 데코레이터로 구현
- 용어집 전용 VectorStore 검색

---

## 도구 4: 논문 요약 도구 (Paper Summarization Tool)

### 도구 설명
특정 논문의 전체 내용을 난이도별(Easy/Hard)로 요약하는 도구

### Langchain 구현 여부
✅ **Langchain 사용**
- `@tool` 데코레이터로 도구 정의
- `load_summarize_chain` 사용 (stuff, map_reduce, refine)
- 난이도별 프롬프트 적용

### 구현해야 할 기능

#### 1. 논문 검색 및 전체 내용 조회
```python
from langchain.tools import tool
from langchain.chains.summarize import load_summarize_chain

@tool
def summarize_paper(paper_title: str, difficulty: str = "easy") -> str:
    """특정 논문을 요약합니다. 난이도에 따라 초심자용/전문가용 요약을 제공합니다."""
    # 1. PostgreSQL에서 논문 메타데이터 조회
    paper_meta = db.execute(
        "SELECT * FROM papers WHERE title ILIKE %s",
        (f"%{paper_title}%",)
    ).fetchone()

    # 2. Vector DB에서 논문 전체 내용 조회 (여러 청크)
    paper_chunks = vectorstore.similarity_search(
        paper_title,
        k=10,
        filter={"paper_id": paper_meta["paper_id"]}
    )

    # 3. Langchain load_summarize_chain 사용
    if difficulty == "easy":
        summary = easy_summarize_chain.run(paper_chunks)
    else:
        summary = hard_summarize_chain.run(paper_chunks)

    return summary
```

#### 2. Langchain Summarization Chain 구현
```python
from langchain.chains.summarize import load_summarize_chain
from langchain.prompts import PromptTemplate

# Easy 모드 요약 체인
easy_prompt = PromptTemplate(
    template="""
    다음 논문을 초심자도 이해할 수 있도록 쉽게 요약해주세요:
    - 전문 용어는 풀어서 설명
    - 핵심 아이디어 3가지
    - 실생활 비유 포함

    논문 내용: {text}

    요약:
    """,
    input_variables=["text"]
)

easy_summarize_chain = load_summarize_chain(
    llm=llm,
    chain_type="stuff",  # or "map_reduce", "refine"
    prompt=easy_prompt
)

# Hard 모드 요약 체인
hard_prompt = PromptTemplate(
    template="""
    다음 논문을 전문가 수준으로 요약해주세요:
    - 기술적 세부사항 포함
    - 수식 및 알고리즘 설명
    - 관련 연구와의 비교

    논문 내용: {text}

    요약:
    """,
    input_variables=["text"]
)

hard_summarize_chain = load_summarize_chain(
    llm=llm,
    chain_type="map_reduce",  # 긴 논문에 적합
    prompt=hard_prompt
)
```

#### 3. 요약 방식 선택
- **stuff**: 짧은 논문, 모든 청크를 한 번에 LLM에 전달
- **map_reduce**: 긴 논문, 각 청크를 요약 후 최종 통합
- **refine**: 순차적 요약, 이전 요약을 다음 청크에 반영

#### 4. 섹션별 요약 (선택)
- Abstract, Introduction, Method, Experiments, Conclusion 별 요약

### 사용하는 DB

#### Vector DB (pgvector)
- **컬렉션**: `paper_chunks`
- **역할**: 논문 전체 내용을 청크로 나눠 저장
- **메타데이터 필터**: paper_id로 특정 논문의 모든 청크 조회

#### PostgreSQL
- **테이블**: `papers`
- **역할**: 논문 메타데이터 조회 (제목으로 paper_id 찾기)

### 담당 팀원 추천
**최현화** (팀장, 전체 기간 참여)
- 논문 요약 도구 담당
- Langchain `load_summarize_chain` 구현 (stuff, map_reduce, refine)
- 난이도별 프롬프트 설계

---

## 도구 5: 파일 저장 도구 (Save to File Tool)

### 도구 설명
대화 내용, 논문 요약, 참고 자료를 파일로 저장하는 도구 (필수 기능)

### Langchain 구현 여부
✅ **Langchain 사용**
- `@tool` 데코레이터로 도구 정의
- 파일 시스템 직접 접근

### 구현해야 할 기능

#### 1. 텍스트 파일 저장
```python
from langchain.tools import tool
import os
from datetime import datetime

@tool
def save_to_file(content: str, filename: str = None) -> str:
    """내용을 텍스트 파일로 저장합니다."""
    if filename is None:
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        filename = f"paper_review_{timestamp}.txt"

    # data/outputs 폴더에 저장
    output_dir = "data/outputs"
    os.makedirs(output_dir, exist_ok=True)

    filepath = os.path.join(output_dir, filename)

    with open(filepath, "w", encoding="utf-8") as f:
        f.write(content)

    return f"파일이 저장되었습니다: {filepath}"
```

#### 2. Markdown 형식 저장
- 대화 내용을 Markdown 형식으로 포맷팅
- 논문 인용 포함 (제목, 저자, 년도)

#### 3. PDF 형식 저장 (선택)
- `reportlab` 라이브러리 사용
- 요약 내용을 PDF로 생성

#### 4. Streamlit 다운로드 버튼 연동
```python
import streamlit as st

# UI에서 다운로드 버튼 제공
if st.button("대화 내용 저장"):
    content = "\n".join([msg["content"] for msg in st.session_state.messages])
    filepath = save_to_file(content)
    st.success(f"저장 완료: {filepath}")

    # 다운로드 버튼
    with open(filepath, "r") as f:
        st.download_button("파일 다운로드", f, file_name=os.path.basename(filepath))
```

### 사용하는 DB
**DB 사용 없음** (파일 시스템 직접 접근)

### 담당 팀원 추천
**임예슬** (전체 기간 참여)
- Streamlit UI 및 파일 저장 도구 담당
- Langchain `@tool` 데코레이터로 구현
- UI에서 다운로드 버튼 연동

---

## 도구 6: 일반 답변 도구 (General Answer Tool)

### 도구 설명
간단한 인사, 일반 상식 질문에 LLM의 자체 지식을 활용하여 직접 답변하는 도구 (도구 호출 없이 바로 답변)

### Langchain 구현 여부
✅ **Langchain 사용**
- LLM 직접 호출 (`ChatOpenAI`)
- 별도 도구 정의 없이 LangGraph에서 바로 답변 노드로 처리

### 구현해야 할 기능

#### 1. LLM 직접 호출
```python
from langchain_openai import ChatOpenAI

def general_answer_node(state: AgentState):
    """일반 질문에 LLM이 직접 답변"""
    question = state["question"]

    # LLM 호출
    response = llm.invoke([
        SystemMessage(content="당신은 친절한 AI 어시스턴트입니다."),
        HumanMessage(content=question)
    ])

    state["final_answer"] = response.content
    return state
```

#### 2. 라우터 노드에서 일반 답변 판단
- 인사말 ("안녕하세요", "반가워요")
- 일반 상식 질문 (논문과 무관한 질문)
- 도구 호출이 불필요한 질문

#### 3. 난이도별 프롬프트 적용
- Easy 모드: 쉬운 언어 사용
- Hard 모드: 전문적인 언어 사용

### 사용하는 DB
**DB 사용 없음** (LLM 자체 지식 활용)

### 담당 팀원 추천
**최현화** (팀장, 전체 기간 참여)
- AI Agent 그래프 및 LLM 클라이언트 담당
- LangGraph에서 일반 답변 노드 구현
- 라우터 노드에서 일반 답변 분기 처리

---

## 팀원별 최종 역할 배분 요약

### 최현화 (팀장)
- **담당 도구**: 도구 6 (일반 답변), 도구 4 (논문 요약)
- **핵심 역할**: AI Agent LangGraph 구성, LLM 클라이언트, 대화 메모리
- **Langchain 구현**:
  - LangGraph StateGraph 설계 및 라우터 노드
  - ChatOpenAI 래퍼 및 스트리밍
  - ConversationBufferMemory 구현
  - load_summarize_chain (stuff, map_reduce, refine)

### 박재홍 (10/31까지)
- **담당 역할**: 데이터 수집 및 DB 적재 (도구 구현 전 인프라 준비)
- **핵심 작업**:
  - arXiv API로 논문 수집
  - Langchain Document Loader (PyPDFLoader)
  - Langchain Text Splitter (RecursiveCharacterTextSplitter)
  - OpenAI Embeddings 생성
  - pgvector 적재
  - PostgreSQL 스키마 생성 및 메타데이터 저장

### 신준엽
- **담당 도구**: 도구 1 (RAG 검색), 도구 3 (용어집)
- **핵심 역할**: RAG 시스템 전체, 검색 최적화
- **Langchain 구현**:
  - PGVector VectorStore 연동
  - VectorStoreRetriever (similarity, mmr)
  - MultiQueryRetriever (쿼리 확장)
  - ContextualCompressionRetriever (문맥 압축)
  - @tool 데코레이터로 search_paper_database 구현
  - @tool 데코레이터로 search_glossary 구현
  - 용어집 전용 VectorStore 관리

### 임예슬
- **담당 도구**: 도구 2 (웹 검색), 도구 5 (파일 저장)
- **핵심 역할**: Streamlit UI, 프롬프트 템플릿, 도구 통합
- **Langchain 구현**:
  - StreamlitCallbackHandler 구현
  - LangGraph Agent 스트리밍 연동 (astream_events)
  - PromptTemplate, ChatPromptTemplate (Easy/Hard 모드)
  - TavilySearchResults 도구 연동
  - @tool 데코레이터로 search_latest_papers 구현
  - @tool 데코레이터로 save_to_file 구현
  - Streamlit 다운로드 버튼 연동

---

## Langchain 기능 사용 현황

### 모든 도구가 Langchain을 사용하는가?
**✅ 네, 모든 도구가 Langchain 기능을 사용합니다.**

| 도구 번호 | 도구 이름 | Langchain 주요 기능 |
|----------|----------|-------------------|
| 도구 1 | RAG 검색 도구 | `@tool`, `PGVector`, `VectorStoreRetriever`, `MultiQueryRetriever`, `ContextualCompressionRetriever` |
| 도구 2 | 웹 검색 도구 | `@tool`, `TavilySearchResults`, `ArxivLoader` |
| 도구 3 | 용어집 도구 | `@tool`, `PGVector`, `VectorStoreRetriever` |
| 도구 4 | 논문 요약 도구 | `@tool`, `load_summarize_chain`, `PromptTemplate` |
| 도구 5 | 파일 저장 도구 | `@tool` |
| 도구 6 | 일반 답변 도구 | `ChatOpenAI`, `SystemMessage`, `HumanMessage` |

### 공통 Langchain 구성 요소
- **LangGraph**: StateGraph, 노드, 엣지, 조건부 라우팅
- **LLM**: ChatOpenAI, 스트리밍, 콜백
- **Memory**: ConversationBufferMemory, ChatMessageHistory
- **Prompts**: PromptTemplate, ChatPromptTemplate, SystemMessage, HumanMessage
- **Tools**: @tool 데코레이터, StructuredTool
- **Retrieval**: VectorStoreRetriever, MultiQueryRetriever, ContextualCompressionRetriever
- **Embeddings**: OpenAIEmbeddings
- **Vector Stores**: PGVector
- **Document Loaders**: PyPDFLoader, ArxivLoader
- **Text Splitters**: RecursiveCharacterTextSplitter
- **Chains**: load_summarize_chain

---

## DB 사용 현황 요약

### pgvector (Vector DB)
| 컬렉션 이름 | 저장 데이터 | 사용 도구 |
|------------|-----------|----------|
| `paper_chunks` | 논문 본문 청크 임베딩 | 도구 1 (RAG 검색), 도구 4 (논문 요약) |
| `paper_abstracts` | 논문 초록 임베딩 | 도구 1 (RAG 검색) |
| `glossary_embeddings` | 용어집 임베딩 | 도구 3 (용어집) |

### PostgreSQL (관계형 DB)
| 테이블 이름 | 저장 데이터 | 사용 도구 |
|-----------|-----------|----------|
| `papers` | 논문 메타데이터 (제목, 저자, 년도, URL, 초록 등) | 도구 1 (RAG 검색), 도구 4 (논문 요약) |
| `glossary` | 용어집 (용어, 정의, Easy/Hard 설명) | 도구 3 (용어집) |
| `query_logs` | 사용자 질의 로그 (선택) | 평가 시스템 |

### DB를 사용하지 않는 도구
- **도구 2** (웹 검색): 외부 API 호출 (Tavily, arXiv)
- **도구 5** (파일 저장): 파일 시스템 직접 접근
- **도구 6** (일반 답변): LLM 자체 지식 활용

---

## 개발 우선순위

### Phase 1 (10/30~10/31): 데이터 인프라 구축
**담당: 박재홍**
1. PostgreSQL 스키마 생성 (papers, glossary)
2. pgvector 컬렉션 생성 (paper_chunks, glossary_embeddings)
3. arXiv API로 논문 50-100편 수집
4. Langchain Document Loader + Text Splitter로 전처리
5. OpenAI Embeddings 생성 및 Vector DB 저장

### Phase 2 (10/31~11/03): 핵심 도구 구현
**담당: 전체 팀원**
1. **최현화**: LangGraph Agent 그래프 + 도구 6 (일반 답변)
2. **신준엽**: 도구 1 (RAG 검색) + 도구 3 (용어집)
3. **임예슬**: 도구 2 (웹 검색) + 도구 5 (파일 저장)

### Phase 3 (11/02~11/03): 고급 기능 구현
**담당: 최현화**
1. 도구 4 (논문 요약) - load_summarize_chain

### Phase 4 (11/04~11/05): 통합 및 테스트
**담당: 전체 팀원**
1. main.py에서 모든 도구 통합
2. Streamlit UI 연동
3. 10개 시나리오 테스트

---

## 참고 자료

### Langchain 공식 문서
- Tools: https://docs.langchain.com/oss/python/langchain/tools#tools
- Agents: https://docs.langchain.com/oss/python/langchain/agents
- LangGraph: https://langchain-ai.github.io/langgraph/
- Retrieval: https://python.langchain.com/docs/tutorials/rag/
- Vector Stores: https://python.langchain.com/docs/integrations/vectorstores/
- Summarization: https://python.langchain.com/docs/use_cases/summarization/

### 프로젝트 관련 문서
- 자료조사_03_시스템_아키텍처.md
- 자료조사_04_RAG_시스템.md
- 자료조사_05_AI_Agent_도구.md
- 자료조사_06_역할분배_일정.md
