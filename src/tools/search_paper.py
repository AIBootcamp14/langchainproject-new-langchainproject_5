# ==========================================
# ğŸ“˜ RAG ë…¼ë¬¸ ê²€ìƒ‰ ë„êµ¬ ëª¨ë“ˆ + Agent ë…¸ë“œ í†µí•©
# ------------------------------------------
# - @tool: search_paper_database
# - Agent ë…¸ë“œ: search_paper_node
# - ê²€ìƒ‰ ëª¨ë“œ ì„ íƒ (similarity/MMR), MultiQuery ì˜µì…˜
# - ë©”íƒ€ë°ì´í„° í•„í„°(year/author/category)
# - PostgreSQL ë©”íƒ€ ì¡°íšŒ â†’ ê²°ê³¼ í•©ì„± â†’ Markdown ë°˜í™˜
# ==========================================

import os
from typing import Any, Dict, List, Optional, Tuple

import psycopg2
from psycopg2.extras import RealDictCursor
from langchain_core.tools import tool
from langchain_core.documents import Document
from langchain.schema import SystemMessage, HumanMessage

from src.rag.retriever import RAGRetriever
from src.prompts import get_tool_prompt
from src.llm.client import LLMClient


# ==================== ë‚´ë¶€ ìœ í‹¸: í™˜ê²½/DB ==================== #

def _env(primary: str, alt: str, default: Optional[str] = None) -> Optional[str]:
    """í™˜ê²½ ë³€ìˆ˜ ì¡°íšŒ (ìš°ì„ ìˆœìœ„: primary > alt > default)"""
    return os.getenv(primary) or os.getenv(alt) or default


def _pg_conn_str() -> str:
    """PostgreSQL ì—°ê²° ë¬¸ìì—´ ìƒì„±"""
    user = _env("POSTGRES_USER", "PGUSER", "postgres")
    password = _env("POSTGRES_PASSWORD", "PGPASSWORD", "postgres")
    host = _env("POSTGRES_HOST", "PGHOST", "localhost")
    port = _env("POSTGRES_PORT", "PGPORT", "5432")
    db = _env("POSTGRES_DB", "PGDATABASE", "papers")
    return f"postgresql://{user}:{password}@{host}:{port}/{db}"


def _fetch_paper_meta(paper_ids: List[int]) -> Dict[int, Dict[str, Any]]:
    """
    papers í…Œì´ë¸”ì—ì„œ ID ëª©ë¡ì— í•´ë‹¹í•˜ëŠ” ë©”íƒ€ë°ì´í„°ë¥¼ ì¼ê´„ ì¡°íšŒ.

    Args:
        paper_ids: ë…¼ë¬¸ ID ë¦¬ìŠ¤íŠ¸

    Returns:
        Dict[int, Dict[str, Any]]: {paper_id: {title, authors, ...}}
    """
    if not paper_ids:
        return {}

    conn = psycopg2.connect(_pg_conn_str())
    try:
        with conn.cursor(cursor_factory=RealDictCursor) as cur:
            cur.execute(
                """
                SELECT paper_id, title, authors, publish_date, url, category, citation_count
                FROM papers
                WHERE paper_id = ANY(%s)
                """,
                (paper_ids,),
            )
            rows = cur.fetchall()
            out: Dict[int, Dict[str, Any]] = {}
            for row in rows:
                out[row["paper_id"]] = dict(row)
            return out
    finally:
        conn.close()


def _format_markdown(results: List[Dict[str, Any]]) -> str:
    """
    ê²€ìƒ‰ ê²°ê³¼ë¥¼ Markdown ë¬¸ìì—´ë¡œ ë³€í™˜.

    Args:
        results: ê²€ìƒ‰ ê²°ê³¼ ë¦¬ìŠ¤íŠ¸

    Returns:
        str: Markdown í˜•ì‹ì˜ ë¬¸ìì—´
    """
    if not results:
        return "ê´€ë ¨ ë…¼ë¬¸ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."

    lines: List[str] = ["## ê²€ìƒ‰ëœ ë…¼ë¬¸\n"]
    for i, r in enumerate(results, 1):
        score_str = f"{r['score']:.4f}" if r.get("score") is not None else "N/A"

        lines.append(f"### {i}. {r.get('title','(Untitled)')}")
        lines.append(f"- **ì €ì**: {r.get('authors','')}")
        lines.append(f"- **ì¶œíŒì¼**: {r.get('publish_date','')}")
        lines.append(f"- **ì¹´í…Œê³ ë¦¬**: {r.get('category','')}")
        lines.append(f"- **ì¸ìš©ìˆ˜**: {r.get('citation_count','')}")
        lines.append(f"- **URL**: {r.get('url','')}")
        lines.append(f"- **ì„¹ì…˜**: {r.get('section','ë³¸ë¬¸')}")
        lines.append(f"- **ìœ ì‚¬ë„ ì ìˆ˜(ë‚®ì„ìˆ˜ë¡ ìœ ì‚¬)**: {score_str}\n")

        preview = (r.get("content") or "")[:600]
        if preview:
            lines.append(preview + ("..." if len(r.get("content","")) > 600 else ""))
        lines.append("\n---\n")

    return "\n".join(lines)


def _build_filter(year_gte: Optional[int], author: Optional[str], category: Optional[str]) -> Dict[str, Any]:
    """
    VectorStore ë©”íƒ€ë°ì´í„° í•„í„° êµ¬ì„±.

    Args:
        year_gte: ì—°ë„ ì´ìƒ í•„í„°
        author: ì €ì ë¶€ë¶„ì¼ì¹˜ í•„í„°
        category: ì¹´í…Œê³ ë¦¬ í•„í„°

    Returns:
        Dict[str, Any]: í•„í„° ë”•ì…”ë„ˆë¦¬
    """
    f: Dict[str, Any] = {}
    if year_gte is not None:
        f["year"] = {"$gte": int(year_gte)}
    if author:
        f["authors"] = {"$ilike": f"%{author}%"}
    if category:
        f["category"] = category
    return f


# ==================== @tool: ë…¼ë¬¸ ê²€ìƒ‰ ==================== #

@tool
def search_paper_database(
    query: str,
    year_gte: Optional[int] = None,
    author: Optional[str] = None,
    category: Optional[str] = None,
    top_k: int = 5,
    with_scores: bool = True,
    use_multi_query: bool = True,
    search_mode: str = "mmr",  # "similarity" | "mmr"
) -> str:
    """
    ë…¼ë¬¸ VectorDB + PostgreSQL ë©”íƒ€ë°ì´í„°ë¥¼ í•¨ê»˜ ì¡°íšŒí•˜ì—¬ ê²°ê³¼ë¥¼ ë°˜í™˜.

    Parameters
    ----------
    query : str
        ì‚¬ìš©ì ì§ˆì˜
    year_gte : Optional[int]
        íŠ¹ì • ì—°ë„ ì´ìƒ í•„í„° (ì˜ˆ: 2020)
    author : Optional[str]
        ì €ì ë¶€ë¶„ì¼ì¹˜ í•„í„°
    category : Optional[str]
        ì¹´í…Œê³ ë¦¬ í•„í„° (ì˜ˆ: 'cs.CL')
    top_k : int
        ë°˜í™˜í•  ë¬¸ì„œ ìˆ˜
    with_scores : bool
        ìœ ì‚¬ë„ ì ìˆ˜ í¬í•¨ ì—¬ë¶€
    use_multi_query : bool
        MultiQuery(LLM ì¿¼ë¦¬ í™•ì¥) ì‚¬ìš© ì—¬ë¶€
    search_mode : str
        "similarity" ë˜ëŠ” "mmr"
    """

    # ---------- Retriever ì¤€ë¹„ ----------
    r = RAGRetriever(search_type=search_mode, k=top_k)

    # ---------- ê²€ìƒ‰ ì‹¤í–‰ (í•„í„°/ë©€í‹°ì¿¼ë¦¬ ì²˜ë¦¬) ----------
    filter_dict = _build_filter(year_gte, author, category)
    docs: List[Document] = []
    pairs: List[Tuple[Document, float]] = []

    if any(filter_dict.values()):
        # ë©”íƒ€ë°ì´í„° í•„í„°ê°€ ìˆìœ¼ë©´ similarity + filterë¡œ ìˆ˜í–‰
        docs = r.search_with_filter(query, filter_dict, k=top_k)
        if with_scores:
            pairs = [(d, None) for d in docs]  # type: ignore
    else:
        if use_multi_query:
            docs = r.multi_query_search(query, k=top_k)
            if with_scores:
                pairs = r.similarity_search_with_score(query, k=len(docs) or top_k)
        else:
            if with_scores:
                pairs = r.similarity_search_with_score(query, k=top_k)
                docs = [d for d, _ in pairs]
            else:
                docs = r.similarity_search(query, k=top_k)

    # ---------- paper_id ë©”íƒ€ë¡œ PostgreSQL ë©”íƒ€ë°ì´í„° ì¡°íšŒ ----------
    paper_ids = []
    for d in docs:
        pid = d.metadata.get("paper_id")
        if isinstance(pid, int):
            paper_ids.append(pid)
        else:
            # í˜¹ì‹œ strì´ë©´ int ë¡œ ë³€í™˜ ì‹œë„
            try:
                paper_ids.append(int(pid))
            except Exception:
                pass
    meta_map = _fetch_paper_meta(list(set(paper_ids)))

    # ---------- ê²°ê³¼ í•©ì„± ----------
    score_map: Dict[str, float] = {}
    if with_scores and pairs:
        for d, s in pairs:
            if s is None:
                continue
            score_map[id(d)] = float(s)

    results: List[Dict[str, Any]] = []
    for d in docs:
        pid = d.metadata.get("paper_id")
        meta = meta_map.get(pid, {}) if pid is not None else {}
        results.append({
            "paper_id": pid,
            "title": meta.get("title") or d.metadata.get("title"),
            "authors": meta.get("authors") or d.metadata.get("authors"),
            "publish_date": meta.get("publish_date") or d.metadata.get("publish_date"),
            "url": meta.get("url") or d.metadata.get("url"),
            "category": meta.get("category") or d.metadata.get("category"),
            "citation_count": meta.get("citation_count"),
            "section": d.metadata.get("section", "ë³¸ë¬¸"),
            "content": d.page_content,
            "score": score_map.get(id(d)) if with_scores else None,
        })

    # ---------- Markdown í¬ë§·ìœ¼ë¡œ ë°˜í™˜ ----------
    return _format_markdown(results)


# ==================== Agent ë…¸ë“œ: RAG ê²€ìƒ‰ ==================== #

def search_paper_node(state, exp_manager=None):
    """
    Agent ë…¸ë“œ: ë…¼ë¬¸ DBì—ì„œ ê´€ë ¨ ë…¼ë¬¸ ê²€ìƒ‰ ë° ë‹µë³€ ìƒì„±

    Args:
        state (AgentState): Agent ìƒíƒœ
        exp_manager: ExperimentManager ì¸ìŠ¤í„´ìŠ¤ (ì„ íƒ ì‚¬í•­)

    Returns:
        AgentState: ì—…ë°ì´íŠ¸ëœ ìƒíƒœ
    """
    # -------------- ìƒíƒœì—ì„œ ì§ˆë¬¸ ë° ë‚œì´ë„ ì¶”ì¶œ -------------- #
    question = state["question"]                          # ì‚¬ìš©ì ì§ˆë¬¸
    difficulty = state.get("difficulty", "easy")          # ë‚œì´ë„ (ê¸°ë³¸ê°’: easy)

    # -------------- ë„êµ¬ë³„ Logger ìƒì„± -------------- #
    tool_logger = exp_manager.get_tool_logger('rag_paper') if exp_manager else None

    if tool_logger:
        tool_logger.write(f"RAG ê²€ìƒ‰ ë…¸ë“œ ì‹¤í–‰: {question}")
        tool_logger.write(f"ë‚œì´ë„: {difficulty}")

    # -------------- search_paper_database ë„êµ¬ í˜¸ì¶œ -------------- #
    try:
        # Langchain @tool í•¨ìˆ˜ í˜¸ì¶œ
        raw_results = search_paper_database.invoke({
            "query": question,                            # ê²€ìƒ‰ ì¿¼ë¦¬
            "year_gte": None,                             # ì—°ë„ í•„í„° ì—†ìŒ
            "author": None,                               # ì €ì í•„í„° ì—†ìŒ
            "category": None,                             # ì¹´í…Œê³ ë¦¬ í•„í„° ì—†ìŒ
            "top_k": 5,                                   # Top-5 ê²€ìƒ‰
            "with_scores": True,                          # ìœ ì‚¬ë„ ì ìˆ˜ í¬í•¨
            "use_multi_query": False,                     # MultiQuery ë¯¸ì‚¬ìš©
            "search_mode": "similarity",                  # ìœ ì‚¬ë„ ê²€ìƒ‰
        })

        if tool_logger:
            tool_logger.write(f"ê²€ìƒ‰ ê²°ê³¼: {len(raw_results)} ê¸€ì")

        # -------------- JSON í”„ë¡¬í”„íŠ¸ ë¡œë“œ -------------- #
        system_prompt = get_tool_prompt("search_paper", difficulty)  # JSON íŒŒì¼ì—ì„œ ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ ë¡œë“œ

        # -------------- ë‚œì´ë„ë³„ LLM ì´ˆê¸°í™” -------------- #
        llm_client = LLMClient.from_difficulty(
            difficulty=difficulty,
            logger=exp_manager.logger if exp_manager else None
        )

        # -------------- ë©”ì‹œì§€ êµ¬ì„± -------------- #
        user_content = f"""[ë…¼ë¬¸ ê²€ìƒ‰ ê²°ê³¼]
{raw_results}

[ì§ˆë¬¸]
{question}

ìœ„ ê²€ìƒ‰ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì§ˆë¬¸ì— ë‹µë³€í•´ì£¼ì„¸ìš”."""

        messages = [
            SystemMessage(content=system_prompt),  # ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸
            HumanMessage(content=user_content)     # ê²€ìƒ‰ ê²°ê³¼ + ì§ˆë¬¸
        ]

        if tool_logger:
            tool_logger.write("LLM ë‹µë³€ ìƒì„± ì‹œì‘")

        # -------------- LLM í˜¸ì¶œ -------------- #
        response = llm_client.llm.invoke(messages)  # LLM ì‘ë‹µ ìƒì„±

        if tool_logger:
            tool_logger.write(f"ë‹µë³€ ìƒì„± ì™„ë£Œ: {len(response.content)} ê¸€ì")
            tool_logger.close()

        # -------------- ìµœì¢… ë‹µë³€ ì €ì¥ -------------- #
        state["final_answer"] = response.content    # ë‹µë³€ ì €ì¥

    except Exception as e:
        if tool_logger:
            tool_logger.write(f"ë…¼ë¬¸ ê²€ìƒ‰ ì‹¤íŒ¨: {e}")
            tool_logger.close()

        # ì—ëŸ¬ ë©”ì‹œì§€ ì €ì¥
        state["final_answer"] = f"ë…¼ë¬¸ ê²€ìƒ‰ ì˜¤ë¥˜: {str(e)}"

    # -------------- ì—…ë°ì´íŠ¸ëœ ìƒíƒœ ë°˜í™˜ -------------- #
    return state
