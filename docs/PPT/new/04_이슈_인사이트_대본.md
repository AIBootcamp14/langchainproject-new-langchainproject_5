# 04. 이슈 & 인사이트 (페이지 63-66 대본)

## 페이지 63: 이슈 & 인사이트 인트로

**PPT 내용:**

논문 리뷰 챗봇
AI/ML 논문을 누구나 쉽게 이해하고 활용할 수 있는 지능형 챗봇 개발

논문을 읽고 이해하기란 쉽지 않을 뿐더러, 사용자마다 이해도의 차이가 존재할 수 있습니다.
저희는 그러한 정보 격차를 완화하고, 진입장벽을 낮추고자 해당 프로젝트를 기획하게 되었습니다.

**발표 대본:**
```
이제 프로젝트 개발 과정에서 발견한 이슈들과
그 해결 과정에서 얻은 인사이트를 공유드리겠습니다.

프로젝트 목표는 AI/ML 논문을 초심자도 쉽게 이해하고 활용할 수 있도록
정보 격차를 완화하고 진입장벽을 낮추는 것이었습니다.

이 과정에서 기술적 난관들을 만났고,
멘토링과 팀원 간 협업을 통해 문제를 해결하며
실무에 적용 가능한 귀중한 인사이트들을 얻을 수 있었습니다.
```

---

## 페이지 64: 인사이트 4가지

**PPT 내용:**

### 1. 난이도별 이중 LLM 전략
- Easy 모드: Solar Pro2 (한국어 특화, 저비용)
- Hard 모드: GPT-4 (기술 정확도, 고품질)
- 비용 절감 효과 - 간단한 작업에 저비용 모델 활용
- 실무에서도 적극 권장하는 전략
- 프롬프트만으론 한계 → 모델 자체 특성 활용이 효과적

### 2. AI Agent 라우팅 최적화
- Few-shot 예시가 라우팅 정확도를 크게 향상
- 각 도구별 2-3개 대표 예시 사용
- 도구 설명 상세화 (키워드, 시나리오, 주의사항)
- 재라우팅 로직보다 처음부터 정확한 프롬프팅이 중요
- 6-7개 도구는 적절 (실무 평균 4개)

### 3. RAG 검색 최적화
- 골든 데이터셋으로 검색 품질 평가
- 기본 유사도 검색만으로 충분 (MMR은 선택적)
- 하이브리드 검색 가중치: 벡터 0.7, 키워드 0.3
- 청크 사이즈: 논문 평균 문단 길이의 1.5배
- 골든 데이터셋 10-20개 준비해서 Precision/Recall 측정

### 4. PostgreSQL + pgvector 통합 전략
- 단일 DB로 관계형 + 벡터 검색 처리
- 논문 50-100편 규모에서 충분히 효과적
- 별도 Vector DB 불필요 (운영 간소화)
- 메타데이터 필터링으로 검색 성능 향상
- HNSW 인덱스 사용 권장

**발표 대본:**
```
프로젝트 진행 과정에서 얻은 4가지 핵심 인사이트를 소개합니다.

첫째, 난이도별 이중 LLM 전략입니다.
Easy 모드는 Solar Pro2를 사용하여 한국어 특화 답변과 비용 절감을 달성했고,
Hard 모드는 GPT-4를 사용하여 기술적 정확도를 확보했습니다.

멘토님께서도 실무에서 적극 권장하는 전략이라고 조언해주셨고,
프롬프트만으로는 난이도 차이를 명확히 구분하기 어렵다는 것을 확인했습니다.
모델 자체의 특성을 활용하는 것이 훨씬 효과적이었습니다.

둘째, AI Agent 라우팅 최적화입니다.
Few-shot 예시가 라우팅 정확도를 크게 향상시켰습니다.
각 도구별로 2-3개의 대표 예시를 제공하고,
도구 설명에 키워드, 시나리오, 주의사항을 상세히 명시했습니다.

멘토님께서는 재라우팅 로직을 구현하기보다
처음부터 정확한 프롬프팅으로 올바른 도구를 선택하는 것이 더 중요하다고 강조하셨고,
실무 평균 4개 도구에 비해 저희의 7개 도구는 적절한 수준이라고 평가해주셨습니다.

셋째, RAG 검색 최적화입니다.
골든 데이터셋을 구축하여 검색 품질을 정량적으로 평가했습니다.
논문 50-100편 규모에서는 기본 유사도 검색만으로 충분했고,
MMR은 선택적으로 사용하면 된다는 것을 확인했습니다.

하이브리드 검색에서 벡터 가중치 0.7, 키워드 가중치 0.3이
실무 평균이라는 조언을 받았으며,
청크 사이즈는 논문 평균 문단 길이의 1.5배로 설정했습니다.

넷째, PostgreSQL + pgvector 통합 전략입니다.
단일 DB로 관계형 데이터와 벡터 검색을 모두 처리하여
운영을 크게 간소화했습니다.

논문 50-100편 규모에서 충분히 효과적이며,
별도의 Vector DB가 불필요하다는 멘토님의 조언을 받았습니다.
메타데이터 필터링과 HNSW 인덱스를 활용하여
검색 성능을 최적화했습니다.
```

---

## 페이지 65: 이슈 4가지

**PPT 내용:**

### 1. 이슈 1: RAG 논문 검색 Fallback 실패
- **문제**: search_paper 실패 시 web_search로 자동 전환되지 않음
- **원인**: LLM이 정중한 답변 생성으로 실패 패턴 감지 실패

### 2. 이슈 2: 도구 자동전환 메커니즘 부재
- **문제**: 도구 선택 실패 시 재시도나 대체 도구 호출 없음
- **원인**: 단일 도구 실행 후 바로 END로 종료되는 그래프 구조

### 3. 이슈 3: 멀티턴 맥락 참조 라우팅 오류
- **문제**: 이전 대화 맥락을 참조하는 질문에서 도구 선택 오류
- **원인**: Router가 대화 히스토리를 충분히 활용하지 못함

### 4. 이슈 4: 용어집 도구 선택 실패
- **문제**: "BERT와 GPT 차이" 같은 비교 질문을 glossary로 잘못 라우팅
- **원인**: 용어 키워드만 보고 판단, 비교 질문 패턴 미학습

**발표 대본:**
```
개발 과정에서 직면한 4가지 주요 이슈를 소개합니다.

첫째, RAG 논문 검색 Fallback 실패 문제입니다.
search_paper 도구가 논문을 찾지 못했을 때
web_search로 자동 전환되어야 하는데 작동하지 않았습니다.

원인을 분석한 결과, LLM이 검색 실패 상황에서도
"죄송합니다만, 현재 데이터베이스에서 해당 논문을 찾지 못했습니다"와 같은
정중하고 완성된 문장으로 답변을 생성하면서
Failure Detector의 패턴 매칭이 실패한 것이었습니다.

둘째, 도구 자동전환 메커니즘 부재 문제입니다.
도구 선택이 잘못되었거나 실행이 실패했을 때
재시도나 대체 도구 호출 없이 바로 종료되었습니다.

초기 LangGraph 구조에서 모든 도구 노드가
실행 후 바로 END로 향하도록 설계되어 있었기 때문입니다.

셋째, 멀티턴 맥락 참조 라우팅 오류입니다.
"그럼 첫 번째 논문 요약해줘"처럼
이전 대화 맥락을 참조하는 질문에서
Router가 적절한 도구를 선택하지 못했습니다.

Router에 대화 히스토리를 전달했지만,
충분히 활용하지 못하는 문제가 있었습니다.

넷째, 용어집 도구 선택 실패 문제입니다.
"BERT와 GPT의 차이는?"처럼 두 개념을 비교하는 질문을
glossary 도구로 잘못 라우팅했습니다.

glossary는 단일 용어 정의만 제공하는 도구인데,
용어 키워드만 보고 판단하면서 비교 질문 패턴을 학습하지 못했습니다.
```

---

## 페이지 66: 이슈 해결 방법 4가지

**PPT 내용:**

### 1. 해결 1: 검색 실패 조기 감지 및 명확한 실패 메시지
- **해결**: raw_results에서 "관련 논문을 찾을 수 없습니다" 감지 시 LLM 호출 전 조기 반환
- **효과**: Failure Detector 패턴 정확히 매칭, web_search로 Fallback 성공

### 2. 해결 2: Fallback Chain 메커니즘 구현
- **해결**: 도구 우선순위 기반 Fallback Chain 시스템 구축
  - 질문 유형별 도구 우선순위 정의 (configs/model_config.yaml)
  - FallbackRouter 노드 추가
  - 조건부 엣지로 도구 실패 시 자동 재라우팅
- **효과**: 최대 재시도 3회, 최종 general 도구로 Fallback

### 3. 해결 3: 질문 재작성 기능 추가
- **해결**: 멀티턴 질문 시 대화 히스토리와 결합하여 완전한 질문 생성
  - "그럼 첫 번째 논문 요약해줘" → "Attention is All You Need 논문 요약해줘"
- **효과**: Router가 맥락 없이도 독립적으로 도구 선택 가능

### 4. 해결 4: Few-shot 예시 및 도구 설명 강화
- **해결**: routing_prompts.json에 비교 질문 예시 추가
  - "BERT와 GPT 차이" → general (비교는 용어집 X)
  - glossary 도구 설명에 "❌ 비교 질문은 general 사용" 명시
- **효과**: 비교 질문 라우팅 정확도 향상

**발표 대본:**
```
4가지 이슈에 대한 해결 방법을 소개합니다.

첫째, 검색 실패 조기 감지 및 명확한 실패 메시지입니다.
search_paper_node에서 raw_results에
"관련 논문을 찾을 수 없습니다"가 포함되어 있으면
LLM 호출 전에 조기 반환하도록 수정했습니다.

"데이터베이스에서 관련 논문을 찾지 못했습니다"라는
명확하고 간결한 실패 메시지를 반환하여
Failure Detector의 패턴 매칭이 정확히 작동하도록 했습니다.

이를 통해 search_paper 실패 시
web_search로 Fallback이 정상 작동하게 되었습니다.

둘째, Fallback Chain 메커니즘을 구현했습니다.
질문 유형별로 도구 우선순위를 정의하고,
FallbackRouter 노드를 추가하여
도구 실행 실패 시 자동으로 다음 우선순위 도구로 재라우팅합니다.

예를 들어 paper_search 유형은
search_paper → web_search → general 순서로 시도하며,
최대 재시도 3회 후에는 최종적으로 general 도구로 Fallback됩니다.

LangGraph의 조건부 엣지를 활용하여
should_fallback 함수가 tool_status를 확인하고
자동으로 재라우팅 여부를 결정합니다.

셋째, 질문 재작성 기능을 추가했습니다.
멀티턴 대화에서 "그럼 첫 번째 논문 요약해줘"처럼
맥락 참조가 필요한 질문을 받으면,
대화 히스토리와 결합하여 완전한 질문으로 재작성합니다.

"Attention is All You Need 논문 요약해줘"처럼
독립적인 질문으로 변환하여
Router가 맥락 없이도 정확한 도구를 선택할 수 있게 했습니다.

넷째, Few-shot 예시 및 도구 설명을 강화했습니다.
routing_prompts.json에 비교 질문 예시를 추가하고,
glossary 도구 설명에
"단일 용어 정의만 제공, 비교 질문은 general 사용"이라는
명확한 주의사항을 명시했습니다.

이를 통해 "BERT와 GPT 차이"처럼
두 개념을 비교하는 질문을 general 도구로 올바르게 라우팅하게 되었습니다.

이러한 문제 해결 과정을 통해
시스템의 안정성과 라우팅 정확도를 크게 향상시킬 수 있었고,
실무에서도 적용 가능한 귀중한 경험을 쌓을 수 있었습니다.
```

---

## 요약

**이슈 & 인사이트 파트 완료**

- 페이지 63-66 내용 작성 완료
- 각 페이지마다 PPT 내용과 발표 대본 포함

**주요 내용:**
1. 이슈 & 인사이트 인트로 (페이지 63)
2. 4가지 인사이트 (페이지 64)
   - 난이도별 이중 LLM 전략
   - AI Agent 라우팅 최적화
   - RAG 검색 최적화
   - PostgreSQL + pgvector 통합 전략
3. 4가지 이슈 (페이지 65)
   - RAG 논문 검색 Fallback 실패
   - 도구 자동전환 메커니즘 부재
   - 멀티턴 맥락 참조 라우팅 오류
   - 용어집 도구 선택 실패
4. 4가지 해결 방법 (페이지 66)
   - 검색 실패 조기 감지 및 명확한 실패 메시지
   - Fallback Chain 메커니즘 구현
   - 질문 재작성 기능 추가
   - Few-shot 예시 및 도구 설명 강화

**참고 문서:**
- docs/minutes/20251030/20251030_멘토링.md - 멘토링 인사이트
- docs/minutes/20251104/20251104_멘토링.md - 추가 멘토링 내용
- docs/issues/01-3_도구_자동전환_및_Fallback_메커니즘.md - Fallback 메커니즘 구현
- docs/issues/02-3_RAG_논문검색_Fallback_실패_문제.md - RAG 검색 이슈
- docs/issues/01-7_멀티턴_질문_재작성_구현.md - 질문 재작성
- docs/issues/02-5_용어집_도구_선택_실패_문제.md - 용어집 라우팅 이슈
