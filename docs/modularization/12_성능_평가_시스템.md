# 12. ì„±ëŠ¥ í‰ê°€ ì‹œìŠ¤í…œ

## ë¬¸ì„œ ì •ë³´
- **ì‘ì„±ì¼**: 2025-11-04
- **ì‘ì„±ì**: ìµœí˜„í™”[íŒ€ì¥]
- **ìµœì¢… ìˆ˜ì •ì¼**: 2025-11-04 (êµ¬ì²´ì  í‰ê°€ ê¸°ì¤€ ì¶”ê°€)

---

## ê°œìš”

ì„±ëŠ¥ í‰ê°€ ì‹œìŠ¤í…œì€ ì±—ë´‡ì˜ ë‹µë³€ í’ˆì§ˆì„ ìë™ìœ¼ë¡œ í‰ê°€í•˜ëŠ” ì‹œìŠ¤í…œì…ë‹ˆë‹¤. **LLM-as-a-Judge** ë°©ì‹ì„ ì‚¬ìš©í•˜ì—¬ ì •í™•ë„, ê´€ë ¨ì„±, ë‚œì´ë„ ì í•©ì„±, ì¶œì²˜ ëª…ì‹œ ì—¬ë¶€ë¥¼ í‰ê°€í•˜ê³ , í‰ê°€ ê²°ê³¼ë¥¼ PostgreSQLì— ì €ì¥í•©ë‹ˆë‹¤.

### í•µì‹¬ ê¸°ëŠ¥
1. LLM-as-a-Judge í‰ê°€ (GPT-5)
2. 4ê°€ì§€ í‰ê°€ ê¸°ì¤€ (ì •í™•ë„, ê´€ë ¨ì„±, ë‚œì´ë„ ì í•©ì„±, ì¶œì²˜ ëª…ì‹œ)
3. evaluation_results í…Œì´ë¸”ì— í‰ê°€ ê²°ê³¼ ì €ì¥
4. í‰ê°€ í†µê³„ ì§‘ê³„ (í‰ê·  ì ìˆ˜, ì´ í‰ê°€ ê°œìˆ˜)

---

## ì‹œìŠ¤í…œ ì•„í‚¤í…ì²˜

```mermaid
graph TB
    subgraph Input["ğŸ”¸ ì…ë ¥"]
        direction LR
        A[ì‚¬ìš©ì ì§ˆë¬¸] --> B[AI ë‹µë³€]
        B --> C[ì°¸ê³  ë¬¸ì„œ]
        C --> D[ë‚œì´ë„ ëª¨ë“œ]
    end

    subgraph Eval["ğŸ”¹ í‰ê°€"]
        direction LR
        E[AnswerEvaluator<br/>ì´ˆê¸°í™”] --> F[í‰ê°€ í”„ë¡¬í”„íŠ¸<br/>í¬ë§·íŒ…]
        F --> G[GPT-5 í˜¸ì¶œ]
        G --> H[JSON íŒŒì‹±<br/>ì ìˆ˜ ì¶”ì¶œ]
    end

    subgraph Storage["ğŸ”º ì €ì¥"]
        direction LR
        I[í‰ê°€ ê²°ê³¼<br/>DB ì €ì¥] --> J[í‰ê°€ í†µê³„<br/>ì§‘ê³„]
    end

    Input --> Eval
    Eval --> Storage

    %% Subgraph ìŠ¤íƒ€ì¼
    style Input fill:#e1f5ff,stroke:#01579b,stroke-width:3px,color:#000
    style Eval fill:#f3e5f5,stroke:#4a148c,stroke-width:3px,color:#000
    style Storage fill:#e8f5e9,stroke:#1b5e20,stroke-width:3px,color:#000

    %% ë…¸ë“œ ìŠ¤íƒ€ì¼ (ì…ë ¥ - íŒŒë‘ ê³„ì—´)
    style A fill:#90caf9,stroke:#1976d2,color:#000
    style B fill:#81d4fa,stroke:#0288d1,color:#000
    style C fill:#64b5f6,stroke:#1976d2,color:#000
    style D fill:#42a5f5,stroke:#1565c0,color:#000

    %% ë…¸ë“œ ìŠ¤íƒ€ì¼ (í‰ê°€ - ë³´ë¼ ê³„ì—´)
    style E fill:#ce93d8,stroke:#7b1fa2,color:#000
    style F fill:#ba68c8,stroke:#7b1fa2,color:#fff
    style G fill:#ab47bc,stroke:#4a148c,color:#fff
    style H fill:#9c27b0,stroke:#4a148c,color:#fff

    %% ë…¸ë“œ ìŠ¤íƒ€ì¼ (ì €ì¥ - ë…¹ìƒ‰ ê³„ì—´)
    style I fill:#a5d6a7,stroke:#388e3c,color:#000
    style J fill:#81c784,stroke:#2e7d32,color:#000
```

**ì•„í‚¤í…ì²˜ íë¦„ ì„¤ëª…:**
- **ì…ë ¥ ë‹¨ê³„**: ì‚¬ìš©ì ì§ˆë¬¸, AI ë‹µë³€, ì°¸ê³  ë¬¸ì„œ, ë‚œì´ë„ ëª¨ë“œë¥¼ ìˆœì°¨ì ìœ¼ë¡œ ìˆ˜ì§‘
- **í‰ê°€ ë‹¨ê³„**: AnswerEvaluatorë¥¼ ì´ˆê¸°í™”í•˜ê³ , í”„ë¡¬í”„íŠ¸ë¥¼ í¬ë§·íŒ…í•œ í›„ GPT-5ë¥¼ í˜¸ì¶œí•˜ì—¬ JSON í˜•ì‹ìœ¼ë¡œ í‰ê°€ ê²°ê³¼ íŒŒì‹±
- **ì €ì¥ ë‹¨ê³„**: í‰ê°€ ê²°ê³¼ë¥¼ PostgreSQL evaluation_results í…Œì´ë¸”ì— ì €ì¥í•˜ê³ , í‰ê°€ í†µê³„ë¥¼ ì§‘ê³„

---

## êµ¬í˜„ íŒŒì¼ êµ¬ì¡°

```
src/
â””â”€â”€ evaluation/
    â”œâ”€â”€ __init__.py              # ëª¨ë“ˆ ì´ˆê¸°í™”
    â”œâ”€â”€ evaluator.py             # AnswerEvaluator í´ë˜ìŠ¤
    â””â”€â”€ storage.py               # í‰ê°€ ê²°ê³¼ ì €ì¥/ì¡°íšŒ

scripts/
â”œâ”€â”€ evaluate_answers.py          # í‰ê°€ ìŠ¤í¬ë¦½íŠ¸
â””â”€â”€ test_evaluation_improvement.py  # í‰ê°€ ì‹œìŠ¤í…œ ê°œì„  í…ŒìŠ¤íŠ¸
```

---

## ì£¼ìš” í´ë˜ìŠ¤ ë° í•¨ìˆ˜

### 1. AnswerEvaluator í´ë˜ìŠ¤

**íŒŒì¼**: `src/evaluation/evaluator.py`

#### ë©”ì„œë“œ

| ë©”ì„œë“œ | ì„¤ëª… | ë°˜í™˜ íƒ€ì… |
|-------|------|----------|
| `__init__(exp_manager=None)` | AnswerEvaluator ì´ˆê¸°í™” | None |
| `evaluate(question, answer, reference_docs, difficulty)` | ë‹¨ì¼ ë‹µë³€ í‰ê°€ | Dict |
| `evaluate_batch(test_cases)` | ë°°ì¹˜ í‰ê°€ | List[Dict] |
| `close()` | Logger ì¢…ë£Œ | None |

#### ì‚¬ìš© ì˜ˆì‹œ

```python
from src.evaluation.evaluator import AnswerEvaluator

# AnswerEvaluator ì´ˆê¸°í™”
evaluator = AnswerEvaluator()

# ë‹µë³€ í‰ê°€
result = evaluator.evaluate(
    question="Transformer ë…¼ë¬¸ ì„¤ëª…í•´ì¤˜",
    answer="TransformerëŠ” 2017ë…„ Googleì—ì„œ ë°œí‘œí•œ ë”¥ëŸ¬ë‹ ëª¨ë¸ì…ë‹ˆë‹¤...",
    reference_docs="Attention Is All You Need (Vaswani et al., 2017)",
    difficulty="easy"
)

print(f"ì´ì : {result['total_score']}/40")
print(f"ì •í™•ë„: {result['accuracy_score']}/10")
print(f"ê´€ë ¨ì„±: {result['relevance_score']}/10")
print(f"ë‚œì´ë„ ì í•©ì„±: {result['difficulty_score']}/10")
print(f"ì¶œì²˜ ëª…ì‹œ: {result['citation_score']}/10")
print(f"ì½”ë©˜íŠ¸: {result['comment']}")
```

---

### 2. í‰ê°€ ê²°ê³¼ ì €ì¥/ì¡°íšŒ í•¨ìˆ˜

**íŒŒì¼**: `src/evaluation/storage.py`

#### í•¨ìˆ˜

| í•¨ìˆ˜ | ì„¤ëª… | ë°˜í™˜ íƒ€ì… |
|------|------|----------|
| `save_evaluation_results(results)` | í‰ê°€ ê²°ê³¼ ì €ì¥ | None |
| `get_evaluation_results(limit=10)` | ìµœê·¼ í‰ê°€ ê²°ê³¼ ì¡°íšŒ | List[Dict] |
| `get_evaluation_statistics()` | í‰ê°€ í†µê³„ ì¡°íšŒ | Dict |

#### ì‚¬ìš© ì˜ˆì‹œ

```python
from src.evaluation.storage import (
    save_evaluation_results,
    get_evaluation_results,
    get_evaluation_statistics
)

# í‰ê°€ ê²°ê³¼ ì €ì¥
save_evaluation_results([result])

# ìµœê·¼ í‰ê°€ ê²°ê³¼ ì¡°íšŒ (ìµœê·¼ 10ê°œ)
recent_results = get_evaluation_results(limit=10)

# í‰ê°€ í†µê³„ ì¡°íšŒ
stats = get_evaluation_statistics()
print(f"ì´ í‰ê°€ ê°œìˆ˜: {stats['total_count']}")
print(f"í‰ê·  ì •í™•ë„: {stats['avg_accuracy']}/10")
print(f"í‰ê·  ì´ì : {stats['avg_total']}/40")
```

---

## ë°ì´í„°ë² ì´ìŠ¤ ìŠ¤í‚¤ë§ˆ

### evaluation_results í…Œì´ë¸”

**í…Œì´ë¸” ìŠ¤í‚¤ë§ˆ:**

| ì»¬ëŸ¼ëª… | íƒ€ì… | ì œì•½ ì¡°ê±´ | ì„¤ëª… |
|--------|------|----------|------|
| eval_id | SERIAL | PRIMARY KEY | í‰ê°€ ID |
| question | TEXT | NOT NULL | ì‚¬ìš©ì ì§ˆë¬¸ |
| answer | TEXT | NOT NULL | AI ë‹µë³€ |
| accuracy_score | INT | CHECK (0-10) | ì •í™•ë„ ì ìˆ˜ |
| relevance_score | INT | CHECK (0-10) | ê´€ë ¨ì„± ì ìˆ˜ |
| difficulty_score | INT | CHECK (0-10) | ë‚œì´ë„ ì í•©ì„± ì ìˆ˜ |
| citation_score | INT | CHECK (0-10) | ì¶œì²˜ ëª…ì‹œ ì ìˆ˜ |
| total_score | INT | CHECK (0-40) | ì´ì  |
| comment | TEXT | NULL | í‰ê°€ ì½”ë©˜íŠ¸ |
| created_at | TIMESTAMP | DEFAULT NOW() | ìƒì„± ì‹œê°„ |

**SQL ì •ì˜:**

```sql
CREATE TABLE IF NOT EXISTS evaluation_results (
    eval_id SERIAL PRIMARY KEY,
    question TEXT NOT NULL,
    answer TEXT NOT NULL,
    accuracy_score INT CHECK (accuracy_score >= 0 AND accuracy_score <= 10),
    relevance_score INT CHECK (relevance_score >= 0 AND relevance_score <= 10),
    difficulty_score INT CHECK (difficulty_score >= 0 AND difficulty_score <= 10),
    citation_score INT CHECK (citation_score >= 0 AND citation_score <= 10),
    total_score INT CHECK (total_score >= 0 AND total_score <= 40),
    comment TEXT,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

-- ì¸ë±ìŠ¤
CREATE INDEX IF NOT EXISTS idx_evaluation_results_created_at ON evaluation_results(created_at DESC);
CREATE INDEX IF NOT EXISTS idx_evaluation_results_total_score ON evaluation_results(total_score DESC);
```

**ì¸ë±ìŠ¤:**

| ì¸ë±ìŠ¤ëª… | ì»¬ëŸ¼ | ì •ë ¬ | ìš©ë„ |
|---------|------|-----|------|
| idx_evaluation_results_created_at | created_at | DESC | ìµœê·¼ í‰ê°€ ê²°ê³¼ ì¡°íšŒ ì„±ëŠ¥ í–¥ìƒ |
| idx_evaluation_results_total_score | total_score | DESC | ê³ ë“ì  í‰ê°€ ê²°ê³¼ ì¡°íšŒ ì„±ëŠ¥ í–¥ìƒ |

**ê´€ë ¨ íŒŒì¼:**

- **ìŠ¤í‚¤ë§ˆ ì •ì˜**: `database/schema.sql` - í…Œì´ë¸” ìƒì„± ë° ì¸ë±ìŠ¤ ì •ì˜
- **êµ¬í˜„ ì½”ë“œ**: `src/evaluation/storage.py` - í‰ê°€ ê²°ê³¼ ì €ì¥, ì¡°íšŒ í•¨ìˆ˜ êµ¬í˜„
- **ì €ì¥ í•¨ìˆ˜**: `save_evaluation_results()` (storage.py:39)
- **ì¡°íšŒ í•¨ìˆ˜**: `get_evaluation_results()` (storage.py:68), `get_evaluation_statistics()` (storage.py:117)

---

## í‰ê°€ ê¸°ì¤€ ê°œìš”

### 4ê°€ì§€ í‰ê°€ í•­ëª©

| í•­ëª© | ì ìˆ˜ ë²”ìœ„ | ì„¤ëª… |
|------|----------|------|
| ì •í™•ë„ (Accuracy) | 0-10 | ì°¸ê³  ë¬¸ì„œì™€ì˜ ì¼ì¹˜ë„ (í•µì‹¬ ë‚´ìš© ë°˜ì˜ ë¹„ìœ¨) |
| ê´€ë ¨ì„± (Relevance) | 0-10 | ì§ˆë¬¸ê³¼ ë‹µë³€ì˜ ê´€ë ¨ë„ (ì§ì ‘ì„±, ì™„ì „ì„±) |
| ë‚œì´ë„ ì í•©ì„± (Difficulty) | 0-10 | ëª¨ë“œë³„ ì„¤ëª… ìˆ˜ì¤€ (Easy: ì‰¬ìš´ ìš©ì–´/ë¹„ìœ , Hard: ì „ë¬¸ ìš©ì–´/ìˆ˜ì‹) |
| ì¶œì²˜ ëª…ì‹œ (Citation) | 0-10 | ì°¸ê³  ë¬¸í—Œ ì¸ìš© ì •ë„ (ì œëª©+ì €ì+ì—°ë„) |
| **ì´ì ** | **0-40** | **4ê°œ í•­ëª© ì ìˆ˜ì˜ í•©** |

**ìƒì„¸ í‰ê°€ ê¸°ì¤€**: [12-1_í‰ê°€_ê¸°ì¤€_ìƒì„¸.md](./12-1_í‰ê°€_ê¸°ì¤€_ìƒì„¸.md) ì°¸ì¡°
**ì¼ê´€ì„± ê²€ì¦**: [12-2_í‰ê°€_ì¼ê´€ì„±_ê²€ì¦.md](./12-2_í‰ê°€_ì¼ê´€ì„±_ê²€ì¦.md) ì°¸ì¡°

---

## í‰ê°€ ìŠ¤í¬ë¦½íŠ¸

### 1. ê¸°ë³¸ í‰ê°€ ìŠ¤í¬ë¦½íŠ¸

**íŒŒì¼**: `scripts/evaluate_answers.py`

**ì‹¤í–‰ ë°©ë²•**:
```bash
python scripts/evaluate_answers.py
```

**ìŠ¤í¬ë¦½íŠ¸ íë¦„**:
1. ExperimentManager ì´ˆê¸°í™”
2. AnswerEvaluator ì´ˆê¸°í™”
3. í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤ ì •ì˜ (2ê°œ ì´ìƒ)
4. ë°°ì¹˜ í‰ê°€ ìˆ˜í–‰
5. í‰ê°€ ê²°ê³¼ PostgreSQLì— ì €ì¥
6. í‰ê°€ í†µê³„ ì¡°íšŒ ë° ì¶œë ¥
7. í‰ê°€ ê²°ê³¼ ë¡œê·¸ ê¸°ë¡

### 2. í‰ê°€ ì‹œìŠ¤í…œ ê°œì„  í…ŒìŠ¤íŠ¸

**íŒŒì¼**: `scripts/test_evaluation_improvement.py`

**ì‹¤í–‰ ë°©ë²•**:
```bash
python scripts/test_evaluation_improvement.py
```

**í…ŒìŠ¤íŠ¸ í•­ëª©**:
1. **ì¼ê´€ì„± í…ŒìŠ¤íŠ¸**: ë™ì¼ ë‹µë³€ 5íšŒ ë°˜ë³µ í‰ê°€ â†’ í‘œì¤€í¸ì°¨ ì¸¡ì •
2. **ì ìˆ˜ ë¶„í¬ ê²€ì¦**: ë‹¤ì–‘í•œ í’ˆì§ˆì˜ ë‹µë³€ í‰ê°€ â†’ ì˜ˆìƒ ë²”ìœ„ ë‚´ í¬í•¨ ì—¬ë¶€ í™•ì¸

**ìƒì„¸ ë‚´ìš©**: [12-2_í‰ê°€_ì¼ê´€ì„±_ê²€ì¦.md](./12-2_í‰ê°€_ì¼ê´€ì„±_ê²€ì¦.md) ì°¸ì¡°

---

## ì„±ëŠ¥ ì¸¡ì •

### í‰ê°€ ì‘ë‹µ ì‹œê°„

- **í‰ê· **: 3.2ì´ˆ
- **p50**: 3.1ì´ˆ
- **p95**: 4.8ì´ˆ âœ… (ëª©í‘œ: â‰¤ 5ì´ˆ)
- **p99**: 5.1ì´ˆ
- **ìµœì†Œ**: 2.5ì´ˆ
- **ìµœëŒ€**: 5.3ì´ˆ

### í‰ê°€ ì •í™•ë„ (10ê°œ í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤)

- **í‰ê·  ì •í™•ë„**: 8.4/10
- **í‰ê·  ê´€ë ¨ì„±**: 9.2/10
- **í‰ê·  ë‚œì´ë„ ì í•©ì„±**: 7.9/10
- **í‰ê·  ì¶œì²˜ ëª…ì‹œ**: 6.8/10
- **í‰ê·  ì´ì **: 32.3/40

---

## í™˜ê²½ ë³€ìˆ˜ ì„¤ì •

`.env` íŒŒì¼ì— í•„ìš”í•œ í™˜ê²½ ë³€ìˆ˜:

```
POSTGRES_HOST=localhost
POSTGRES_PORT=5432
POSTGRES_USER=postgres
POSTGRES_PASSWORD=your_password
POSTGRES_DB=papers

OPENAI_API_KEY=your_openai_key
```

---

## ì°¸ê³  ë¬¸ì„œ

- [docs/PRD/09_í‰ê°€_ê¸°ì¤€.md](../PRD/09_í‰ê°€_ê¸°ì¤€.md) - RAG í‰ê°€ ì§€í‘œ, LLM-as-a-Judge
- [docs/roles/ë‹´ë‹¹ì—­í• _05-2_ìµœí˜„í™”_ì„±ëŠ¥í‰ê°€ì‹œìŠ¤í…œ.md](../roles/ë‹´ë‹¹ì—­í• _05-2_ìµœí˜„í™”_ì„±ëŠ¥í‰ê°€ì‹œìŠ¤í…œ.md) - êµ¬í˜„ ê°€ì´ë“œ
- [docs/issues/05-2_ì„±ëŠ¥í‰ê°€ì‹œìŠ¤í…œ_êµ¬í˜„.md](../issues/05-2_ì„±ëŠ¥í‰ê°€ì‹œìŠ¤í…œ_êµ¬í˜„.md) - ì„±ëŠ¥ í‰ê°€ ì‹œìŠ¤í…œ ì´ˆê¸° êµ¬í˜„
- [docs/issues/05-3_í‰ê°€ì‹œìŠ¤í…œ_ê°œì„ _êµ¬ì²´ì _ê¸°ì¤€_ì¶”ê°€.md](../issues/05-3_í‰ê°€ì‹œìŠ¤í…œ_ê°œì„ _êµ¬ì²´ì _ê¸°ì¤€_ì¶”ê°€.md) - êµ¬ì²´ì  í‰ê°€ ê¸°ì¤€ ì¶”ê°€

---

## í–¥í›„ ê°œì„  ì‚¬í•­

### ë‹¨ê¸° ê°œì„  ì‚¬í•­
1. Streamlit UIì— í‰ê°€ ê²°ê³¼ í‘œì‹œ í˜ì´ì§€ ì¶”ê°€
2. í‰ê°€ í†µê³„ ì‹œê°í™” (ì°¨íŠ¸, ê·¸ë˜í”„)
3. í‰ê°€ ê²°ê³¼ CSV ë‚´ë³´ë‚´ê¸° ê¸°ëŠ¥

### ì¥ê¸° ê°œì„  ì‚¬í•­
1. RAG ê²€ìƒ‰ ì„±ëŠ¥ í‰ê°€ (Recall@K, MRR, NDCG)
2. Agent ë¼ìš°íŒ… ì •í™•ë„ í‰ê°€
3. ì‘ë‹µ ì‹œê°„ ë° ë¹„ìš© ë¶„ì„ ìë™í™”
4. í‰ê°€ ê²°ê³¼ ê¸°ë°˜ ë‹µë³€ í’ˆì§ˆ ê°œì„  ìë™í™”

---

## ì‘ì„±ì

- **ìµœí˜„í™”[íŒ€ì¥]** (êµ¬í˜„ ë° ë¬¸ì„œí™”)
