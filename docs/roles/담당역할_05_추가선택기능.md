# 추가 선택 기능 (먼저 개발 완료한 팀원이 선택)

## 문서 정보
- **작성일**: 2025-10-30
- **목적**: 핵심 기능 개발을 먼저 완료한 팀원이 추가로 선택하여 구현할 수 있는 기능 목록
- **우선순위**: 선택 사항 (시간이 있을 경우)

---

## 개요

핵심 기능(AI Agent, RAG, 용어집, 웹 검색, 파일 저장, UI)을 먼저 완료한 팀원이 아래 기능 중 선택하여 구현할 수 있습니다.

**선택 기준:**
1. 프로젝트에 가산점을 줄 수 있는 기능
2. 구현 난이도와 시간을 고려
3. 팀원의 관심사 및 강점

---

## 선택 기능 1: Text-to-SQL 도구 (⭐⭐⭐ 가산점)

### 기능 설명
자연어 질문을 SQL 쿼리로 변환하여 논문 통계 정보를 조회하는 도구

### 사용 시점
- "2024년에 발표된 논문 개수는?"
- "가장 많이 인용된 논문 Top 5는?"
- "저자별 논문 수 알려줘"
- "카테고리별 논문 분포는?"

### Langchain 구현

#### 1. SQLDatabaseChain 사용

**파일 경로**: `src/tools/text2sql.py`

**구현 방법**:
1. SQLDatabase.from_uri()로 PostgreSQL 연결
2. SQLDatabaseChain 생성
   - LLM: ChatOpenAI (model: gpt-4, temperature: 0)
   - db: SQLDatabase 인스턴스
   - verbose: True
3. `query_paper_statistics` 함수를 @tool 데코레이터로 정의
   - 인자: question (자연어 질문)
   - sql_chain.run()으로 SQL 생성 및 실행
   - 결과를 Markdown 형식으로 포맷팅하여 반환

#### 2. 커스텀 SQL 생성 (고급)

**구현 방법**:
1. SQL_GENERATION_PROMPT 정의
   - 데이터베이스 스키마 정보 포함
   - 질문을 SQL 쿼리로 변환하는 프롬프트
2. `custom_sql_query` 함수를 @tool 데코레이터로 정의
   - LLM으로 SQL 쿼리 생성
   - psycopg2로 PostgreSQL 연결
   - 생성된 SQL 쿼리 실행
   - 결과 포맷팅 (SQL과 결과 포함)
   - 오류 처리 (try-except-finally)

### 구현해야 할 기능
1. SQLDatabaseChain 설정
2. DB 스키마 정보 프롬프트에 포함
3. SQL 쿼리 생성
4. 쿼리 실행 및 결과 포맷팅
5. 오류 처리 (잘못된 SQL 생성 시)

### 사용하는 DB
- **PostgreSQL**: `papers`, `glossary` 테이블

### 예상 소요 시간
**2-3일**

### 예제 코드

```python
# src/tools/text2sql.py

from langchain.tools import tool
from langchain_openai import ChatOpenAI
from langchain_community.utilities import SQLDatabase
from langchain.chains import SQLDatabaseChain
import psycopg2

# PostgreSQL 연결
db = SQLDatabase.from_uri("postgresql://user:password@localhost:5432/papers")

# LLM 초기화 (SQL 생성용)
llm = ChatOpenAI(model="gpt-4", temperature=0)

# SQLDatabaseChain 생성
sql_chain = SQLDatabaseChain.from_llm(llm=llm, db=db, verbose=True)

@tool
def query_paper_statistics(question: str) -> str:
    """
    논문 통계 정보를 조회합니다. 자연어 질문을 SQL 쿼리로 변환하여 실행합니다.

    Args:
        question: 자연어 질문 (예: "2024년에 발표된 논문 개수는?")

    Returns:
        쿼리 결과 (Markdown 형식)
    """
    try:
        # SQLDatabaseChain으로 SQL 생성 및 실행
        result = sql_chain.run(question)

        return f"## 통계 조회 결과\n\n{result}"

    except Exception as e:
        return f"오류 발생: {str(e)}"


# 커스텀 SQL 생성 (고급)
SQL_GENERATION_PROMPT = """
다음 질문을 SQL 쿼리로 변환하세요.

데이터베이스 스키마:
- papers (paper_id, title, authors, publish_date, source, url, category, citation_count, abstract, created_at)
- glossary (term_id, term, definition, category, difficulty_level, created_at)

질문: {question}

하나의 SQL SELECT 쿼리만 반환하세요:
"""

@tool
def custom_sql_query(question: str) -> str:
    """
    커스텀 SQL 생성을 통한 통계 조회

    Args:
        question: 자연어 질문

    Returns:
        쿼리 결과
    """
    # LLM으로 SQL 쿼리 생성
    llm = ChatOpenAI(model="gpt-4", temperature=0)
    sql_query = llm.invoke(SQL_GENERATION_PROMPT.format(question=question)).content.strip()

    # SQL에서 마크다운 코드 블록 제거
    if sql_query.startswith("```"):
        sql_query = sql_query.split("```")[1]
        if sql_query.startswith("sql"):
            sql_query = sql_query[3:]
        sql_query = sql_query.strip()

    # PostgreSQL 연결 및 쿼리 실행
    conn = psycopg2.connect("postgresql://user:password@localhost/papers")
    cursor = conn.cursor()

    try:
        cursor.execute(sql_query)
        results = cursor.fetchall()
        column_names = [desc[0] for desc in cursor.description]

        # 결과 포맷팅
        formatted = f"## 통계 조회 결과\n\n"
        formatted += f"**실행된 SQL**:\n```sql\n{sql_query}\n```\n\n"
        formatted += f"**결과**:\n\n"

        if results:
            # 테이블 형식으로 포맷팅
            formatted += "| " + " | ".join(column_names) + " |\n"
            formatted += "| " + " | ".join(["---"] * len(column_names)) + " |\n"

            for row in results:
                formatted += "| " + " | ".join(str(val) for val in row) + " |\n"
        else:
            formatted += "결과가 없습니다.\n"

        cursor.close()
        conn.close()

        return formatted

    except Exception as e:
        cursor.close()
        conn.close()
        return f"SQL 오류: {str(e)}\n\n생성된 SQL:\n```sql\n{sql_query}\n```"
```

### 참고 자료
- Langchain SQL Database: https://python.langchain.com/docs/integrations/tools/sql_database
- SQLDatabaseChain: https://python.langchain.com/docs/use_cases/sql/

---

## 선택 기능 2: 성능 평가 시스템 (⭐⭐ 가산점)

### 기능 설명
챗봇의 답변 품질을 자동으로 평가하는 시스템

### 평가 항목
1. **답변 정확도**: 논문 내용과 일치하는지
2. **관련성**: 질문과 답변이 관련있는지
3. **난이도 적합성**: Easy/Hard 모드에 맞는 답변인지
4. **출처 명시**: 논문 제목, 저자를 명시했는지

### Langchain 구현

#### 1. LLM-as-a-Judge 평가

**파일 경로**: `src/evaluation/evaluator.py`

**구현 방법**:
1. EVALUATION_PROMPT 정의 (PromptTemplate)
   - 평가 기준: 정확도, 관련성, 난이도 적합성, 출처 명시 (각 0-10점)
   - JSON 형식으로 평가 결과 반환
2. `AnswerEvaluator` 클래스 정의
   - ChatOpenAI 초기화 (model: gpt-4, temperature: 0)
3. `evaluate` 메서드 구현
   - 프롬프트 포맷팅 (question, answer, reference_docs, difficulty)
   - LLM 호출하여 평가 수행
   - 결과를 JSON으로 파싱하여 반환

#### 2. 평가 결과 저장

**구현 방법**:
1. `save_evaluation_results` 함수 정의
2. PostgreSQL 연결
3. evaluation_results 테이블 생성
   - eval_id, question, answer, accuracy_score, relevance_score, difficulty_score, citation_score, total_score, comment, created_at
4. 평가 결과 리스트를 순회하며 INSERT
5. 커밋 및 연결 종료

### 구현해야 할 기능
1. LLM-as-a-Judge 프롬프트 설계
2. 평가 결과 JSON 파싱
3. PostgreSQL 평가 결과 테이블 생성
4. 평가 결과 저장 및 조회
5. Streamlit UI에 평가 결과 표시

### 예상 소요 시간
**2-3일**

### 예제 코드

```python
# src/evaluation/evaluator.py

from langchain_openai import ChatOpenAI
from langchain.prompts import PromptTemplate
import json
import psycopg2

# 평가 프롬프트
EVALUATION_PROMPT_TEMPLATE = """
다음 AI 챗봇의 답변을 평가해주세요.

[사용자 질문]
{question}

[AI 답변]
{answer}

[참고 문서]
{reference_docs}

[난이도 모드]
{difficulty}

[평가 기준]
1. 정확도 (0-10점): 참고 문서의 내용과 일치하는가?
2. 관련성 (0-10점): 질문과 답변이 관련있는가?
3. 난이도 적합성 (0-10점): 난이도 모드에 맞는 답변인가?
4. 출처 명시 (0-10점): 논문 제목, 저자를 명시했는가?

JSON 형식으로만 반환하세요:
{{
    "accuracy_score": <점수>,
    "relevance_score": <점수>,
    "difficulty_score": <점수>,
    "citation_score": <점수>,
    "total_score": <총점>,
    "comment": "<평가 코멘트>"
}}
"""

EVALUATION_PROMPT = PromptTemplate(
    template=EVALUATION_PROMPT_TEMPLATE,
    input_variables=["question", "answer", "reference_docs", "difficulty"]
)

class AnswerEvaluator:
    """답변 품질 평가 클래스"""

    def __init__(self):
        """LLM 초기화"""
        self.llm = ChatOpenAI(model="gpt-4", temperature=0)

    def evaluate(self, question: str, answer: str, reference_docs: str, difficulty: str):
        """
        답변 평가

        Args:
            question: 사용자 질문
            answer: AI 답변
            reference_docs: 참고 문서
            difficulty: 난이도

        Returns:
            평가 결과 딕셔너리
        """
        # 프롬프트 포맷팅
        prompt = EVALUATION_PROMPT.format(
            question=question,
            answer=answer,
            reference_docs=reference_docs,
            difficulty=difficulty
        )

        # LLM 호출
        response = self.llm.invoke(prompt)

        # JSON 파싱
        try:
            result = json.loads(response.content)
            return result
        except json.JSONDecodeError:
            return {
                "accuracy_score": 0,
                "relevance_score": 0,
                "difficulty_score": 0,
                "citation_score": 0,
                "total_score": 0,
                "comment": "평가 실패"
            }


def save_evaluation_results(evaluation_results):
    """
    평가 결과를 PostgreSQL에 저장

    Args:
        evaluation_results: 평가 결과 리스트
    """
    conn = psycopg2.connect("postgresql://user:password@localhost/papers")
    cursor = conn.cursor()

    # evaluation_results 테이블 생성
    cursor.execute("""
        CREATE TABLE IF NOT EXISTS evaluation_results (
            eval_id SERIAL PRIMARY KEY,
            question TEXT NOT NULL,
            answer TEXT NOT NULL,
            accuracy_score INT,
            relevance_score INT,
            difficulty_score INT,
            citation_score INT,
            total_score INT,
            comment TEXT,
            created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
        )
    """)

    # 평가 결과 삽입
    for result in evaluation_results:
        cursor.execute("""
            INSERT INTO evaluation_results
            (question, answer, accuracy_score, relevance_score, difficulty_score, citation_score, total_score, comment)
            VALUES (%s, %s, %s, %s, %s, %s, %s, %s)
        """, (
            result['question'],
            result['answer'],
            result['accuracy_score'],
            result['relevance_score'],
            result['difficulty_score'],
            result['citation_score'],
            result['total_score'],
            result['comment']
        ))

    conn.commit()
    cursor.close()
    conn.close()


# 사용 예시
if __name__ == "__main__":
    evaluator = AnswerEvaluator()

    # 테스트 평가
    question = "Transformer 논문 설명해줘"
    answer = "Transformer는 2017년 Google에서 발표한 딥러닝 모델입니다..."
    reference_docs = "Attention Is All You Need (Vaswani et al., 2017)"
    difficulty = "easy"

    result = evaluator.evaluate(question, answer, reference_docs, difficulty)
    print(json.dumps(result, indent=2, ensure_ascii=False))

    # 평가 결과 저장
    save_evaluation_results([{
        'question': question,
        'answer': answer,
        **result
    }])
```

### 참고 자료
- LangChain Evaluation: https://python.langchain.com/docs/guides/evaluation/

---

## 선택 기능 3: Reranking (검색 최적화) (⭐⭐)

### 기능 설명
RAG 검색 결과를 재순위화하여 더 관련성 높은 문서를 상위에 배치

### Langchain 구현

#### 1. Cohere Rerank 사용

**파일 경로**: `src/rag/reranking.py`

**구현 방법**:
1. `create_rerank_retriever` 함수 정의
   - 인자: base_retriever
2. CohereRerank 압축기 생성
   - model: "rerank-english-v2.0"
   - API 키를 환경변수에서 로드
3. ContextualCompressionRetriever 생성
   - base_compressor: CohereRerank
   - base_retriever: 전달받은 Retriever
4. 사용 예시
   - PGVector로 VectorStore 생성
   - base_retriever 생성 (k=20)
   - create_rerank_retriever()로 Reranking 적용
   - 상위 20개 중 재순위화하여 상위 5개 반환

#### 2. LLMChainExtractor (커스텀)

**구현 방법**:
1. `create_llm_extractor_retriever` 함수 정의
   - 인자: base_retriever, llm
2. LLMChainExtractor 생성
   - LLM을 사용하여 문서 압축
3. ContextualCompressionRetriever 생성
   - base_compressor: LLMChainExtractor
   - base_retriever: 전달받은 Retriever
4. 반환

### 구현해야 할 기능
1. Cohere API 키 설정
2. ContextualCompressionRetriever 구현
3. RAG 검색 도구에 Reranking 적용
4. 성능 비교 (Before/After)

### 예상 소요 시간
**1-2일**

### 참고 자료
- ContextualCompressionRetriever: https://python.langchain.com/docs/modules/data_connection/retrievers/contextual_compression/

---

## 선택 기능 4: 논문 비교 도구 (⭐)

### 기능 설명
여러 논문의 차이점을 비교하여 표로 정리

### 사용 시점
- "BERT와 GPT 비교해줘"
- "Transformer와 RNN의 차이는?"

### Langchain 구현

**파일 경로**: `src/tools/paper_comparison.py`

**구현 방법**:
1. `compare_papers` 함수를 @tool 데코레이터로 정의
   - 인자: paper1_title, paper2_title
2. RAG Retriever로 두 논문 검색
   - paper1_docs = rag_retriever.retrieve(paper1_title)
   - paper2_docs = rag_retriever.retrieve(paper2_title)
3. 비교 프롬프트 구성
   - 두 논문의 제목과 내용 포함
   - 비교 항목: 주요 기여, 모델 구조, 장점, 단점, 성능
   - Markdown 표 형식으로 출력 요청
4. LLM 호출하여 비교 결과 생성
5. 결과 반환

### 예상 소요 시간
**1일**

---

## 선택 기능 5: 대화 이력 시각화 (⭐)

### 기능 설명
사용자 질문 패턴, 자주 사용되는 도구 등을 시각화

### Streamlit 구현

**파일 경로**: `ui/analytics.py`

**구현 방법**:
1. `show_analytics` 함수 정의
2. Streamlit 헤더 표시 ("대화 이력 분석")
3. PostgreSQL 연결
4. 도구 사용 통계 조회
   - query_logs 테이블에서 tool_used별 COUNT
   - pandas.read_sql()로 DataFrame 생성
   - plotly.express.bar()로 막대 그래프 생성
   - st.plotly_chart()로 표시
5. 난이도별 질문 분포 조회
   - query_logs 테이블에서 difficulty_mode별 COUNT
   - pandas.read_sql()로 DataFrame 생성
   - plotly.express.pie()로 파이 차트 생성
   - st.plotly_chart()로 표시
6. 연결 종료

### 예상 소요 시간
**1일**

---

## 선택 기능 6: 멀티모달 지원 (이미지 논문) (⭐⭐⭐)

### 기능 설명
논문 내 그래프, 표, 수식 이미지를 GPT-4 Vision으로 분석

### Langchain 구현

**구현 방법**:
1. ChatOpenAI 초기화
   - model: "gpt-4-vision-preview"
2. `analyze_paper_image` 함수 정의
   - 인자: image_path, question
3. 이미지 로드 및 Base64 인코딩
   - 파일을 읽어서 base64로 인코딩
4. HumanMessage 생성
   - content에 text와 image_url 포함
   - text: 질문
   - image_url: Base64 인코딩된 이미지
5. GPT-4 Vision 호출
   - llm_vision.invoke([message])
6. 응답 내용 반환

### 예상 소요 시간
**2-3일**

---

## 우선순위 추천

### High Priority (가산점 크고 구현 가능)
1. **Text-to-SQL** (⭐⭐⭐) - 2-3일
2. **성능 평가 시스템** (⭐⭐) - 2-3일

### Medium Priority (구현 간단)
3. **Reranking** (⭐⭐) - 1-2일
4. **논문 비교 도구** (⭐) - 1일
5. **대화 이력 시각화** (⭐) - 1일

### Low Priority (시간 많이 소요)
6. **멀티모달 지원** (⭐⭐⭐) - 2-3일

---

## 선택 가이드

### 시간이 2일 남았다면
→ **Text-to-SQL** 또는 **성능 평가 시스템**

### 시간이 1일 남았다면
→ **Reranking** 또는 **논문 비교 도구**

### 시간이 여유 있다면
→ **멀티모달 지원**

---

## 참고 사항

- 선택 기능은 **필수가 아닙니다**
- 핵심 기능을 먼저 완성한 후 시간이 남을 때만 구현
- 팀원들과 상의하여 역할 분배
- 구현 시 **Feature 브랜치 생성** 필수
